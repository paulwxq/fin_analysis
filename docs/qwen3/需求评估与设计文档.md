# Qwen3 Chat Client for MAF - 需求评估与设计文档

## 文档版本

- **版本**: v1.0
- **日期**: 2026-01-29
- **作者**: AI Assistant
- **状态**: 需求评估阶段

---

## 1. 项目背景

### 1.1 问题陈述

Microsoft Agent Framework (MAF) python-1.0.0b260128 版本原生不支持阿里云通义千问（Qwen3）系列模型。当前只能通过OpenAI兼容模式运行，但这种方式**无法使用Qwen3特有的高级参数**：

- ❌ `enable_thinking` - 思考模式（CoT推理）
- ❌ `enable_search` - 原生联网搜索能力
- ❌ `incremental_output` - 增量流式输出控制
- ❌ 视觉模型的专用参数（min_pixels, max_pixels）

### 1.2 业务需求

本项目需要在MAF中使用以下两种Qwen3模型：

| 模型类型 | 模型ID | 主要用途 | 优先级 |
|---------|--------|---------|-------|
| **推理模型** | qwen-plus | 主要推理引擎，支持思考模式和联网搜索 | P0（核心） |
| **视觉模型** | qwen3-vl-plus / qwen-vl-max | K线图分析、技术形态识别 | P1（重要） |

### 1.3 技术目标

1. ✅ **完全兼容MAF架构** - 继承 `BaseChatClient`，遵循 `ChatClientProtocol`
2. ✅ **保留Qwen原生能力** - 支持所有特有参数
3. ✅ **类型安全** - 使用TypedDict提供IDE智能提示
4. ✅ **异步优先** - 全链路异步，避免阻塞事件循环
5. ✅ **生产级质量** - 错误处理、日志记录、成本监控

---

## 2. 技术架构分析

### 2.1 MAF架构关键点

根据官方文档和源码分析：

```
MAF 核心协议栈：
┌─────────────────────────────────────┐
│   ChatClientProtocol (接口协议)      │
│   - get_response()                   │
│   - get_streaming_response()         │
└─────────────────────────────────────┘
            ↓ 继承
┌─────────────────────────────────────┐
│   BaseChatClient (基类)              │
│   - 中间件自动注入                    │
│   - OpenTelemetry追踪                │
│   - 工具规范化                        │
└─────────────────────────────────────┘
            ↓ 实现
┌─────────────────────────────────────┐
│   QwenChatClient (自定义实现)        │
│   - 文本/推理模型                    │
│   - dashscope.Generation            │
│   - 参数转换与验证                    │
│   - 异步流式处理                      │
└─────────────────────────────────────┘
┌─────────────────────────────────────┐
│   QwenVLChatClient (自定义实现)      │
│   - 视觉模型                          │
│   - dashscope.MultiModalConversation│
│   - 多模态转换与验证                  │
│   - 异步流式处理                      │
└─────────────────────────────────────┘
```

**核心设计决策**：
- ✅ 推理模型与视觉模型**分别实现**（`QwenChatClient` / `QwenVLChatClient`），避免接口与参数混用
- ✅ 继承 `BaseChatClient` 而非仅实现协议 → 获得中间件支持
- ✅ **使用DashScope原生SDK**（文本用 `dashscope.Generation.call()`，视觉用 `dashscope.MultiModalConversation.call()`）→ 直接传递原生参数
- ✅ 异步桥接策略：**非流式**使用 `asyncio.to_thread`，**流式**使用“后台线程 + asyncio.Queue”
- ✅ 强制设置 `incremental_output=True` 避免流式重复

**API端点说明**：
- ✅ 使用 DashScope SDK 默认中国站端点（本模块默认在中国环境执行，不做 region 选择）
- ❌ 不使用 OpenAI 兼容模式

### 2.2 DashScope SDK架构特性

```
DashScope接口隔离原则：

文本模型 (qwen-plus)           视觉模型 (qwen3-vl-plus)
        ↓                              ↓
dashscope.Generation       dashscope.MultiModalConversation
        ↓                              ↓
简单消息格式                      复杂多模态格式
{'role': 'user',              {'role': 'user',
 'content': 'text'}            'content': [
                                 {'text': '...'},
                                 {'image': 'url'}
                               ]}
```

**关键差异**：
1. **接口强制分流** - 不同模型必须使用不同的调用类
2. **参数支持异构** - `enable_search` 仅文本模型支持
3. **消息格式不兼容** - 需要独立的转换逻辑

### 2.3 技术挑战与解决方案

| 挑战 | 影响 | 解决方案 |
|-----|------|---------|
| DashScope SDK是同步阻塞的 | 会阻塞MAF的asyncio事件循环 | 使用 `asyncio.to_thread` 放入后台线程池 |
| 流式输出默认累积模式 | UI会显示重复文本 | 强制 `incremental_output=True` |
| 思考模式必须流式调用 | 非流式会返回400错误 | 在 `get_response` 中检测并抛出异常 |
| 视觉模型不支持搜索 | 参数传递会报错 | 视觉Client禁用 `enable_search` |
| 多模态消息格式复杂 | 需要遍历和转换多种Content类型 | 编写健壮的 `_process_content_item` |

---

## 3. 文件结构设计

### 3.1 目录结构

```
qwen3/
├── __init__.py                  # 包导出
├── config.py                    # 全局配置与价格常量
├── qwen_options.py              # TypedDict配置类
├── qwen_client.py               # 推理模型Client (qwen-plus/max)
├── qwen_vl_client.py            # 视觉模型Client (qwen3-vl-plus)
├── utils.py                     # 共享工具函数
├── exceptions.py                # 自定义异常
│
├── tests/
│   ├── __init__.py
│   ├── test_qwen_client.py      # 推理模型单元测试
│   ├── test_qwen_vl_client.py   # 视觉模型单元测试
│   └── test_integration.py      # 集成测试（与MAF Agent）
│
└── examples/
    ├── basic_chat.py            # 基础对话示例
    ├── thinking_mode.py         # 思考模式示例
    ├── search_enhanced.py       # 联网搜索示例
    └── vision_analysis.py       # K线图分析示例
```

### 3.2 核心文件职责

#### 1. `config.py` (约40行)

**职责**：集中管理默认参数（除 API Key 外的可变项）

```python
DEFAULT_MODEL_ID = "qwen-plus"          # 默认模型
DEFAULT_TEMPERATURE = 0.7               # 温度
DEFAULT_MAX_TOKENS = 2000               # 最大输出 Token
DEFAULT_TOP_P = 0.9                     # Top-p
DEFAULT_ENABLE_SEARCH = True            # 默认是否启用搜索
REQUEST_TIMEOUT_S = 60                  # 请求超时（秒）
MAX_RETRIES = 3                         # 最大重试次数
```

#### 2. `qwen_options.py` (约80行)

**职责**：定义类型安全的配置类

```python
class QwenChatOptions(ChatOptions):
    """Qwen文本模型配置"""
    # 思维链控制
    enable_thinking: NotRequired[bool]          # 思考总开关
    include_reasoning: NotRequired[bool]        # 是否返回思考过程

    # 搜索与工具
    enable_search: NotRequired[bool]            # 原生搜索增强

    # 随机性控制
    seed: NotRequired[int]                      # 随机种子
    repetition_penalty: NotRequired[float]      # 重复惩罚

class QwenVLChatOptions(ChatOptions):
    """Qwen视觉模型配置"""
    min_pixels: NotRequired[int]
    max_pixels: NotRequired[int]
    # 注意：不包含 enable_search
```

**优势**：
- ✅ IDE自动补全
- ✅ 类型检查（MyPy/Pyright）
- ✅ 避免拼写错误

#### 3. `qwen_client.py` (约450行)

**职责**：封装文本推理模型

**核心类**：
```python
class QwenChatClient(BaseChatClient[QwenChatOptions]):
    def __init__(self, model_id, api_key, **kwargs)
    def _convert_messages(self, messages) -> List[Dict]
    def _build_request_params(self, messages, options) -> Dict
    async def _inner_get_response(self, messages, **options) -> ChatResponse
    async def _inner_get_streaming_response(self, messages, **options) -> AsyncIterable
```

**关键特性**：
- ✅ 支持 `enable_search` 联网搜索
- ✅ 强制 `incremental_output=True`
- ✅ 异步流式响应（使用线程池队列）
- ✅ Token统计日志

#### 4. `qwen_vl_client.py` (约550行)

**职责**：封装视觉语言模型

**核心类**：
```python
class QwenVLChatClient(BaseChatClient[QwenVLChatOptions]):
    def __init__(self, model_id, api_key, **kwargs)
    def _process_content_item(self, item) -> Dict[str, str]
    def _convert_messages(self, messages) -> List[Dict]
    async def _inner_get_response(self, messages, **options) -> ChatResponse
    async def _inner_get_streaming_response(self, messages, **options) -> AsyncIterable
```

**关键特性**：
- ✅ 多模态消息转换（Text + Image）
- ✅ 支持 URL 或 Base64（本地文件需调用侧先转 Base64）
- ✅ 仅图片分析（URL/Base64）
- ✅ 分辨率参数控制

#### 5. `utils.py` (约150行)

**职责**：共享工具函数

```python
def map_finish_reason(reason: str) -> FinishReason
def extract_search_info(response) -> Dict
async def async_retry(func, max_retries=3)
```

#### 6. `exceptions.py` (约60行)

**职责**：自定义异常类

```python
class QwenAPIError(Exception)
class ThinkingModeRequiresStreamError(ValueError)
class UnsupportedParameterError(ValueError)
class RateLimitError(QwenAPIError)
```

---

## 4. 核心实现策略

### 4.1 异步桥接模式

**问题**：DashScope SDK的 `Generation.call()` 是同步方法

**解决方案**：分两类处理  
- **非流式**：用 `asyncio.to_thread` 包装同步调用  
- **流式**：用后台线程生产数据 + `asyncio.Queue` 异步消费

```python
# 流式响应的异步适配器
async def _inner_get_streaming_response(self, ...):
    loop = asyncio.get_running_loop()
    queue = asyncio.Queue()
    sentinel = object()

    def _producer():
        try:
            responses = dashscope.Generation.call(stream=True, ...)
            for resp in responses:
                loop.call_soon_threadsafe(queue.put_nowait, resp)
            loop.call_soon_threadsafe(queue.put_nowait, sentinel)
        except Exception as e:
            loop.call_soon_threadsafe(queue.put_nowait, e)

    threading.Thread(target=_producer, daemon=True).start()

    while True:
        item = await queue.get()
        if item is sentinel:
            break
        if isinstance(item, Exception):
            raise item
        yield ChatResponseUpdate(...)
```

### 4.2 思考模式处理

**DashScope返回结构**：
```json
{
  "output": {
    "choices": [{
      "message": {
        "reasoning_content": "思考过程...",  // 思维链
        "content": "最终答案..."              // 实际回答
      }
    }]
  }
}
```

**处理策略**：
1. 检测 `delta.reasoning_content` 字段
2. 根据 `include_reasoning` 参数决定是否返回给用户
3. 记录思考Token数量

```python
if hasattr(delta, "reasoning_content") and delta.reasoning_content:
    # 优先使用SDK返回的usage.reasoning_tokens；无该字段时才用长度估算
    if usage and getattr(usage, "reasoning_tokens", None) is not None:
        thinking_tokens += usage.reasoning_tokens
    else:
        thinking_tokens += len(delta.reasoning_content) // 4
    if include_reasoning:
        contents.append(TextContent(
            text=f"<thinking>{delta.reasoning_content}</thinking>"
        ))
```

### 4.3 多模态消息转换

**MAF格式** → **DashScope格式**：

```python
def _process_content_item(self, item) -> Dict[str, str]:
    # 1. 文本内容
    if isinstance(item, str):
        return {"text": item}

    if hasattr(item, "text") and item.text:
        return {"text": item.text}

    # 2. 图像内容
    if hasattr(item, "url") and item.url:
        return {"image": item.url}

    if hasattr(item, "data") and item.data:
        # Base64编码的图片
        return {"image": item.data}

    return {"text": str(item)}
```

---

## 5. 测试策略

### 5.1 单元测试覆盖

**推理模型测试** (`test_qwen_client.py`)：

```python
class TestQwenChatClient:
    def test_message_conversion()              # 消息格式转换
    def test_basic_chat()                       # 基础对话
    def test_streaming_response()               # 流式响应
    def test_thinking_mode()                    # 思考模式
    def test_search_enabled()                   # 联网搜索
    def test_thinking_requires_stream()         # 错误处理
    def test_cost_tracking()                    # Token统计
```

**视觉模型测试** (`test_qwen_vl_client.py`)：

```python
class TestQwenVLChatClient:
    def test_multimodal_message_conversion()    # 多模态转换
    def test_image_url_input()                  # URL图片
    def test_image_base64_input()               # Base64图片
    def test_text_only_input()                  # 纯文本降级
    def test_unsupported_search_parameter()     # 参数验证
```

**集成测试** (`test_integration.py`)：

```python
class TestMAFIntegration:
    def test_with_chat_agent()                  # 与ChatAgent集成
    def test_middleware_compatibility()         # 中间件兼容性
    def test_mixed_model_workflow()             # 混合模型工作流
```

### 5.2 测试数据准备

```
tests/fixtures/
├── sample_kline.png          # K线图样本
├── sample_messages.json      # 消息样本
└── mock_responses.json       # Mock API响应
```

---

## 6. 依赖管理

### 6.1 新增依赖

需要添加到 `pyproject.toml`：

```toml
dependencies = [
    # 现有依赖...
    "dashscope>=1.20.0",           # 阿里云DashScope SDK
    "tenacity>=9.0.0",             # 重试机制（可选）
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.25.0",
    "pytest-mock>=3.15.0",
    "mypy>=1.15.0",
]
```

### 6.2 环境变量

需要在 `.env` 中配置（仅 API Key）：

```bash
# Qwen API配置
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxx

# 其他可变参数统一写入 config.py
```

---

## 7. 开发计划

### 7.1 开发阶段（预计3-5天）

| 阶段 | 任务 | 文件 | 工作量 | 优先级 |
|-----|------|------|-------|-------|
| **Phase 1** | 基础架构搭建 | `qwen_options.py`<br>`exceptions.py`<br>`utils.py` | 4小时 | P0 |
| **Phase 2** | 推理模型实现 | `qwen_client.py` | 8小时 | P0 |
| **Phase 3** | 视觉模型实现 | `qwen_vl_client.py` | 8小时 | P1 |
| **Phase 4** | 单元测试编写 | `tests/test_*.py` | 6小时 | P0 |
| **Phase 5** | 示例和文档 | `examples/*.py`<br>`README.md` | 4小时 | P1 |

**总计**: 约30小时工作量

### 7.2 里程碑

- [x] **M1 - 需求评估完成** (当前)
- [ ] **M2 - 推理模型可用** (Phase 1-2完成)
  - 支持基础对话
  - 支持思考模式
  - 支持联网搜索
- [ ] **M3 - 视觉模型可用** (Phase 3完成)
  - 支持图片分析
  - 支持K线图识别
- [ ] **M4 - 生产就绪** (Phase 4-5完成)
  - 测试覆盖率 > 80%
  - 完整文档和示例

---

## 8. 风险评估

### 8.1 技术风险

| 风险 | 概率 | 影响 | 缓解措施 |
|-----|------|------|---------|
| DashScope API限流 | 中 | 中 | 实现指数退避重试 + 本地限流器 |
| 异步流式阻塞 | 低 | 高 | 使用线程池隔离 + 超时机制 |
| 多模态格式兼容 | 中 | 中 | 编写健壮的类型检测逻辑 |

### 8.2 质量保证

**代码质量标准**：
- ✅ 类型标注覆盖率 100%
- ✅ 单元测试覆盖率 > 80%
- ✅ 所有异步函数必须测试超时
- ✅ 所有公开API必须有docstring

**性能要求**：
- ✅ 流式首字延迟 < 2秒（TTFT）
- ✅ 异步并发10个请求不阻塞
- ✅ 内存泄漏测试（长时间运行）

---

## 9. 成功标准

### 9.1 功能验收

- [ ] 推理模型（qwen-plus）能在MAF中正常调用
- [ ] 视觉模型（qwen3-vl-plus）能分析K线图
- [ ] 思考模式正确返回推理过程
- [ ] 联网搜索正确返回引用信息
- [ ] 所有参数（温度、Top-P等）正确传递
- [ ] 流式输出无重复文本
- [ ] 错误处理完善（网络错误、API错误、参数错误）

### 9.2 集成验收

- [ ] 能与 `ChatAgent` 无缝集成
- [ ] 中间件（日志、追踪）自动生效
- [ ] 工具调用（Function Calling）正常工作
- [ ] 多轮对话上下文正确传递

### 9.3 文档验收

- [ ] API参考文档完整
- [ ] 至少4个可运行示例
- [ ] 故障排查指南
- [ ] 参数调优建议

---

## 10. 后续优化方向

### 10.1 短期优化（1-2周）

1. **性能优化**
   - 连接池复用
   - 响应缓存（幂等请求）
   - 批量推理支持

### 10.2 中期扩展（1-2月）

1. **多模型编排**
   - 自动模型选择（根据任务类型）
   - 模型降级策略（qwen-max → qwen-plus）
   - A/B测试框架

2. **高级特性**
   - RAG增强（结合向量数据库）
   - 多Agent协作

---

## 11. 附录

### 11.1 参考文档

1. [Microsoft Agent Framework 官方文档](https://learn.microsoft.com/en-us/agent-framework)
2. [DashScope API参考](https://www.alibabacloud.com/help/en/model-studio)
3. [Qwen3技术博客](https://qwenlm.github.io)
4. 本地文档：
   - `docs/qwen/Qwen集成MS_Agent_Framework完整指南_v3最终版.md`
   - `docs/qwen/Qwen3 MAF 融合开发指南.md`
   - `docs/qwen/Qwen3 模型MAF封装设计文档.md`

### 11.2 术语表

| 术语 | 英文 | 解释 |
|-----|------|------|
| MAF | Microsoft Agent Framework | 微软智能体框架 |
| CoT | Chain of Thought | 思维链推理 |
| TTFT | Time To First Token | 首字延迟 |
| RAG | Retrieval-Augmented Generation | 检索增强生成 |
| VL | Vision-Language | 视觉-语言多模态 |

---

## 12. 决策记录

### 决策1：使用BaseChatClient而非仅实现协议

**日期**: 2026-01-29
**决策人**: 开发团队
**理由**:
- 自动获得中间件支持
- OpenTelemetry追踪免费
- 框架升级时自动获得新特性

**备选方案**: 仅实现ChatClientProtocol
**权衡**: 实现难度稍高，但长期收益大

---

### 决策2：推理模型和视觉模型分别实现

**日期**: 2026-01-29
**决策人**: 架构师
**理由**:
- DashScope强制接口隔离（Generation vs MultiModalConversation）
- 参数支持差异大（enable_search仅文本模型）
- 消息格式完全不同

**备选方案**: 单一Client自动检测模型类型
**权衡**: 代码复杂度高，容易出错

---

### 决策3：使用TypedDict而非dataclass

**日期**: 2026-01-29
**决策人**: 开发团队
**理由**:
- MAF原生使用TypedDict（ChatOptions）
- 更好的向后兼容性
- 支持 `NotRequired` 灵活标注

**备选方案**: Pydantic BaseModel
**权衡**: TypedDict运行时无验证，但符合MAF风格

---

## 13. 下一步行动

### 立即行动（今天）

1. [ ] **环境配置**
   - 在 `pyproject.toml` 添加 `dashscope` 依赖
   - 验证 `DASHSCOPE_API_KEY` 可用
   - 运行 `uv sync` 更新依赖

2. [ ] **代码框架搭建**
   - 创建所有空文件（按上述结构）
   - 编写 `qwen_options.py`
   - 编写 `exceptions.py`

### 本周目标

- [ ] 完成 `qwen_client.py` 核心实现
- [ ] 编写基础单元测试
- [ ] 验证基础对话功能

### 下周目标

- [ ] 完成 `qwen_vl_client.py` 实现
- [ ] 编写K线图分析示例
- [ ] 完成集成测试

---

**文档状态**: ✅ 已完成需求评估
**下一阶段**: 开始Phase 1开发
