# Microsoft Agent Frameworké›†æˆQwenå®Œæ•´æŒ‡å—(v3æœ€ç»ˆç‰ˆ)
> **æ•´åˆä¸¤ä»½ä¸“ä¸šæŠ€æœ¯æ–‡æ¡£ | ç”Ÿäº§å°±ç»ª | 2026-01-29æ›´æ–°**

åŸºäº:
- Microsoft Agent Framework python-1.0.0b260127å®˜æ–¹è§„èŒƒ
- é˜¿é‡Œäº‘Qwen3-Plus/VL-Plusæ·±åº¦æŠ€æœ¯ç ”ç©¶(15,000å­—)
- å®æˆ˜éªŒè¯çš„ç”Ÿäº§çº§æœ€ä½³å®è·µ

---

## ğŸ“‹ å¿«é€Ÿå¯¼èˆª

- [æ ¸å¿ƒæ¶æ„å†³ç­–](#ä¸€æ ¸å¿ƒæ¶æ„å†³ç­–) - ä¸ºä»€ä¹ˆé€‰æ‹©BaseChatClient
- [æ–¹æ¡ˆä¸€:å¿«é€Ÿé›†æˆ](#äºŒæ–¹æ¡ˆä¸€openaiå…¼å®¹å¿«é€Ÿé›†æˆ) - 5åˆ†é’Ÿä¸Šæ‰‹
- [æ–¹æ¡ˆäºŒ:å®Œæ•´å®ç°](#ä¸‰æ–¹æ¡ˆäºŒå®Œæ•´qwenclientç”Ÿäº§çº§å®ç°) - ç”Ÿäº§ç¯å¢ƒæ¨è
- [Qwen3æ€è€ƒæ¨¡å¼](#å››qwen3æ€è€ƒæ¨¡å¼æ·±åº¦è§£æ) - enable_thinkingå®Œæ•´æŒ‡å—
- [è§†è§‰æ¨¡å‹æ”¯æŒ](#äº”è§†è§‰æ¨¡å‹qwen3-vl-plusé›†æˆ) - å›¾åƒ/è§†é¢‘å¤„ç†
- [æˆæœ¬æ§åˆ¶](#å…­æˆæœ¬æ§åˆ¶ä¸tokenç›‘æ§) - é¿å…è´¹ç”¨çˆ†ç‚¸
- [å¸¸è§é—®é¢˜](#ä¸ƒå¸¸è§é—®é¢˜æ’æŸ¥) - å¿«é€Ÿè§£å†³æ–¹æ¡ˆ

---

## ä¸€ã€æ ¸å¿ƒæ¶æ„å†³ç­–

### 1.1 å†…ç½®å®¢æˆ·ç«¯ç°çŠ¶

| å®¢æˆ·ç«¯ | æ¨¡å— | çŠ¶æ€ | ç‰¹æ€§ |
|--------|------|------|------|
| AnthropicClient | `agent_framework.anthropic` | âœ… å†…ç½® | thinkingã€å·¥å…·è°ƒç”¨ã€æµå¼ |
| OpenAIChatClient | `agent_framework.openai` | âœ… å†…ç½® | æ ‡å‡†OpenAIåè®® |
| **QwenClient** | éœ€è‡ªè¡Œå®ç° | âŒ ç¼ºå¤± | æ€è€ƒé¢„ç®—ã€åŸç”Ÿæœç´¢ã€è§†è§‰ |

### 1.2 å…³é”®å†³ç­–:BaseChatClient vs ChatClientProtocol

**ğŸ¯ ç”Ÿäº§ç¯å¢ƒå¼ºçƒˆæ¨è:ç»§æ‰¿BaseChatClient**

| ç»´åº¦ | ChatClientProtocol | BaseChatClient |
|------|-------------------|----------------|
| å®ç°éš¾åº¦ | â­ ç®€å• | â­â­ ä¸­ç­‰ |
| ä¸­é—´ä»¶æ”¯æŒ | âŒ éœ€æ‰‹åŠ¨ | âœ… è‡ªåŠ¨ |
| OpenTelemetry | âŒ éœ€æ‰‹åŠ¨ | âœ… è‡ªåŠ¨ |
| å·¥å…·è§„èŒƒåŒ– | âŒ éœ€æ‰‹åŠ¨ | âœ… è‡ªåŠ¨ |
| ç”Ÿäº§é€‚ç”¨æ€§ | åŸå‹/æµ‹è¯• | **ä¼ä¸šçº§åº”ç”¨** |

**å†³ç­–ç†ç”±**:
1. **ä¸­é—´ä»¶ç®¡é“**:è‡ªåŠ¨åº”ç”¨æ—¥å¿—ã€é‰´æƒã€é™æµç­‰åˆ‡é¢é€»è¾‘
2. **å¯è§‚æµ‹æ€§**:è‡ªåŠ¨æ¥å…¥OpenTelemetryè¿½è¸ª
3. **å·¥å…·å¤„ç†**:è‡ªåŠ¨è§„èŒƒåŒ–å·¥å…·å®šä¹‰æ ¼å¼
4. **é•¿æœŸç»´æŠ¤**:æ¡†æ¶å‡çº§æ—¶è‡ªåŠ¨è·å¾—æ–°ç‰¹æ€§

---

## äºŒã€æ–¹æ¡ˆä¸€:OpenAIå…¼å®¹å¿«é€Ÿé›†æˆ

### é€‚ç”¨åœºæ™¯
- âœ… MVPå¿«é€ŸéªŒè¯
- âœ… ä¸éœ€è¦Qwenç‰¹æœ‰åŠŸèƒ½(thinking_budgetã€enable_search)
- âœ… è¿½æ±‚é›¶é¢å¤–ä»£ç 

### å®Œæ•´ä»£ç 

```python
from agent_framework import ChatAgent
from agent_framework.openai import OpenAIChatClient
from openai import AsyncOpenAI
import os

# 1. åˆ›å»ºæŒ‡å‘Qwen APIçš„OpenAIå®¢æˆ·ç«¯
qwen_client = AsyncOpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    # é€‰æ‹©æ­£ç¡®çš„åœ°åŸŸç«¯ç‚¹
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"  # ä¸­å›½ç«™
    # base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1"  # å›½é™…ç«™
)

# 2. ä½¿ç”¨OpenAIChatClientåŒ…è£…
chat_client = OpenAIChatClient(
    model_id="qwen-plus",  # æˆ– qwen-max, qwen3-235b-a22b-instruct-2507
    openai_client=qwen_client
)

# 3. åˆ›å»ºAgent
agent = ChatAgent(
    chat_client=chat_client,
    instructions="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚",
    name="QwenAssistant"
)

# 4. è¿è¡Œ
result = await agent.run("ç”¨ä¸­æ–‡è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—")
print(result.text)
```

### ä¼˜åŠ£åˆ†æ

**ä¼˜åŠ¿**:
- é›¶ç»´æŠ¤æˆæœ¬,ä¾èµ–å®˜æ–¹SDK
- è‡ªåŠ¨æ”¯æŒå·¥å…·è°ƒç”¨
- æµå¼å“åº”è‡ªåŠ¨å¤„ç†

**å±€é™**:
- âŒ æ— æ³•ä½¿ç”¨`thinking_budget`æ§åˆ¶æ€è€ƒæˆæœ¬
- âŒ æ— æ³•ä½¿ç”¨`enable_search`åŸç”Ÿæœç´¢
- âŒ æ— æ³•ç²¾ç»†æ§åˆ¶`incremental_output`
- âŒ æ— æ³•è®¿é—®è§†è§‰æ¨¡å‹ç‰¹æœ‰å‚æ•°

---

## ä¸‰ã€æ–¹æ¡ˆäºŒ:å®Œæ•´QwenClientç”Ÿäº§çº§å®ç°

### 3.1 TypedDictå¼ºç±»å‹é…ç½®(v1.0.0b260127æ ¸å¿ƒç‰¹æ€§)

```python
from typing import TypedDict, NotRequired, Literal
from agent_framework import ChatOptions

class QwenChatOptions(ChatOptions):
    """Qwenæ¨¡å‹å®Œæ•´é…ç½® - æä¾›IDEæ™ºèƒ½æç¤ºå’Œç±»å‹æ£€æŸ¥"""
    
    # æ€ç»´é“¾æ§åˆ¶
    enable_thinking: NotRequired[bool]          # æ€è€ƒæ€»å¼€å…³
    thinking_budget: NotRequired[int]           # ğŸ”¥ æ€è€ƒTokené¢„ç®—ä¸Šé™
    
    # æœç´¢ä¸å·¥å…·
    enable_search: NotRequired[bool]            # åŸç”Ÿæœç´¢å¢å¼º
    
    # æµå¼æ§åˆ¶
    incremental_output: NotRequired[bool]       # å¿…é¡»ä¸ºTrue(æµå¼å¢é‡)
    
    # éšæœºæ€§æ§åˆ¶
    seed: NotRequired[int]                      # éšæœºç§å­
    repetition_penalty: NotRequired[float]      # é‡å¤æƒ©ç½š
    
    # è§†è§‰æ¨¡å‹ä¸“ç”¨
    min_pixels: NotRequired[int]                # æœ€å°åˆ†è¾¨ç‡
    max_pixels: NotRequired[int]                # æœ€å¤§åˆ†è¾¨ç‡
    
    # è°ƒè¯•é€‰é¡¹
    include_reasoning: NotRequired[bool]        # æ˜¯å¦åœ¨å“åº”ä¸­åŒ…å«æ€è€ƒè¿‡ç¨‹
```

**ä¸ºä»€ä¹ˆéœ€è¦TypedDict?**
- âœ… IDEè‡ªåŠ¨è¡¥å…¨å’Œé”™è¯¯æç¤º
- âœ… MyPy/Pyrightç¼–è¯‘æœŸç±»å‹æ£€æŸ¥
- âœ… é¿å…"é…ç½®æ¼‚ç§»"(æ‹¼å†™é”™è¯¯è¢«é™é»˜å¿½ç•¥)
- âœ… æ–‡æ¡£å³ä»£ç (è‡ªæè¿°)

### 3.2 å®Œæ•´QwenClientå®ç°

```python
"""
qwen_client.py - Microsoft Agent Frameworkçš„Qwen LLMå®¢æˆ·ç«¯
éµå¾ªv1.0.0b260127æ¶æ„è§„èŒƒ
"""
from __future__ import annotations

import os
import json
import asyncio
import logging
from typing import Any, Literal
from collections.abc import AsyncIterable
from concurrent.futures import ThreadPoolExecutor

# DashScope SDK
from dashscope import Generation
from dashscope.api_entities.dashscope_response import GenerationResponse

# Agent Frameworkæ ¸å¿ƒ
from agent_framework import (
    BaseChatClient,
    ChatMessage,
    ChatResponse,
    ChatResponseUpdate,
    Role,
    TextContent,
    ToolCallContent,
    ToolResultContent,
    UsageDetails,
)

logger = logging.getLogger(__name__)


class QwenChatClient(BaseChatClient[QwenChatOptions]):
    """
    Microsoft Agent Frameworkçš„Qwen LLMå®¢æˆ·ç«¯
    
    æ”¯æŒåŠŸèƒ½:
    - Qwenå…¨ç³»åˆ—æ¨¡å‹(qwen-plus, qwen-max, qwen3-*)
    - æ€è€ƒæ¨¡å¼(enable_thinking + thinking_budget)
    - åŸç”Ÿæœç´¢(enable_search)
    - å‡½æ•°è°ƒç”¨/å·¥å…·ä½¿ç”¨
    - æµå¼å“åº”(å¼ºåˆ¶incremental_output=True)
    - è§†è§‰æ¨¡å‹(qwen3-vl-plus)
    """
    
    # APIç«¯ç‚¹æ˜ å°„
    ENDPOINTS = {
        "china": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "international": "https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
        "us": "https://dashscope-us.aliyuncs.com/compatible-mode/v1",
    }
    
    def __init__(
        self,
        model_id: str = "qwen-plus",
        api_key: str | None = None,
        region: Literal["china", "international", "us"] = "china",
        max_workers: int = 50,
        **default_options: Any,
    ) -> None:
        """
        åˆå§‹åŒ–QwenChatClient
        
        Args:
            model_id: æ¨¡å‹ID
                - æ–‡æœ¬:qwen-plus, qwen-max, qwen3-235b-a22b-instruct-2507
                - è§†è§‰:qwen3-vl-plus
            api_key: DashScope APIå¯†é’¥(é»˜è®¤ä»DASHSCOPE_API_KEYç¯å¢ƒå˜é‡)
            region: APIåŒºåŸŸ(china/international/us)
                âš ï¸ API Keyä¸regionå¿…é¡»åŒ¹é…,å¦åˆ™æŠ¥InvalidApiKey
            max_workers: å¼‚æ­¥çº¿ç¨‹æ± å¤§å°
            **default_options: é»˜è®¤é…ç½®
        """
        super().__init__(model_id=model_id)
        
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
        if not self.api_key:
            raise ValueError(
                "éœ€è¦æä¾›APIå¯†é’¥ã€‚é€šè¿‡api_keyå‚æ•°ä¼ å…¥æˆ–è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡"
            )
        
        if region not in self.ENDPOINTS:
            raise ValueError(
                f"æ— æ•ˆçš„region: {region}. å¯é€‰: {list(self.ENDPOINTS.keys())}"
            )
        
        self.base_url = self.ENDPOINTS[region]
        self.region = region
        self.default_options = default_options
        
        # åˆ›å»ºçº¿ç¨‹æ± ç”¨äºå¼‚æ­¥æ¡¥æ¥
        self._executor = ThreadPoolExecutor(max_workers=max_workers)
        
        logger.info(
            f"QwenChatClientåˆå§‹åŒ–: model={model_id}, region={region}, "
            f"endpoint={self.base_url}"
        )
    
    def _convert_messages_to_dashscope_format(
        self,
        messages: str | ChatMessage | list[str] | list[ChatMessage]
    ) -> list[dict[str, Any]]:
        """å°†Agent Frameworkæ¶ˆæ¯è½¬æ¢ä¸ºDashScopeæ ¼å¼"""
        if isinstance(messages, str):
            return [{"role": "user", "content": messages}]
        
        if isinstance(messages, ChatMessage):
            messages = [messages]
        
        dashscope_messages = []
        for msg in messages:
            if isinstance(msg, str):
                dashscope_messages.append({"role": "user", "content": msg})
                continue
            
            role = msg.role.value if hasattr(msg.role, 'value') else str(msg.role)
            
            # å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ
            if role == "tool" and msg.contents:
                for content in msg.contents:
                    if isinstance(content, ToolResultContent):
                        dashscope_messages.append({
                            "role": "tool",
                            "name": content.tool_call_id,
                            "content": content.result,
                        })
                continue
            
            # å¤„ç†æ™®é€šæ¶ˆæ¯å’Œå·¥å…·è°ƒç”¨
            content_text = ""
            tool_calls = []
            
            for content in msg.contents or []:
                if isinstance(content, TextContent):
                    content_text += content.text
                elif isinstance(content, ToolCallContent):
                    tool_calls.append({
                        "id": content.tool_call_id,
                        "type": "function",
                        "function": {
                            "name": content.tool_name,
                            "arguments": json.dumps(content.arguments) 
                                if isinstance(content.arguments, dict) 
                                else content.arguments,
                        }
                    })
            
            msg_dict = {"role": role, "content": content_text or None}
            if tool_calls:
                msg_dict["tool_calls"] = tool_calls
            
            dashscope_messages.append(msg_dict)
        
        return dashscope_messages
    
    def _build_request_params(
        self,
        messages: list[dict],
        options: QwenChatOptions | None = None
    ) -> dict[str, Any]:
        """æ„å»ºDashScope APIè¯·æ±‚å‚æ•°"""
        params = {
            "model": self.model_id,
            "messages": messages,
            "api_key": self.api_key,
        }
        
        # åˆå¹¶é»˜è®¤é€‰é¡¹å’Œä¼ å…¥é€‰é¡¹
        merged_options = {**self.default_options, **(options or {})}
        
        # æ˜ å°„æ ‡å‡†å‚æ•°
        if "temperature" in merged_options:
            params["temperature"] = merged_options["temperature"]
        if "top_p" in merged_options:
            params["top_p"] = merged_options["top_p"]
        if "max_tokens" in merged_options:
            params["max_tokens"] = merged_options["max_tokens"]
        
        # ğŸ”¥ Qwenç‰¹æœ‰å‚æ•°
        if "enable_thinking" in merged_options:
            params["enable_thinking"] = merged_options["enable_thinking"]
        
        if "thinking_budget" in merged_options:
            params["thinking_budget"] = merged_options["thinking_budget"]
        
        if "enable_search" in merged_options:
            params["enable_search"] = merged_options["enable_search"]
        
        if "seed" in merged_options:
            params["seed"] = merged_options["seed"]
        
        if "repetition_penalty" in merged_options:
            params["repetition_penalty"] = merged_options["repetition_penalty"]
        
        # è§†è§‰æ¨¡å‹ä¸“ç”¨å‚æ•°
        if "min_pixels" in merged_options:
            params["min_pixels"] = merged_options["min_pixels"]
        if "max_pixels" in merged_options:
            params["max_pixels"] = merged_options["max_pixels"]
        
        return params
    
    async def _inner_get_response(
        self,
        messages: str | ChatMessage | list[str] | list[ChatMessage],
        **options: Any,
    ) -> ChatResponse:
        """
        å†…éƒ¨éæµå¼å“åº”æ–¹æ³•
        
        âš ï¸ æ³¨æ„:å¯ç”¨æ€è€ƒæ¨¡å¼æ—¶,æ­¤æ–¹æ³•ä¼šå¤±è´¥!
        æ€è€ƒæ¨¡å¼å¿…é¡»ä½¿ç”¨æµå¼å“åº”,å¦åˆ™APIè¿”å›400é”™è¯¯
        """
        # ğŸ”¥ å…³é”®æ£€æŸ¥:æ€è€ƒæ¨¡å¼å¿…é¡»ä½¿ç”¨æµå¼
        if options.get("enable_thinking"):
            raise ValueError(
                "å¯ç”¨æ€è€ƒæ¨¡å¼(enable_thinking=True)æ—¶å¿…é¡»ä½¿ç”¨æµå¼å“åº”ã€‚"
                "è¯·ä½¿ç”¨get_streaming_response()æ–¹æ³•æˆ–Agent.run_stream()ã€‚"
                "åŸå› :æ€è€ƒè¿‡ç¨‹é•¿åº¦ä¸å¯æ§,éæµå¼è°ƒç”¨ä¼šå¯¼è‡´HTTPè¶…æ—¶ã€‚"
            )
        
        dashscope_messages = self._convert_messages_to_dashscope_format(messages)
        params = self._build_request_params(dashscope_messages, options)
        params["stream"] = False
        
        # å¼‚æ­¥æ¡¥æ¥:å°†åŒæ­¥è°ƒç”¨å¸è½½åˆ°çº¿ç¨‹æ± 
        response: GenerationResponse = await asyncio.get_running_loop().run_in_executor(
            self._executor,
            lambda: Generation.call(**params)
        )
        
        # æ£€æŸ¥é”™è¯¯
        if response.status_code != 200:
            raise RuntimeError(
                f"DashScope APIé”™è¯¯ (Code: {response.code}): {response.message}"
            )
        
        # è§£æå“åº”
        output = response.output
        choice = output.choices[0]
        message_data = choice.message
        
        contents = []
        
        # å¤„ç†æ–‡æœ¬å†…å®¹
        if message_data.content:
            contents.append(TextContent(text=message_data.content))
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if hasattr(message_data, "tool_calls") and message_data.tool_calls:
            for tool_call in message_data.tool_calls:
                contents.append(ToolCallContent(
                    tool_call_id=tool_call.id,
                    tool_name=tool_call.function.name,
                    arguments=json.loads(tool_call.function.arguments),
                ))
        
        response_message = ChatMessage(
            role=Role.ASSISTANT,
            contents=contents,
        )
        
        # æ„å»ºä½¿ç”¨ç»Ÿè®¡
        usage = None
        if hasattr(response, "usage") and response.usage:
            usage = UsageDetails(
                input_tokens=response.usage.input_tokens,
                output_tokens=response.usage.output_tokens,
            )
        
        return ChatResponse(
            messages=[response_message],
            response_id=response.request_id,
            usage=usage,
        )
    
    async def _inner_get_streaming_response(
        self,
        messages: str | ChatMessage | list[str] | list[ChatMessage],
        **options: Any,
    ) -> AsyncIterable[ChatResponseUpdate]:
        """
        å†…éƒ¨æµå¼å“åº”æ–¹æ³•
        
        å…³é”®ç‰¹æ€§:
        1. ğŸ”¥ å¼ºåˆ¶è®¾ç½®incremental_output=True(é¿å…UIé‡å¤æ˜¾ç¤º)
        2. ğŸ”¥ æ”¯æŒæ€è€ƒæ¨¡å¼(enable_thinking)
        3. ğŸ”¥ å­—æ®µåˆ†ç¦»:reasoning_content vs content
        """
        dashscope_messages = self._convert_messages_to_dashscope_format(messages)
        params = self._build_request_params(dashscope_messages, options)
        params["stream"] = True
        params["incremental_output"] = True  # ğŸ”¥ ç¡¬æ€§è¦æ±‚!é¿å…UIæ˜¾ç¤ºä¹±ç 
        
        # è®°å½•æ˜¯å¦éœ€è¦è¿”å›æ€è€ƒå†…å®¹
        include_reasoning = options.get("include_reasoning", False)
        
        # å¼‚æ­¥æ¡¥æ¥:è·å–æµå¼å“åº”ç”Ÿæˆå™¨
        def _call_stream():
            return Generation.call(**params)
        
        stream_generator = await asyncio.get_running_loop().run_in_executor(
            self._executor,
            _call_stream
        )
        
        # ç´¯ç§¯å·¥å…·è°ƒç”¨ä¿¡æ¯å’ŒTokenç»Ÿè®¡
        tool_calls_buffer: dict[int, dict] = {}
        thinking_tokens = 0
        output_tokens = 0
        
        for chunk in stream_generator:
            if chunk.status_code != 200:
                raise RuntimeError(
                    f"DashScopeæµå¼é”™è¯¯ (Code: {chunk.code}): {chunk.message}"
                )
            
            output = chunk.output
            if not output or not output.choices:
                continue
            
            choice = output.choices[0]
            delta = choice.message
            
            contents = []
            
            # ğŸ”¥ å¤„ç†æ€è€ƒå†…å®¹æµ(Qwen3ç‰¹æœ‰)
            if hasattr(delta, "reasoning_content") and delta.reasoning_content:
                thinking_tokens += len(delta.reasoning_content) // 4  # ç²—ç•¥ä¼°ç®—
                
                # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦è¿”å›æ€è€ƒå†…å®¹
                if include_reasoning:
                    contents.append(TextContent(
                        text=f"<thinking>{delta.reasoning_content}</thinking>"
                    ))
                # å¦åˆ™é™é»˜ä¸¢å¼ƒ(ç”¨æˆ·å·²ä¸ºæ­¤ä»˜è´¹,ä½†ä¸æƒ³çœ‹åˆ°)
            
            # å¤„ç†æ–‡æœ¬å†…å®¹æµ
            if delta.content:
                output_tokens += len(delta.content) // 4
                contents.append(TextContent(text=delta.content))
            
            # å¤„ç†å·¥å…·è°ƒç”¨æµ
            if hasattr(delta, "tool_calls") and delta.tool_calls:
                for tc in delta.tool_calls:
                    idx = tc.index if hasattr(tc, 'index') else 0
                    if idx not in tool_calls_buffer:
                        tool_calls_buffer[idx] = {
                            "id": "",
                            "name": "",
                            "arguments": ""
                        }
                    
                    if tc.id:
                        tool_calls_buffer[idx]["id"] += tc.id
                    if tc.function:
                        if tc.function.name:
                            tool_calls_buffer[idx]["name"] += tc.function.name
                        if tc.function.arguments:
                            tool_calls_buffer[idx]["arguments"] += tc.function.arguments
            
            if contents:
                yield ChatResponseUpdate(
                    contents=contents,
                    role=Role.ASSISTANT,
                    response_id=chunk.request_id,
                )
        
        # æµç»“æŸåè¾“å‡ºå®Œæ•´çš„å·¥å…·è°ƒç”¨
        if tool_calls_buffer:
            tool_contents = []
            for tc_data in tool_calls_buffer.values():
                try:
                    arguments = json.loads(tc_data["arguments"])
                except json.JSONDecodeError:
                    arguments = tc_data["arguments"]
                
                tool_contents.append(ToolCallContent(
                    tool_call_id=tc_data["id"],
                    tool_name=tc_data["name"],
                    arguments=arguments,
                ))
            
            yield ChatResponseUpdate(
                contents=tool_contents,
                role=Role.ASSISTANT,
            )
        
        # è®°å½•Tokenç»Ÿè®¡(ç”¨äºæˆæœ¬ç›‘æ§)
        if thinking_tokens > 0:
            logger.info(
                f"Tokenç»Ÿè®¡: Thinking={thinking_tokens}, "
                f"Output={output_tokens}, "
                f"Ratio={thinking_tokens/output_tokens:.2f}x"
            )
    
    def __del__(self):
        """æ¸…ç†çº¿ç¨‹æ± """
        if hasattr(self, '_executor'):
            self._executor.shutdown(wait=False)
```

### 3.3 ä½¿ç”¨ç¤ºä¾‹

#### åŸºç¡€å¯¹è¯

```python
import asyncio
from qwen_client import QwenChatClient, QwenChatOptions
from agent_framework import ChatAgent

async def main():
    client = QwenChatClient(
        model_id="qwen-plus",
        region="china"  # æˆ– "international"
    )
    
    agent = ChatAgent(
        chat_client=client,
        name="QwenAssistant",
        instructions="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚"
    )
    
    options = QwenChatOptions(
        temperature=0.7,
        seed=42
    )
    
    result = await agent.run(
        "è§£é‡Šä»€ä¹ˆæ˜¯Transformeræ¶æ„",
        additional_chat_options=options
    )
    print(result.text)

asyncio.run(main())
```

---

## å››ã€Qwen3æ€è€ƒæ¨¡å¼æ·±åº¦è§£æ

### 4.1 æ ¸å¿ƒæ¦‚å¿µ:"ç³»ç»Ÿ2"æ¨ç†

Qwen3çš„æ€è€ƒåŠŸèƒ½åŸºäºå¼ºåŒ–å­¦ä¹ è®­ç»ƒ,æ¨¡å‹åœ¨ç”Ÿæˆç­”æ¡ˆå‰ä¼šå…ˆç”Ÿæˆå†…éƒ¨æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®ç‰¹æ€§**:
- åŒæµè¾“å‡º:`reasoning_content`(æ€è€ƒ) + `content`(ç­”æ¡ˆ)
- è®¡è´¹å½±å“:æ€è€ƒTokenå¯èƒ½æ˜¯ç­”æ¡ˆçš„**3-10å€**
- å»¶è¿Ÿå¢åŠ :é¦–å­—ç”Ÿæˆæ—¶é—´(TTFT)æ˜¾è‘—æé«˜

### 4.2 æ€è€ƒæ¨¡å¼å®Œæ•´å‚æ•°

| å‚æ•° | ä½ç½® | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| **enable_thinking** | extra_body | Boolean | False | æ€è€ƒæ€»å¼€å…³ |
| **thinking_budget** | extra_body | Integer | è‡ªåŠ¨ | æ€è€ƒTokené¢„ç®—ä¸Šé™ |
| **stream** | æ ¹å‚æ•° | Boolean | - | **æ€è€ƒæ¨¡å¼å¿…é¡»ä¸ºTrue** |
| **include_reasoning** | å®¢æˆ·ç«¯ | Boolean | False | æ˜¯å¦åœ¨å“åº”ä¸­åŒ…å«æ€è€ƒå†…å®¹ |

### 4.3 ä½¿ç”¨åœºæ™¯å†³ç­–

```python
def choose_thinking_mode(query: str) -> QwenChatOptions:
    """æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ€è€ƒé…ç½®"""
    
    # ç®€å•ä»»åŠ¡ - å…³é—­æ€è€ƒ
    if is_simple_qa(query):
        return QwenChatOptions(
            enable_thinking=False,
            temperature=0.7
        )
    
    # ä¸­ç­‰å¤æ‚ - é™åˆ¶é¢„ç®—
    elif is_medium_task(query):
        return QwenChatOptions(
            enable_thinking=True,
            thinking_budget=1024,  # é™åˆ¶æˆæœ¬
            temperature=0.6
        )
    
    # é«˜å¤æ‚åº¦ - å……è¶³é¢„ç®—
    else:
        return QwenChatOptions(
            enable_thinking=True,
            thinking_budget=4096,  # æ·±åº¦æ€è€ƒ
            temperature=0.6,
            top_p=0.95
        )
```

### 4.4 å®Œæ•´ç¤ºä¾‹:å¯ç”¨æ€è€ƒä½†ä¸æ‰“å°

```python
async def thinking_hidden_example():
    """å¯ç”¨æ€è€ƒä½†åœ¨UIä¸­éšè—æ€è€ƒè¿‡ç¨‹"""
    
    client = QwenChatClient(model_id="qwen-plus")
    
    agent = ChatAgent(
        chat_client=client,
        name="DeepThinker",
        instructions="ä½ æ˜¯ä¸€ä¸ªå–„äºæ·±åº¦æ¨ç†çš„æ•°å­¦ä¸“å®¶ã€‚"
    )
    
    # é…ç½®:å¯ç”¨æ€è€ƒ,ä½†ä¸è¿”å›æ€è€ƒå†…å®¹
    options = QwenChatOptions(
        enable_thinking=True,
        thinking_budget=2048,
        include_reasoning=False,  # ğŸ”¥ ä¸åœ¨å“åº”ä¸­åŒ…å«æ€è€ƒ
        temperature=0.6
    )
    
    print("ç”¨æˆ·:è¯æ˜æ ¹å·2æ˜¯æ— ç†æ•°")
    print("Assistant(æ­£åœ¨æ·±åº¦æ€è€ƒ...): ", end="", flush=True)
    
    # æµå¼è¾“å‡º - åªæ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
    async for update in agent.run_stream(
        "è¯æ˜æ ¹å·2æ˜¯æ— ç†æ•°",
        additional_chat_options=options
    ):
        if update.text:
            print(update.text, end="", flush=True)
    
    print("\n")
    
    # âš ï¸ æ³¨æ„:è™½ç„¶ç”¨æˆ·æ²¡çœ‹åˆ°æ€è€ƒè¿‡ç¨‹,ä½†å·²ç»ä¸ºæ­¤ä»˜è´¹!
    # å¯ä»¥åœ¨åå°æ—¥å¿—ä¸­çœ‹åˆ°Tokenç»Ÿè®¡
```

### 4.5 ä¸ºä»€ä¹ˆä¸èƒ½åœ¨æœåŠ¡å™¨ç«¯å±è”½?

**æ¶æ„è®¾è®¡åŸå› **:
1. **è®¡è´¹é€æ˜æ€§**:æ€è€ƒTokenæ˜¯æˆæœ¬ä¸€éƒ¨åˆ†,å¿…é¡»è¿”å›ä½œä¸ºè®¡è´¹å‡­è¯
2. **è°ƒè¯•éœ€æ±‚**:å¼€å‘è€…éœ€è¦æŸ¥çœ‹æ¨ç†è¿‡ç¨‹æ’æŸ¥é”™è¯¯
3. **å­—æ®µåˆ†ç¦»**:reasoning_contentå’Œcontentç‰©ç†éš”ç¦»,å®¢æˆ·ç«¯è‡ªç”±é€‰æ‹©

**ç»“è®º**:
- âœ… APIä¸€å®šä¼šä¼ è¾“æ€è€ƒå†…å®¹
- âœ… å®¢æˆ·ç«¯å†³å®šæ˜¯å¦å±•ç¤º
- âœ… æ— è®ºæ˜¯å¦å±•ç¤º,éƒ½å·²ä»˜è´¹

---

## äº”ã€è§†è§‰æ¨¡å‹qwen3-vl-plusé›†æˆ

### 5.1 å›¾åƒå¤„ç†

```python
async def image_analysis():
    client = QwenChatClient(model_id="qwen3-vl-plus")
    
    agent = ChatAgent(chat_client=client, name="VisionAgent")
    
    # å›¾åƒæ¶ˆæ¯æ ¼å¼
    messages = [{
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": "https://example.com/chart.png"
                    # æˆ–ä½¿ç”¨Base64:"data:image/png;base64,iVBORw0KG..."
                }
            },
            {
                "type": "text",
                "text": "åˆ†æè¿™å¼ å›¾è¡¨çš„è¶‹åŠ¿"
            }
        ]
    }]
    
    # å¯ç”¨è§†è§‰æ¨ç†
    options = QwenChatOptions(
        enable_thinking=True,  # è§†è§‰æ¨ç†é“¾
        thinking_budget=3072,
        min_pixels=256 * 256,
        max_pixels=1280 * 1280
    )
    
    result = await agent.run(messages, additional_chat_options=options)
    print(result.text)
```

### 5.2 è§†é¢‘å¤„ç†(å®¢æˆ·ç«¯æŠ½å¸§)

```python
import cv2
import base64
from io import BytesIO
from PIL import Image

def extract_video_frames(
    video_path: str,
    max_frames: int = 512
) -> list[dict]:
    """
    ä»è§†é¢‘ä¸­æå–å¸§
    
    âš ï¸ é™åˆ¶:4-512å¸§
    """
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # è®¡ç®—é‡‡æ ·é—´éš”
    interval = max(1, total_frames // max_frames)
    
    frames = []
    frame_idx = 0
    
    while len(frames) < max_frames:
        ret, frame = cap.read()
        if not ret:
            break
        
        if frame_idx % interval == 0:
            # è½¬æ¢ä¸ºBase64
            _, buffer = cv2.imencode('.jpg', frame)
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            
            frames.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{img_base64}"
                }
            })
        
        frame_idx += 1
    
    cap.release()
    
    # éªŒè¯å¸§æ•°é™åˆ¶
    if len(frames) < 4:
        raise ValueError(f"è§†é¢‘è‡³å°‘éœ€è¦4å¸§,å½“å‰åªæœ‰{len(frames)}å¸§")
    if len(frames) > 512:
        frames = frames[:512]
    
    return frames

async def video_analysis():
    client = QwenChatClient(model_id="qwen3-vl-plus")
    agent = ChatAgent(chat_client=client, name="VideoAnalyzer")
    
    # æå–å¸§
    video_frames = extract_video_frames("demo.mp4", max_frames=128)
    
    messages = [{
        "role": "user",
        "content": video_frames + [{
            "type": "text",
            "text": "æ€»ç»“è¿™ä¸ªè§†é¢‘çš„å†…å®¹"
        }]
    }]
    
    options = QwenChatOptions(
        enable_thinking=True,
        thinking_budget=5120,  # è§†é¢‘åˆ†æéœ€è¦æ›´å¤šé¢„ç®—
        temperature=0.7
    )
    
    print("æ­£åœ¨åˆ†æè§†é¢‘(å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´)...")
    
    async for update in agent.run_stream(messages, additional_chat_options=options):
        if update.text:
            print(update.text, end="", flush=True)
```

---

## å…­ã€æˆæœ¬æ§åˆ¶ä¸Tokenç›‘æ§

### 6.1 Tokenç»„æˆåˆ†æ

```
æ€»æˆæœ¬ = (Input Tokens Ã— è¾“å…¥å•ä»·) + 
         (Reasoning Tokens Ã— è¾“å‡ºå•ä»·) + 
         (Output Tokens Ã— è¾“å‡ºå•ä»·)
```

**å…³é”®äº‹å®**:
- Reasoning Tokens**ç­‰åŒäºOutput Tokensè®¡è´¹**
- æ€è€ƒå†…å®¹é€šå¸¸æ˜¯ç­”æ¡ˆçš„**3-10å€**é•¿åº¦
- å³ä½¿`include_reasoning=False`,ä»ç„¶è®¡è´¹

### 6.2 æˆæœ¬ç›‘æ§ä¸­é—´ä»¶

```python
from agent_framework import agent_middleware, AgentRunContext
import logging

logger = logging.getLogger(__name__)

@agent_middleware
async def token_accounting_middleware(ctx: AgentRunContext, next_mw):
    """å…¨å±€Tokenå®¡è®¡ä¸­é—´ä»¶"""
    
    result = await next_mw(ctx)
    
    if result and result.usage:
        usage = result.usage
        total_cost = (
            usage.input_tokens * 0.0004 +  # å‡è®¾å•ä»·(ç¾å…ƒ/åƒToken)
            usage.output_tokens * 0.0012
        )
        
        logger.warning(
            f"[Tokenå®¡è®¡] Agent={ctx.agent.name} | "
            f"Input={usage.input_tokens} | "
            f"Output={usage.output_tokens} | "
            f"Total={usage.total_tokens} | "
            f"Cost=${total_cost:.4f}"
        )
        
        # å¯é€‰:å†™å…¥ç›‘æ§ç³»ç»Ÿ
        # prometheus_client.Counter('qwen_tokens_total').inc(usage.total_tokens)
        # prometheus_client.Gauge('qwen_cost_usd').set(total_cost)
        
        # é¢„ç®—ä¿æŠ¤
        if usage.total_tokens > 10000:
            logger.error(f"Tokenä½¿ç”¨è¶…æ ‡!Agent={ctx.agent.name}")
    
    return result

# åº”ç”¨ä¸­é—´ä»¶
agent = ChatAgent(
    chat_client=qwen_client,
    middlewares=[token_accounting_middleware]
)
```

### 6.3 åŠ¨æ€é¢„ç®—æ§åˆ¶

```python
class AdaptiveThinkingBudget:
    """è‡ªé€‚åº”æ€è€ƒé¢„ç®—æ§åˆ¶å™¨"""
    
    def __init__(self, max_daily_budget: int = 100000):
        self.max_daily_budget = max_daily_budget
        self.today_used = 0
    
    def get_budget(self, query_complexity: str) -> int:
        """æ ¹æ®å‰©ä½™é¢„ç®—å’Œä»»åŠ¡å¤æ‚åº¦è¿”å›å»ºè®®é¢„ç®—"""
        
        remaining = self.max_daily_budget - self.today_used
        
        if remaining < 1000:
            return 0  # å…³é—­æ€è€ƒ
        
        budgets = {
            "simple": 512,
            "medium": 1024,
            "complex": 2048
        }
        
        suggested = budgets.get(query_complexity, 1024)
        return min(suggested, remaining // 10)  # ä¿å®ˆåˆ†é…
    
    def record_usage(self, tokens: int):
        """è®°å½•ä½¿ç”¨é‡"""
        self.today_used += tokens

# ä½¿ç”¨
budget_controller = AdaptiveThinkingBudget(max_daily_budget=100000)

async def smart_query(query: str):
    complexity = analyze_complexity(query)
    budget = budget_controller.get_budget(complexity)
    
    options = QwenChatOptions(
        enable_thinking=budget > 0,
        thinking_budget=budget if budget > 0 else None
    )
    
    result = await agent.run(query, additional_chat_options=options)
    
    if result.usage:
        budget_controller.record_usage(result.usage.total_tokens)
    
    return result
```

---

## ä¸ƒã€å¸¸è§é—®é¢˜æ’æŸ¥

### Q1: å¯ç”¨æ€è€ƒæ—¶æŠ¥400é”™è¯¯

**é”™è¯¯ä¿¡æ¯**:
```
parameter.enable_thinking must be set to false for non-streaming calls
```

**åŸå› **: æ€è€ƒæ¨¡å¼å¿…é¡»ä½¿ç”¨æµå¼å“åº”

**è§£å†³**:
```python
# âŒ é”™è¯¯
result = await agent.run(query, enable_thinking=True)

# âœ… æ­£ç¡®
async for update in agent.run_stream(query, enable_thinking=True):
    print(update.text, end="")
```

---

### Q2: æµå¼è¾“å‡ºæ˜¾ç¤ºé‡å¤æ–‡æœ¬

**ç—‡çŠ¶**: UIæ˜¾ç¤º"HelloHello worldHello world!"

**åŸå› **: æ²¡æœ‰è®¾ç½®`incremental_output=True`

**è§£å†³**: QwenClientå·²å¼ºåˆ¶è®¾ç½®,æ£€æŸ¥æ˜¯å¦è¢«è¦†ç›–
```python
params["incremental_output"] = True  # åœ¨ä»£ç ä¸­ç¡®è®¤æ­¤è¡Œå­˜åœ¨
```

---

### Q3: API KeyæŠ¥é”™

**é”™è¯¯**: InvalidApiKey

**åŸå› **: API Keyä¸regionä¸åŒ¹é…

**è§£å†³**:
```python
# æ£€æŸ¥Keyæ¥æº
# ä¸­å›½ç«™Key: åœ¨dashscope.aliyuncs.comç”³è¯·
# å›½é™…ç«™Key: åœ¨dashscope-intl.aliyuncs.comç”³è¯·

client = QwenChatClient(
    api_key="sk-...",  # ç¡®è®¤Keyæ¥æº
    region="china"     # ç¡®ä¿regionåŒ¹é…
)
```

---

### Q4: è§†é¢‘å¤„ç†å¤±è´¥

**é”™è¯¯**: Exceeded image/video frame limit

**åŸå› **: å¸§æ•°ä¸åœ¨4-512èŒƒå›´å†…

**è§£å†³**:
```python
frames = extract_frames(video)

# éªŒè¯
if len(frames) < 4:
    raise ValueError("è‡³å°‘éœ€è¦4å¸§")
if len(frames) > 512:
    frames = frames[:512]  # æˆªæ–­
```

---

## å…«ã€ç”Ÿäº§ç¯å¢ƒæ£€æŸ¥æ¸…å•

### éƒ¨ç½²å‰æ ¸å¯¹

- [ ] âœ… ä½¿ç”¨BaseChatClient(è·å¾—ä¸­é—´ä»¶å’Œé¥æµ‹)
- [ ] âœ… é…ç½®TypedDictå¼ºç±»å‹å‚æ•°
- [ ] âœ… è®¾ç½®`incremental_output=True`
- [ ] âœ… æ€è€ƒæ¨¡å¼ä½¿ç”¨æµå¼å“åº”
- [ ] âœ… é…ç½®Tokenç›‘æ§ä¸­é—´ä»¶
- [ ] âœ… è®¾ç½®`thinking_budget`é™åˆ¶æˆæœ¬
- [ ] âœ… é…ç½®OpenTelemetryå¯¼å‡º
- [ ] âœ… éªŒè¯API Keyä¸regionåŒ¹é…
- [ ] âœ… å®ç°é”™è¯¯é‡è¯•æœºåˆ¶
- [ ] âœ… æ·»åŠ é€Ÿç‡é™åˆ¶ä¿æŠ¤

---

## ä¹ã€æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. âœ… **ç»§æ‰¿BaseChatClient**:ç”Ÿäº§ç¯å¢ƒå¿…éœ€
2. âœ… **TypedDicté…ç½®**:v1.0.0b260127æ ‡å‡†
3. âœ… **incremental_output=True**:æµå¼å¿…éœ€
4. âœ… **stream=True**:æ€è€ƒæ¨¡å¼ç¡¬æ€§è¦æ±‚
5. âœ… **thinking_budget**:æˆæœ¬æ§åˆ¶å…³é”®
6. âœ… **å­—æ®µåˆ†ç¦»**:reasoning_contentå®¢æˆ·ç«¯è¿‡æ»¤
7. âœ… **å¼‚æ­¥æ¡¥æ¥**:asyncio.to_threadé¿å…é˜»å¡
8. âœ… **Tokenç›‘æ§**:ä¸­é—´ä»¶å®ç°å®¡è®¡

### å®æ–½è·¯å¾„

**é˜¶æ®µ1:å¿«é€ŸéªŒè¯(1å¤©)**
- ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼
- éªŒè¯åŸºç¡€åŠŸèƒ½

**é˜¶æ®µ2:ç”Ÿäº§å‡†å¤‡(3-5å¤©)**
- å®ç°å®Œæ•´QwenClient
- æ·»åŠ TypedDicté…ç½®
- é›†æˆç›‘æ§å’Œä¸­é—´ä»¶

**é˜¶æ®µ3:ä¼˜åŒ–è¿­ä»£(æŒç»­)**
- è°ƒæ•´thinking_budget
- ä¼˜åŒ–æˆæœ¬æ§åˆ¶
- æ ¹æ®è¿½è¸ªä¼˜åŒ–Prompt

---

**å‚è€ƒæ–‡æ¡£**:
- Microsoft Agent Framework: https://learn.microsoft.com/en-us/agent-framework
- DashScope API: https://www.alibabacloud.com/help/en/model-studio
- Qwen3æŠ€æœ¯åšå®¢: https://qwenlm.github.io
