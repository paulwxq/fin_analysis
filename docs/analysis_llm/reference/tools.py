"""
å·¥å…·å‡½æ•°æ¨¡å—
å®šä¹‰å„Agentä½¿ç”¨çš„å·¥å…·å‡½æ•°
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from pathlib import Path
import json

from agent_framework.tools import Tool, web_search
from database import StockDatabase


# ========== StockDataAgent å·¥å…· ==========

def query_stock_kline_tool(db: StockDatabase) -> Tool:
    """åˆ›å»ºæŸ¥è¯¢Kçº¿æ•°æ®çš„å·¥å…·"""
    
    async def query_stock_kline(
        code: str,
        months: int = 12
    ) -> str:
        """
        ä»æ•°æ®åº“æŸ¥è¯¢è‚¡ç¥¨çš„æœˆKçº¿æ•°æ®
        
        Args:
            code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "300444.SZ"
            months: æŸ¥è¯¢æœ€è¿‘å‡ ä¸ªæœˆçš„æ•°æ®ï¼Œé»˜è®¤12ä¸ªæœˆ
            
        Returns:
            JSONæ ¼å¼çš„Kçº¿æ•°æ®
        """
        try:
            df = await db.query_kline_data(code, months)
            
            if df.empty:
                return json.dumps({
                    "success": False,
                    "message": f"æœªæ‰¾åˆ°è‚¡ç¥¨ {code} çš„æ•°æ®",
                    "data": None
                }, ensure_ascii=False)
            
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            data_dict = {
                "success": True,
                "code": code,
                "name": df.iloc[0]['name'] if not df.empty else "",
                "records": len(df),
                "start_month": str(df.iloc[0]['month']),
                "end_month": str(df.iloc[-1]['month']),
                "data": df.to_dict('records')
            }
            
            return json.dumps(data_dict, ensure_ascii=False, default=str)
            
        except Exception as e:
            return json.dumps({
                "success": False,
                "message": f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
                "data": None
            }, ensure_ascii=False)
    
    return Tool(
        function=query_stock_kline,
        name="query_stock_kline",
        description="ä»PostgreSQLæ•°æ®åº“æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨çš„æœˆKçº¿å†å²æ•°æ®"
    )


def calculate_indicators_tool() -> Tool:
    """åˆ›å»ºè®¡ç®—æŠ€æœ¯æŒ‡æ ‡çš„å·¥å…·"""
    
    async def calculate_indicators(kline_data_json: str) -> str:
        """
        åŸºäºKçº¿æ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        
        Args:
            kline_data_json: Kçº¿æ•°æ®çš„JSONå­—ç¬¦ä¸²ï¼ˆæ¥è‡ªquery_stock_klineï¼‰
            
        Returns:
            JSONæ ¼å¼çš„æŠ€æœ¯æŒ‡æ ‡
        """
        try:
            data = json.loads(kline_data_json)
            
            if not data.get('success') or not data.get('data'):
                return json.dumps({
                    "success": False,
                    "message": "è¾“å…¥æ•°æ®æ— æ•ˆ"
                }, ensure_ascii=False)
            
            df = pd.DataFrame(data['data'])
            
            # è½¬æ¢æ•°æ®ç±»å‹
            for col in ['open', 'high', 'low', 'close', 'volume']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # è¯†åˆ«å¹³åº•é”…ç‰¹å¾
            peak_idx = df['close'].idxmax()
            peak_price = float(df.loc[peak_idx, 'close'])
            peak_time = str(df.loc[peak_idx, 'month'])
            current_price = float(df.iloc[-1]['close'])
            
            # éœ‡è¡æœŸæ•°æ®
            oscillation_df = df[df.index > peak_idx] if peak_idx < len(df) - 1 else df.tail(6)
            
            # è®¡ç®—æŒ¯å¹…
            if not oscillation_df.empty:
                volatility = float(
                    (oscillation_df['high'] - oscillation_df['low']).mean() / 
                    oscillation_df['close'].mean()
                )
            else:
                volatility = 0.0
            
            # æˆäº¤é‡è¶‹åŠ¿
            if len(oscillation_df) >= 6:
                recent_volume = oscillation_df['volume'].iloc[-3:].mean()
                earlier_volume = oscillation_df['volume'].iloc[-6:-3].mean()
                volume_trend = "é€’å¢" if recent_volume > earlier_volume * 1.1 else \
                              "é€’å‡" if recent_volume < earlier_volume * 0.9 else "å¹³ç¨³"
            else:
                volume_trend = "æ•°æ®ä¸è¶³"
            
            # å½“å‰ä½ç½®
            if not oscillation_df.empty:
                osc_high = float(oscillation_df['high'].max())
                osc_low = float(oscillation_df['low'].min())
                position_pct = (current_price - osc_low) / (osc_high - osc_low) * 100 if osc_high > osc_low else 50
                
                if position_pct < 33:
                    position = "ä½ä½"
                elif position_pct > 67:
                    position = "é«˜ä½"
                else:
                    position = "ä¸­ä½"
            else:
                position = "æ— æ³•åˆ¤æ–­"
                osc_high = current_price
                osc_low = current_price
            
            # åˆ¤æ–­æ˜¯å¦ç¬¦åˆå¹³åº•é”…ç‰¹å¾
            is_pan_bottom = (
                volatility < 0.15 and  # æŒ¯å¹…å°äº15%
                len(oscillation_df) >= 6 and  # è‡³å°‘éœ‡è¡6ä¸ªæœˆ
                (peak_price - current_price) / peak_price > 0.3  # ä»å³°å€¼å›è½è¶…è¿‡30%
            )
            
            indicators = {
                "success": True,
                "pan_bottom_features": {
                    "is_pan_bottom": is_pan_bottom,
                    "peak_price": peak_price,
                    "peak_time": peak_time,
                    "current_price": current_price,
                    "price_drop_pct": round((current_price - peak_price) / peak_price * 100, 2),
                    "oscillation_months": len(oscillation_df),
                    "oscillation_range": {
                        "high": float(osc_high),
                        "low": float(osc_low)
                    }
                },
                "technical_indicators": {
                    "volatility": round(volatility, 4),
                    "volume_trend": volume_trend,
                    "current_position": position
                },
                "summary": f"è¯¥è‚¡ç¥¨ä»{peak_time}çš„å³°å€¼{peak_price}å…ƒå›è½è‡³å½“å‰{current_price}å…ƒï¼Œ"
                          f"åœ¨éœ‡è¡åŒºé—´({osc_low:.2f}-{osc_high:.2f}å…ƒ)å†…å·²éœ‡è¡{len(oscillation_df)}ä¸ªæœˆï¼Œ"
                          f"æŒ¯å¹…{volatility*100:.1f}%ï¼Œæˆäº¤é‡{volume_trend}ï¼Œå½“å‰å¤„äºéœ‡è¡åŒºé—´{position}ã€‚"
            }
            
            return json.dumps(indicators, ensure_ascii=False)
            
        except Exception as e:
            return json.dumps({
                "success": False,
                "message": f"è®¡ç®—å¤±è´¥: {str(e)}"
            }, ensure_ascii=False)
    
    return Tool(
        function=calculate_indicators,
        name="calculate_indicators",
        description="åŸºäºKçº¿æ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å’Œå¹³åº•é”…å½¢æ€ç‰¹å¾"
    )


# ========== SectorResearchAgent å·¥å…· ==========

def web_search_tool() -> Tool:
    """Webæœç´¢å·¥å…·ï¼ˆä½¿ç”¨MAFå†…ç½®ï¼‰"""
    return web_search


def search_sectors_tool() -> Tool:
    """åˆ›å»ºæœç´¢è‚¡ç¥¨æ‰€å±æ¿å—çš„å·¥å…·"""
    
    async def search_sectors(
        stock_code: str,
        stock_name: str
    ) -> str:
        """
        æœç´¢è‚¡ç¥¨æ‰€å±çš„è¡Œä¸šæ¿å—å’Œæ¦‚å¿µæ¿å—
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            
        Returns:
            JSONæ ¼å¼çš„æ¿å—ä¿¡æ¯
        """
        # è¿™é‡Œå®é™…åº”è¯¥è°ƒç”¨web_searchï¼Œè¿™é‡Œæä¾›æ¡†æ¶
        # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼ŒAgentä¼šè‡ªå·±è°ƒç”¨web_search
        
        return json.dumps({
            "message": "è¯·ä½¿ç”¨web_searchå·¥å…·æœç´¢ä»¥ä¸‹å…³é”®è¯:",
            "search_queries": [
                f"{stock_name} æ‰€å±æ¿å—",
                f"{stock_name} è¡Œä¸šåˆ†ç±»",
                f"{stock_name} æ¦‚å¿µè‚¡",
                f"{stock_code} æ¿å—"
            ],
            "tips": "ä»æœç´¢ç»“æœä¸­æå–ä¸»æ¿å—ï¼ˆå¦‚'æ–°èƒ½æº'ã€'åŠå¯¼ä½“'ï¼‰å’Œæ¦‚å¿µæ¿å—ï¼ˆå¦‚'ç¢³ä¸­å’Œ'ã€'å·¥ä¸š4.0'ï¼‰"
        }, ensure_ascii=False)
    
    return Tool(
        function=search_sectors,
        name="search_sectors",
        description="ç”Ÿæˆæœç´¢è‚¡ç¥¨æ‰€å±æ¿å—çš„æŸ¥è¯¢å»ºè®®"
    )


def analyze_sector_hotness_tool() -> Tool:
    """åˆ›å»ºåˆ†ææ¿å—çƒ­åº¦çš„å·¥å…·"""
    
    async def analyze_sector_hotness(
        sector_name: str,
        months: int = 6
    ) -> str:
        """
        åˆ†ææ¿å—çš„çƒ­åº¦è¶‹åŠ¿
        
        Args:
            sector_name: æ¿å—åç§°
            months: åˆ†ææœ€è¿‘å‡ ä¸ªæœˆ
            
        Returns:
            æ¿å—çƒ­åº¦åˆ†æå»ºè®®
        """
        current_year = datetime.now().year
        previous_year = current_year - 1
        
        return json.dumps({
            "message": f"è¯·ä½¿ç”¨web_searchå·¥å…·æœç´¢ä»¥ä¸‹å…³é”®è¯æ¥åˆ†æ'{sector_name}'æ¿å—çƒ­åº¦:",
            "search_queries": [
                f"{sector_name}æ¿å— {current_year} è¶‹åŠ¿",
                f"{sector_name} æ”¿ç­–æ”¯æŒ {previous_year} {current_year}",
                f"{sector_name} é¾™å¤´è‚¡ æ¶¨å¹…",
                f"{sector_name}è¡Œä¸š æŠ•èµ„æœºä¼š"
            ],
            "analysis_framework": {
                "æ–°é—»çƒ­åº¦": "ç»Ÿè®¡æœ€è¿‘3-6ä¸ªæœˆçš„ç›¸å…³æ–°é—»æ•°é‡å’Œè´¨é‡",
                "æ”¿ç­–æ”¯æŒ": "æŸ¥æ‰¾å›½å®¶æˆ–åœ°æ–¹æ”¿ç­–ã€äº§ä¸šè§„åˆ’",
                "èµ„é‡‘æµå‘": "è§‚å¯Ÿæ¿å—å†…é¾™å¤´è‚¡çš„è¡¨ç°å’Œæˆäº¤é‡",
                "è¡Œä¸šæ™¯æ°”åº¦": "å…³æ³¨è¡Œä¸šè®¢å•ã€ä¸šç»©å¢é•¿ç­‰æ•°æ®"
            },
            "scoring_guide": {
                "8-10åˆ†": "å¤šé‡æ”¿ç­–åˆ©å¥½ + é¾™å¤´è‚¡å¤§æ¶¨ + åª’ä½“é«˜åº¦å…³æ³¨",
                "5-7åˆ†": "æœ‰ä¸€å®šæ”¯æŒ + è¡Œä¸šç¨³å®šå‘å±•",
                "1-4åˆ†": "ç¼ºä¹å…³æ³¨ + æ”¿ç­–æ”¯æŒå¼± + èµ„é‡‘æµå‡º"
            }
        }, ensure_ascii=False)
    
    return Tool(
        function=analyze_sector_hotness,
        name="analyze_sector_hotness",
        description="ç”Ÿæˆåˆ†ææ¿å—çƒ­åº¦çš„æœç´¢ç­–ç•¥å’Œè¯„åˆ†æŒ‡å—"
    )


# ========== CompanyResearchAgent å·¥å…· ==========

def search_company_news_tool() -> Tool:
    """åˆ›å»ºæœç´¢å…¬å¸æ–°é—»çš„å·¥å…·"""
    
    async def search_company_news(
        stock_code: str,
        stock_name: str,
        months: int = 6
    ) -> str:
        """
        ç”Ÿæˆæœç´¢å…¬å¸æ–°é—»çš„æŸ¥è¯¢ç­–ç•¥
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: å…¬å¸åç§°
            months: æœç´¢æœ€è¿‘å‡ ä¸ªæœˆ
            
        Returns:
            æœç´¢ç­–ç•¥å»ºè®®
        """
        current_year = datetime.now().year
        
        return json.dumps({
            "message": f"è¯·ä½¿ç”¨web_searchå·¥å…·æœç´¢ä»¥ä¸‹å…³é”®è¯æ¥è°ƒç ”{stock_name}:",
            "search_categories": {
                "è´¢åŠ¡ä¿¡æ¯": [
                    f"{stock_name} è´¢æŠ¥ {current_year}",
                    f"{stock_name} ä¸šç»©é¢„å‘Š",
                    f"{stock_code} è¥æ”¶ å‡€åˆ©æ¶¦"
                ],
                "é‡å¤§äº‹ä»¶": [
                    f"{stock_name} é‡å¤§åˆåŒ {current_year}",
                    f"{stock_name} æ–°äº§å“ æ–°æŠ€æœ¯",
                    f"{stock_name} å¹¶è´­ åˆä½œ"
                ],
                "ç«äº‰åœ°ä½": [
                    f"{stock_name} å¸‚åœºä»½é¢",
                    f"{stock_name} è¡Œä¸šåœ°ä½ æ’å",
                    f"{stock_name} ç«äº‰å¯¹æ‰‹"
                ],
                "é£é™©å› ç´ ": [
                    f"{stock_name} è´Ÿé¢æ–°é—»",
                    f"{stock_name} è¯‰è®¼ å¤„ç½š",
                    f"{stock_name} é£é™©æç¤º"
                ]
            },
            "catalyst_checklist": [
                "é‡å¤§åˆåŒç­¾è®¢ï¼ˆç‰¹åˆ«æ˜¯è¶…è¿‡å¹´è¥æ”¶10%çš„è®¢å•ï¼‰",
                "æ–°äº§å“å‘å¸ƒï¼ˆæŠ€æœ¯çªç ´ã€å¸‚åœºå‰æ™¯å¥½ï¼‰",
                "ä¸šç»©è¶…é¢„æœŸï¼ˆå¢é•¿ç‡æ˜¾è‘—é«˜äºè¡Œä¸šå¹³å‡ï¼‰",
                "æ”¿ç­–å€¾æ–œï¼ˆè·å¾—æ”¿åºœè¡¥è´´ã€é¡¹ç›®æ”¯æŒï¼‰",
                "èµ„äº§æ³¨å…¥ï¼ˆå¤§è‚¡ä¸œæ³¨å…¥ä¼˜è´¨èµ„äº§ï¼‰",
                "ç®¡ç†å±‚å¢æŒï¼ˆè¡¨æ˜å†…éƒ¨çœ‹å¥½ï¼‰"
            ],
            "evaluation_framework": {
                "è´¢åŠ¡å¥åº·": "è¥æ”¶å’Œåˆ©æ¶¦æ˜¯å¦æŒç»­å¢é•¿",
                "äº‹ä»¶å½±å“": "é‡å¤§äº‹ä»¶å¯¹æœªæ¥ä¸šç»©çš„æå‡ç¨‹åº¦",
                "ç«äº‰ä¼˜åŠ¿": "æ˜¯å¦æœ‰ç‹¬ç‰¹æŠ€æœ¯æˆ–å¸‚åœºåœ°ä½",
                "é£é™©ç¨‹åº¦": "æ˜¯å¦å­˜åœ¨é‡å¤§ä¸ç¡®å®šæ€§"
            }
        }, ensure_ascii=False)
    
    return Tool(
        function=search_company_news,
        name="search_company_news",
        description="ç”Ÿæˆæœç´¢å…¬å¸æ–°é—»å’ŒåŸºæœ¬é¢ä¿¡æ¯çš„æŸ¥è¯¢ç­–ç•¥"
    )


# ========== TechnicalAnalystAgent å·¥å…· ==========

def analyze_kline_image_tool() -> Tool:
    """åˆ›å»ºåˆ†æKçº¿å›¾ç‰‡çš„å·¥å…·"""
    
    async def analyze_kline_image(
        image_path: str
    ) -> str:
        """
        åˆ†æKçº¿å›¾å›¾ç‰‡ï¼ˆå¦‚æœæä¾›ï¼‰
        
        Args:
            image_path: Kçº¿å›¾PNGæ–‡ä»¶è·¯å¾„
            
        Returns:
            å›¾ç‰‡åˆ†æç»“æœ
        """
        # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šä½¿ç”¨GPT-4oçš„visionèƒ½åŠ›
        # æˆ–å…¶ä»–å›¾åƒè¯†åˆ«æ¨¡å‹
        
        if not Path(image_path).exists():
            return json.dumps({
                "success": False,
                "message": f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"
            }, ensure_ascii=False)
        
        return json.dumps({
            "success": True,
            "message": "å›¾ç‰‡åˆ†æåŠŸèƒ½éœ€è¦visionæ¨¡å‹æ”¯æŒ",
            "tip": "å»ºè®®åŸºäºKçº¿æ•°æ®è¿›è¡ŒæŠ€æœ¯åˆ†æï¼Œæ•ˆæœæ›´å¯é "
        }, ensure_ascii=False)
    
    return Tool(
        function=analyze_kline_image,
        name="analyze_kline_image",
        description="åˆ†æPNGæ ¼å¼çš„Kçº¿å›¾ï¼ˆéœ€è¦visionæ¨¡å‹æ”¯æŒï¼‰"
    )


def calculate_support_resistance_tool() -> Tool:
    """åˆ›å»ºè®¡ç®—æ”¯æ’‘é˜»åŠ›ä½çš„å·¥å…·"""
    
    async def calculate_support_resistance(
        kline_data_json: str,
        sector_hotness_score: float = 5.0,
        has_catalyst: bool = False
    ) -> str:
        """
        è®¡ç®—æ”¯æ’‘ä½ã€é˜»åŠ›ä½å’Œçªç ´æ¦‚ç‡
        
        Args:
            kline_data_json: Kçº¿æ•°æ®JSON
            sector_hotness_score: æ¿å—çƒ­åº¦è¯„åˆ†(0-10)
            has_catalyst: æ˜¯å¦æœ‰é‡å¤§å‚¬åŒ–å‰‚
            
        Returns:
            æŠ€æœ¯åˆ†æç»“æœ
        """
        try:
            data = json.loads(kline_data_json)
            
            if not data.get('success') or not data.get('data'):
                return json.dumps({
                    "success": False,
                    "message": "è¾“å…¥æ•°æ®æ— æ•ˆ"
                }, ensure_ascii=False)
            
            df = pd.DataFrame(data['data'])
            
            for col in ['open', 'high', 'low', 'close']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # æ‰¾åˆ°å³°å€¼åçš„éœ‡è¡åŒºé—´
            peak_idx = df['close'].idxmax()
            oscillation_df = df[df.index > peak_idx] if peak_idx < len(df) - 1 else df.tail(12)
            
            if oscillation_df.empty:
                oscillation_df = df.tail(6)
            
            # è®¡ç®—æ”¯æ’‘ä½å’Œé˜»åŠ›ä½
            support_level = float(oscillation_df['low'].min())
            resistance_level = float(oscillation_df['high'].max())
            current_price = float(df.iloc[-1]['close'])
            
            # å½¢æ€æˆç†Ÿåº¦è¯„åˆ†ï¼ˆ0-10ï¼‰
            oscillation_months = len(oscillation_df)
            if oscillation_months >= 18:
                maturity_score = 10
            elif oscillation_months >= 12:
                maturity_score = 7
            elif oscillation_months >= 6:
                maturity_score = 5
            else:
                maturity_score = 3
            
            # æˆäº¤é‡è¯„åˆ†ï¼ˆ0-10ï¼‰
            if len(oscillation_df) >= 6:
                recent_volume = oscillation_df['volume'].iloc[-3:].mean()
                earlier_volume = oscillation_df['volume'].iloc[-6:-3].mean()
                
                if recent_volume > earlier_volume * 1.3:
                    volume_score = 8  # æ˜æ˜¾æ”¾é‡
                elif recent_volume > earlier_volume * 1.1:
                    volume_score = 6  # æ¸©å’Œæ”¾é‡
                elif recent_volume > earlier_volume * 0.9:
                    volume_score = 5  # å¹³ç¨³
                else:
                    volume_score = 3  # ç¼©é‡
            else:
                volume_score = 5
            
            # è®¡ç®—çªç ´æ¦‚ç‡
            # æƒé‡ï¼šå½¢æ€æˆç†Ÿåº¦30%ï¼Œæ¿å—çƒ­åº¦40%ï¼Œå‚¬åŒ–å‰‚30%
            catalyst_score = 8 if has_catalyst else 3
            
            breakout_probability = (
                maturity_score * 0.3 +
                sector_hotness_score * 0.4 +
                catalyst_score * 0.3
            ) * 10  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            
            breakout_probability = min(95, max(10, breakout_probability))  # é™åˆ¶åœ¨10-95%
            
            # ç›®æ ‡ä»·ä½ï¼ˆå‡è®¾çªç ´åä¸Šæ¶¨ç©ºé—´ï¼‰
            if breakout_probability > 70:
                upside_potential = 0.3  # 30%ä¸Šæ¶¨ç©ºé—´
            elif breakout_probability > 50:
                upside_potential = 0.2
            else:
                upside_potential = 0.1
            
            target_price = resistance_level * (1 + upside_potential)
            
            result = {
                "success": True,
                "support_level": round(support_level, 2),
                "resistance_level": round(resistance_level, 2),
                "current_price": round(current_price, 2),
                "technical_scores": {
                    "maturity_score": maturity_score,
                    "volume_score": volume_score,
                    "sector_score": sector_hotness_score,
                    "catalyst_score": catalyst_score
                },
                "breakout_analysis": {
                    "probability_pct": round(breakout_probability, 1),
                    "target_price": round(target_price, 2),
                    "upside_potential_pct": round(upside_potential * 100, 1)
                },
                "summary": f"å½“å‰ä»·æ ¼{current_price:.2f}å…ƒï¼Œæ”¯æ’‘ä½{support_level:.2f}å…ƒï¼Œ"
                          f"é˜»åŠ›ä½{resistance_level:.2f}å…ƒã€‚"
                          f"ç»¼åˆå½¢æ€æˆç†Ÿåº¦ã€æ¿å—çƒ­åº¦å’Œå‚¬åŒ–å‰‚å› ç´ ï¼Œ"
                          f"é¢„è®¡6ä¸ªæœˆå†…çªç ´é˜»åŠ›ä½çš„æ¦‚ç‡ä¸º{breakout_probability:.0f}%ã€‚"
            }
            
            return json.dumps(result, ensure_ascii=False)
            
        except Exception as e:
            return json.dumps({
                "success": False,
                "message": f"è®¡ç®—å¤±è´¥: {str(e)}"
            }, ensure_ascii=False)
    
    return Tool(
        function=calculate_support_resistance,
        name="calculate_support_resistance",
        description="è®¡ç®—æ”¯æ’‘ä½ã€é˜»åŠ›ä½å’Œå‘ä¸Šçªç ´æ¦‚ç‡"
    )


# ========== ReportWriterAgent å·¥å…· ==========

def generate_markdown_report_tool() -> Tool:
    """åˆ›å»ºç”ŸæˆMarkdownæŠ¥å‘Šçš„å·¥å…·"""
    
    async def generate_markdown_report(
        stock_code: str,
        stock_name: str,
        analysis_data: str
    ) -> str:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            analysis_data: æ‰€æœ‰åˆ†ææ•°æ®çš„JSONå­—ç¬¦ä¸²
            
        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Š
        """
        try:
            data = json.loads(analysis_data)
            
            report = f"""# {stock_code} {stock_name} æŠ•èµ„åˆ†ææŠ¥å‘Š

ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š åŸºæœ¬ä¿¡æ¯

{data.get('basic_info', 'æš‚æ— æ•°æ®')}

## ğŸ” å¹³åº•é”…å½¢æ€åˆ†æ

{data.get('pan_bottom_analysis', 'æš‚æ— æ•°æ®')}

## ğŸ“ˆ æ¿å—åˆ†æ

{data.get('sector_analysis', 'æš‚æ— æ•°æ®')}

## ğŸ¢ å…¬å¸åŸºæœ¬é¢

{data.get('company_analysis', 'æš‚æ— æ•°æ®')}

## ğŸ“‰ æŠ€æœ¯åˆ†æ

{data.get('technical_analysis', 'æš‚æ— æ•°æ®')}

## ğŸ’¡ ç»¼åˆè¯„ä¼°

{data.get('evaluation', 'æš‚æ— æ•°æ®')}

---
*æœ¬æŠ¥å‘Šç”±AIç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®*
"""
            
            return report
            
        except Exception as e:
            return f"# æŠ¥å‘Šç”Ÿæˆå¤±è´¥\n\né”™è¯¯ä¿¡æ¯ï¼š{str(e)}"
    
    return Tool(
        function=generate_markdown_report,
        name="generate_markdown_report",
        description="åŸºäºåˆ†ææ•°æ®ç”ŸæˆMarkdownæ ¼å¼çš„æŠ•èµ„åˆ†ææŠ¥å‘Š"
    )


def save_to_database_tool(db: StockDatabase) -> Tool:
    """åˆ›å»ºä¿å­˜ç»“æœåˆ°æ•°æ®åº“çš„å·¥å…·"""
    
    async def save_to_database(
        stock_code: str,
        recommendation_score: float,
        reason: str,
        analysis_detail: Optional[str] = None
    ) -> str:
        """
        å°†åˆ†æç»“æœä¿å­˜åˆ°æ•°æ®åº“
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            recommendation_score: æ¨èè¯„åˆ†(0-10)
            reason: æ¨èç†ç”±ï¼ˆç®€çŸ­ï¼Œ100å­—ä»¥å†…ï¼‰
            analysis_detail: è¯¦ç»†åˆ†ææ•°æ®ï¼ˆJSONå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰
            
        Returns:
            ä¿å­˜ç»“æœ
        """
        try:
            # éªŒè¯è¯„åˆ†èŒƒå›´
            if not 0 <= recommendation_score <= 10:
                return json.dumps({
                    "success": False,
                    "message": f"è¯„åˆ†å¿…é¡»åœ¨0-10ä¹‹é—´ï¼Œå½“å‰å€¼: {recommendation_score}"
                }, ensure_ascii=False)
            
            # è§£æè¯¦ç»†æ•°æ®
            detail_dict = None
            if analysis_detail:
                try:
                    detail_dict = json.loads(analysis_detail)
                except:
                    pass
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            await db.insert_analysis_result(
                code=stock_code,
                score=recommendation_score,
                reason=reason,
                detail=detail_dict
            )
            
            return json.dumps({
                "success": True,
                "message": f"æˆåŠŸä¿å­˜ {stock_code} çš„åˆ†æç»“æœ",
                "code": stock_code,
                "score": recommendation_score
            }, ensure_ascii=False)
            
        except Exception as e:
            return json.dumps({
                "success": False,
                "message": f"ä¿å­˜å¤±è´¥: {str(e)}"
            }, ensure_ascii=False)
    
    return Tool(
        function=save_to_database,
        name="save_to_database",
        description="å°†åˆ†æç»“æœï¼ˆè¯„åˆ†ã€ç†ç”±ã€è¯¦æƒ…ï¼‰ä¿å­˜åˆ°stock_analysis_resultsè¡¨"
    )


# å¯¼å‡ºæ‰€æœ‰å·¥å…·åˆ›å»ºå‡½æ•°
__all__ = [
    'query_stock_kline_tool',
    'calculate_indicators_tool',
    'web_search_tool',
    'search_sectors_tool',
    'analyze_sector_hotness_tool',
    'search_company_news_tool',
    'analyze_kline_image_tool',
    'calculate_support_resistance_tool',
    'generate_markdown_report_tool',
    'save_to_database_tool'
]
