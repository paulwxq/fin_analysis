# æ¨¡å—Aï¼šAKShare æ•°æ®é‡‡é›† â€” è¯¦ç»†è®¾è®¡æ–‡æ¡£

## ä¸€ã€æ¦‚è¿°

### 1.1 å®šä½

æ¨¡å—A æ˜¯ `stock_analyzer` çš„ç»“æ„åŒ–æ•°æ®é‡‡é›†æ¨¡å—ï¼Œè´Ÿè´£é€šè¿‡ **AKShare** è°ƒç”¨ä¸œæ–¹è´¢å¯Œç­‰æ•°æ®æºæ¥å£ï¼Œè·å–ç›®æ ‡è‚¡ç¥¨çš„åŸºæœ¬é¢ã€ä¼°å€¼ã€èµ„é‡‘æµå‘ã€è‚¡ä¸œç»“æ„ç­‰ **12 ä¸ªä¸»é¢˜**çš„ç»“æ„åŒ–æ•°æ®ï¼Œæ•´ç†åè¾“å‡ºä¸º `AKShareData`ï¼ˆPydantic æ¨¡å‹å¯¹è±¡ï¼‰ã€‚

**æ ¸å¿ƒç‰¹å¾ï¼š** çº¯ Python ä»£ç ï¼Œä¸æ¶‰åŠ AI/Agentã€‚

### 1.2 è¾“å…¥è¾“å‡º

| | è¯´æ˜ |
|------|------|
| **è¾“å…¥** | è‚¡ç¥¨ä»£ç ï¼ˆ`symbol`ï¼Œçº¯6ä½æ•°å­—ï¼‰ã€è‚¡ç¥¨åç§°ï¼ˆ`name`ï¼‰ |
| **è¾“å‡º** | `AKShareData`ï¼ˆPydantic æ¨¡å‹å¯¹è±¡ï¼‰ |

### 1.3 æŠ€æœ¯é€‰å‹

| ç»„ä»¶ | é€‰å‹ | è¯´æ˜ |
|------|------|------|
| Python ç‰ˆæœ¬ | **3.12+** | é¡¹ç›®è¦æ±‚ï¼ˆè§ `pyproject.toml`ï¼‰ |
| æ•°æ®æº | AKShare `>=1.18.22` | å¼€æº A è‚¡æ•°æ®æ¥å£ï¼ˆåº•å±‚çˆ¬è™«ï¼‰ |
| æ•°æ®å¤„ç† | pandas `>=2.3.3` | DataFrame æ“ä½œ |
| æ•°æ®æ ¡éªŒ | Pydantic `>=2.12.5` | è¾“å‡ºç»“æ„åŒ–æ ¡éªŒ |
| æ—¥å¿— | `stock_analyzer.logger` | ä¸é¡¹ç›®ç»Ÿä¸€ï¼ˆæ§åˆ¶å° + æ–‡ä»¶ï¼‰ |
| é…ç½® | `stock_analyzer.config` | ä¸é¡¹ç›®ç»Ÿä¸€ï¼ˆç¯å¢ƒå˜é‡é©±åŠ¨ï¼‰ |

### 1.4 è®¾è®¡åŸåˆ™

1. **çº¯ä»£ç å®ç°**ï¼šä¸ä½¿ç”¨ AI/Agentï¼ŒAKShare è¿”å›ç»“æ„åŒ–æ•°æ®ï¼Œç›´æ¥è§£ææ‹¼æ¥å³å¯
2. **å®¹é”™ä¼˜å…ˆ**ï¼šä»»ä½•å•ä¸ªä¸»é¢˜é‡‡é›†å¤±è´¥ä¸ä¸­æ–­æ•´ä½“æµç¨‹ï¼Œè®°å½•é”™è¯¯ç»§ç»­æ‰§è¡Œ
3. **ä¸²è¡Œè°ƒç”¨**ï¼šAKShare åº•å±‚æ˜¯çˆ¬è™«ï¼Œå¹¶è¡Œè°ƒç”¨æ˜“è§¦å‘ IP å°ç¦ï¼Œå¿…é¡»ä¸²è¡Œ + é—´éš”
4. **ç»Ÿä¸€ä»£ç è½¬æ¢**ï¼šå°è£… `format_symbol()` å·¥å…·å‡½æ•°è§£å†³ AKShare ä¸åŒå‡½æ•°çš„ä»£ç æ ¼å¼ä¸ä¸€è‡´é—®é¢˜
5. **å…±äº«åŸºç¡€è®¾æ–½**ï¼šå¤ç”¨ `config.py`ã€`logger.py`ã€`exceptions.py`ï¼Œä¸æ¨¡å—Bä¿æŒä¸€è‡´

---

## äºŒã€æ¶æ„è®¾è®¡

### 2.1 æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | ç±»å‹ | èŒè´£ |
|------|------|------|
| `AKShareCollector` | ä¸»ç±» | ç¼–æ’12ä¸ªä¸»é¢˜çš„æ•°æ®é‡‡é›†ï¼Œç»Ÿä¸€å¼‚å¸¸å¤„ç†å’Œç»“æœç»„è£… |
| `format_symbol()` | å·¥å…·å‡½æ•° | è‚¡ç¥¨ä»£ç æ ¼å¼è½¬æ¢ï¼ˆçº¯6ä½ / å°å†™å‰ç¼€ / å¤§å†™å‰ç¼€ï¼‰ |
| `get_market()` | å·¥å…·å‡½æ•° | è¿”å›å¸‚åœºæ ‡è¯†ï¼ˆ`sh` / `sz`ï¼‰ |
| `AKShareData` | Pydantic æ¨¡å‹ | è¾“å‡ºæ•°æ®ç»“æ„å®šä¹‰å’Œæ ¡éªŒ |
| `collect_akshare_data()` | å…¥å£å‡½æ•° | æ¨¡å—Aå¯¹å¤–å…¥å£ï¼Œåˆ›å»º Collector å¹¶æ‰§è¡Œé‡‡é›† |

### 2.2 æ•°æ®æµå›¾

```
è¾“å…¥ï¼šsymbol="000001", name="å¹³å®‰é“¶è¡Œ"
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   collect_akshare_data()     â”‚  â† æ¨¡å—Aå…¥å£å‡½æ•°
    â”‚                              â”‚
    â”‚   åˆ›å»º AKShareCollector      â”‚
    â”‚   è°ƒç”¨ collector.collect()   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   AKShareCollector.collect() â”‚
    â”‚                              â”‚
    â”‚   ä¸²è¡Œæ‰§è¡Œ12ä¸ªä¸»é¢˜é‡‡é›†ï¼š      â”‚
    â”‚                              â”‚
    â”‚   â‘  å…¬å¸åŸºæœ¬ä¿¡æ¯             â”‚  â† ak.stock_individual_info_em
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘¡ å®æ—¶è¡Œæƒ…å¿«ç…§             â”‚  â† ak.stock_zh_a_spot_em
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘¢ è´¢åŠ¡åˆ†ææŒ‡æ ‡             â”‚  â† ak.stock_financial_analysis_indicator
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘£ ä¼°å€¼å†å²æ•°æ®             â”‚  â† ak.stock_a_lg_indicator
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘¤ è¡Œä¸šä¼°å€¼å¯¹æ¯”             â”‚  â† ak.stock_zh_valuation_comparison_em
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘¥ ä¸ªè‚¡èµ„é‡‘æµå‘             â”‚  â† ak.stock_individual_fund_flow
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘¦ æ¿å—èµ„é‡‘æµå‘             â”‚  â† ak.stock_board_industry_fund_flow_rank_em
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘§ åŒ—å‘èµ„é‡‘æŒä»“             â”‚  â† ak.stock_hsgt_hold_stock_em
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘¨ è‚¡ä¸œæˆ·æ•°                 â”‚  â† ak.stock_zh_a_gdhs_detail_em
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘© åˆ†çº¢å†å²                 â”‚  â† ak.stock_history_dividend
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘ª ä¸šç»©é¢„å‘Š                 â”‚  â† ak.stock_yjyg_em
    â”‚          â†“ (é—´éš”3ç§’)         â”‚
    â”‚   â‘« è‚¡æƒè´¨æŠ¼                 â”‚  â† ak.stock_gpzy_pledge_ratio_em
    â”‚                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ ç»„è£…ç»“æœ
                   â–¼
         AKShareDataï¼ˆPydantic å¯¹è±¡ï¼‰
```

### 2.3 æ–‡ä»¶ç»“æ„

```
stock_analyzer/
â”œâ”€â”€ config.py                      # å…±äº«é…ç½®ï¼ˆéœ€æ–°å¢æ¨¡å—Aé…ç½®é¡¹ï¼‰
â”œâ”€â”€ logger.py                      # å…±äº«æ—¥å¿—
â”œâ”€â”€ exceptions.py                  # å…±äº«å¼‚å¸¸ï¼ˆéœ€æ–°å¢æ¨¡å—Aå¼‚å¸¸ç±»ï¼‰
â”œâ”€â”€ models.py                      # å…±äº«æ¨¡å‹ï¼ˆç°æœ‰æ¨¡å—Bæ¨¡å‹ï¼Œä¿æŒä¸å˜ï¼‰
â”œâ”€â”€ module_a_models.py             # ğŸ†• æ¨¡å—A Pydantic æ•°æ®æ¨¡å‹
â”œâ”€â”€ module_a_akshare.py            # ğŸ†• æ¨¡å—A ä¸»é€»è¾‘ï¼ˆAKShareCollector + å…¥å£å‡½æ•°ï¼‰
â”œâ”€â”€ utils.py                       # ğŸ†• å·¥å…·å‡½æ•°ï¼ˆformat_symbol, get_market, normalize_symbol ç­‰ï¼‰
â”œâ”€â”€ run_module_a.py                # ğŸ†• æ¨¡å—A å‘½ä»¤è¡Œè¿è¡Œè„šæœ¬ï¼ˆç‹¬ç«‹æµ‹è¯•ç”¨ï¼‰
â””â”€â”€ docs/
    â””â”€â”€ module_a_akshare_detail_design.md  # ğŸ†• æœ¬æ–‡æ¡£
```

---

## ä¸‰ã€é…ç½®è®¾è®¡

### 3.1 æ–°å¢é…ç½®é¡¹

åœ¨ç°æœ‰ `config.py` ä¸­æ–°å¢æ¨¡å—Aä¸“ç”¨é…ç½®ï¼š

```python
# ============================================================
# æ¨¡å—Aï¼šAKShare æ•°æ®é‡‡é›†é…ç½®
# ============================================================

# AKShare è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…è§¦å‘æ•°æ®æº IP å°ç¦
AKSHARE_CALL_INTERVAL: float = float(os.getenv("AKSHARE_CALL_INTERVAL", "3.0"))

# AKShare å•æ¬¡è°ƒç”¨è¶…æ—¶ï¼ˆç§’ï¼‰
AKSHARE_CALL_TIMEOUT: float = float(os.getenv("AKSHARE_CALL_TIMEOUT", "30.0"))

# è´¢åŠ¡æŒ‡æ ‡å–æœ€è¿‘ N æœŸæ•°æ®
AKSHARE_FINANCIAL_PERIODS: int = int(os.getenv("AKSHARE_FINANCIAL_PERIODS", "8"))

# èµ„é‡‘æµå‘å–æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥
AKSHARE_FUND_FLOW_DAYS: int = int(os.getenv("AKSHARE_FUND_FLOW_DAYS", "5"))

# è‚¡ä¸œæˆ·æ•°å–æœ€è¿‘ N æœŸ
AKSHARE_SHAREHOLDER_PERIODS: int = int(os.getenv("AKSHARE_SHAREHOLDER_PERIODS", "4"))

# åˆ†çº¢å†å²å–æœ€è¿‘ N å¹´
AKSHARE_DIVIDEND_YEARS: int = int(os.getenv("AKSHARE_DIVIDEND_YEARS", "5"))

# è¿ç»­è¶…æ—¶ç†”æ–­é˜ˆå€¼ï¼šè¿ç»­ N æ¬¡è¶…æ—¶åä¸­æ­¢é‡‡é›†
AKSHARE_MAX_CONSECUTIVE_TIMEOUTS: int = int(os.getenv("AKSHARE_MAX_CONSECUTIVE_TIMEOUTS", "3"))

# å…¨å¸‚åœºæ•°æ®ç¼“å­˜ TTLï¼ˆç§’ï¼‰ï¼šåŒä¸€è½®æ‰¹é‡åˆ†æä¸­å¤ç”¨å…¨é‡æŸ¥è¯¢ç»“æœ
AKSHARE_MARKET_CACHE_TTL_SEC: int = int(os.getenv("AKSHARE_MARKET_CACHE_TTL_SEC", "300"))
```

### 3.2 é…ç½®é¡¹è¯´æ˜

| é…ç½®é¡¹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `AKSHARE_CALL_INTERVAL` | `3.0` | æ¯æ¬¡ AKShare API è°ƒç”¨ä¹‹é—´çš„ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ |
| `AKSHARE_CALL_TIMEOUT` | `30.0` | å•æ¬¡ AKShare API è°ƒç”¨çš„è¶…æ—¶ä¸Šé™ï¼ˆç§’ï¼‰ |
| `AKSHARE_FINANCIAL_PERIODS` | `8` | è´¢åŠ¡æŒ‡æ ‡å–æœ€è¿‘å‡ æœŸï¼ˆå­£æŠ¥ï¼‰ï¼Œ8æœŸçº¦ç­‰äº2å¹´ |
| `AKSHARE_FUND_FLOW_DAYS` | `5` | èµ„é‡‘æµå‘æ˜ç»†å–æœ€è¿‘å‡ ä¸ªäº¤æ˜“æ—¥ |
| `AKSHARE_SHAREHOLDER_PERIODS` | `4` | è‚¡ä¸œæˆ·æ•°å–æœ€è¿‘å‡ æœŸæŠ¥å‘Š |
| `AKSHARE_DIVIDEND_YEARS` | `5` | åˆ†çº¢å†å²å–æœ€è¿‘å‡ å¹´ |
| `AKSHARE_MAX_CONSECUTIVE_TIMEOUTS` | `3` | è¿ç»­è¶…æ—¶ç†”æ–­é˜ˆå€¼ï¼Œè¾¾åˆ°åä¸­æ­¢é‡‡é›† |
| `AKSHARE_MARKET_CACHE_TTL_SEC` | `300` | å…¨å¸‚åœºæ¥å£ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰ï¼Œæ‰¹é‡åˆ†ææ—¶å¤ç”¨ |

### 3.3 æ—¥å¿—é…ç½®

å¤ç”¨ç°æœ‰ `logger.py`ï¼Œæ¨¡å—Aå†…éƒ¨ç»Ÿä¸€ä½¿ç”¨ï¼š

```python
from stock_analyzer.logger import logger
```

---

## å››ã€è‚¡ç¥¨ä»£ç æ ¼å¼è½¬æ¢

### 4.1 é—®é¢˜èƒŒæ™¯

> âš ï¸ è¿™æ˜¯ AKShare æœ€å¤§çš„å‘ä¹‹ä¸€ï¼šä¸åŒå‡½æ•°è¦æ±‚çš„è‚¡ç¥¨ä»£ç æ ¼å¼ä¸åŒã€‚

| æ ¼å¼ | ç¤ºä¾‹ | ä½¿ç”¨çš„å‡½æ•° |
|------|------|-----------|
| çº¯6ä½æ•°å­— (`bare`) | `"000001"` | `stock_individual_info_em`, `stock_zh_a_hist`, `stock_news_em`, `stock_financial_analysis_indicator`, `stock_a_lg_indicator`, `stock_zh_a_gdhs_detail_em` |
| å°å†™å‰ç¼€ (`lower`) | `"sz000001"` | `stock_history_dividend` |
| å¤§å†™å‰ç¼€ (`upper`) | `"SZ000001"` | `stock_zh_valuation_comparison_em` |
| ä»£ç +å¸‚åœºå‚æ•° | `stock="000001"`, `market="sz"` | `stock_individual_fund_flow` |

### 4.2 å¸‚åœºåˆ¤å®šè§„åˆ™

```python
def get_market(code: str) -> str:
    """
    æ ¹æ®è‚¡ç¥¨ä»£ç åˆ¤æ–­æ‰€å±å¸‚åœºã€‚

    Args:
        code: çº¯6ä½æ•°å­—è‚¡ç¥¨ä»£ç 

    Returns:
        "sh" æˆ– "sz"

    è§„åˆ™ï¼š
    - 6 å¼€å¤´ â†’ ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€ (sh)
    - 0ã€3 å¼€å¤´ â†’ æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€ (sz)
    - å…¶ä»– â†’ é»˜è®¤ szï¼ˆå« 002 ä¸­å°æ¿ã€300 åˆ›ä¸šæ¿ï¼‰
    """
    return "sh" if code.startswith("6") else "sz"
```

### 4.3 æ ¼å¼è½¬æ¢å‡½æ•°

```python
def format_symbol(code: str, style: str) -> str:
    """
    ç»Ÿä¸€è‚¡ç¥¨ä»£ç æ ¼å¼è½¬æ¢ã€‚

    Args:
        code: çº¯6ä½æ•°å­—è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001"
        style: ç›®æ ‡æ ¼å¼
            - "bare"  â†’ "000001"
            - "lower" â†’ "sz000001"
            - "upper" â†’ "SZ000001"

    Returns:
        è½¬æ¢åçš„è‚¡ç¥¨ä»£ç 

    Raises:
        ValueError: code ä¸æ˜¯6ä½æ•°å­—ï¼Œæˆ– style ä¸åˆæ³•
    """
    if not code.isdigit() or len(code) != 6:
        raise ValueError(f"Invalid stock code: '{code}', expected 6-digit string")
    
    market = get_market(code)
    
    if style == "bare":
        return code
    elif style == "lower":
        return f"{market}{code}"
    elif style == "upper":
        return f"{market.upper()}{code}"
    else:
        raise ValueError(f"Unknown style: '{style}', expected 'bare'/'lower'/'upper'")
```

### 4.4 å‘½ä»¤è¡Œä»£ç æ¸…æ´—å‡½æ•°

ç”¨æˆ·ä»å‘½ä»¤è¡Œä¼ å…¥çš„è‚¡ç¥¨ä»£ç å¯èƒ½å¸¦æœ‰äº¤æ˜“æ‰€åç¼€ï¼ˆå¦‚ `600519.SH`ã€`000001.SZ`ï¼‰ï¼Œ
éœ€è¦åœ¨å…¥å£å±‚ç»Ÿä¸€æ¸…æ´—ä¸ºçº¯6ä½æ•°å­—ï¼š

```python
import re

# åŒ¹é…å¤šç§å¸¸è§æ ¼å¼ï¼š600519.SH / 600519.sh / SH600519 / sh600519 / 600519
_SYMBOL_RE = re.compile(
    r"^(?:(?P<prefix>[A-Za-z]{2})(?P<code1>\d{6}))$"    # SH600519
    r"|^(?:(?P<code2>\d{6})(?:[.\-](?P<suffix>[A-Za-z]{2,4}))?)$"  # 600519 / 600519.SH
)


def normalize_symbol(raw: str) -> str:
    """
    ä»å„ç§å¸¸è§æ ¼å¼ä¸­æå–çº¯6ä½æ•°å­—è‚¡ç¥¨ä»£ç ã€‚

    æ”¯æŒæ ¼å¼ï¼š
        "600519"      â†’ "600519"
        "600519.SH"   â†’ "600519"
        "600519.sh"   â†’ "600519"
        "SH600519"    â†’ "600519"
        "sh600519"    â†’ "600519"

    Args:
        raw: åŸå§‹è‚¡ç¥¨ä»£ç å­—ç¬¦ä¸²

    Returns:
        çº¯6ä½æ•°å­—ä»£ç 

    Raises:
        ValueError: æ— æ³•ä»è¾“å…¥ä¸­è§£æå‡ºåˆæ³•çš„6ä½ä»£ç 
    """
    raw = raw.strip()
    m = _SYMBOL_RE.match(raw)
    if m:
        code = m.group("code1") or m.group("code2")
        if code and len(code) == 6:
            return code
    raise ValueError(
        f"Cannot normalize symbol: '{raw}'. "
        f"Expected formats: 600519 / 600519.SH / SH600519"
    )
```

### 4.5 å„ä¸»é¢˜ä½¿ç”¨çš„ä»£ç æ ¼å¼

| ä¸»é¢˜ | AKShare å‡½æ•° | ä»£ç æ ¼å¼ | è°ƒç”¨ç¤ºä¾‹ |
|------|-------------|---------|---------|
| â‘  å…¬å¸åŸºæœ¬ä¿¡æ¯ | `stock_individual_info_em` | `bare` | `symbol="000001"` |
| â‘¡ å®æ—¶è¡Œæƒ… | `stock_zh_a_spot_em` | æ— å‚æ•°ï¼ˆå…¨å¸‚åœºï¼‰ | è¿”å›åæŒ‰ä»£ç è¿‡æ»¤ |
| â‘¢ è´¢åŠ¡æŒ‡æ ‡ | `stock_financial_analysis_indicator` | `bare` | `stock="000001"` |
| â‘£ ä¼°å€¼å†å² | `stock_a_lg_indicator` | `bare` | `stock="000001"` |
| â‘¤ è¡Œä¸šä¼°å€¼å¯¹æ¯” | `stock_zh_valuation_comparison_em` | `upper` | `symbol="SZ000001"` |
| â‘¥ ä¸ªè‚¡èµ„é‡‘æµå‘ | `stock_individual_fund_flow` | `bare` + `market` | `stock="000001"`, `market="sz"` |
| â‘¦ æ¿å—èµ„é‡‘æµå‘ | `stock_board_industry_fund_flow_rank_em` | æ— å‚æ•°ï¼ˆå…¨å¸‚åœºï¼‰ | è¿”å›åæŒ‰è¡Œä¸šè¿‡æ»¤ |
| â‘§ åŒ—å‘èµ„é‡‘æŒä»“ | `stock_hsgt_hold_stock_em` | æ— å‚æ•°ï¼ˆå…¨å¸‚åœºï¼‰ | è¿”å›åæŒ‰ä»£ç è¿‡æ»¤ |
| â‘¨ è‚¡ä¸œæˆ·æ•° | `stock_zh_a_gdhs_detail_em` | `bare` | `symbol="000001"` |
| â‘© åˆ†çº¢å†å² | `stock_history_dividend` | `lower` | `symbol="sz000001"` |
| â‘ª ä¸šç»©é¢„å‘Š | `stock_yjyg_em` | æ— å‚æ•°ï¼ˆæŒ‰æ—¥æœŸæŸ¥å…¨å¸‚åœºï¼‰ | è¿”å›åæŒ‰ä»£ç è¿‡æ»¤ |
| â‘« è‚¡æƒè´¨æŠ¼ | `stock_gpzy_pledge_ratio_em` | æ— å‚æ•°ï¼ˆå…¨å¸‚åœºï¼‰ | è¿”å›åæŒ‰ä»£ç è¿‡æ»¤ |

---

## äº”ã€å¼‚å¸¸å¤„ç†è®¾è®¡

### 5.1 å¼‚å¸¸ç±»å®šä¹‰

åœ¨ `stock_analyzer/exceptions.py` ä¸­æ–°å¢æ¨¡å—Aä¸“ç”¨å¼‚å¸¸ï¼š

```python
# ============================================================
# æ¨¡å—Aï¼šAKShare æ•°æ®é‡‡é›†å¼‚å¸¸
# ============================================================

class AKShareError(Exception):
    """AKShare æ•°æ®é‡‡é›†å¼‚å¸¸åŸºç±»ã€‚"""
    pass


class AKShareAPIError(AKShareError):
    """å•ä¸ª AKShare API è°ƒç”¨å¤±è´¥ã€‚

    ç”¨äºè®°å½•æŸä¸ªä¸»é¢˜çš„é‡‡é›†å¤±è´¥ï¼Œä¸ä¸­æ–­æ•´ä½“æµç¨‹ã€‚
    """

    def __init__(self, topic: str, func_name: str, cause: Exception):
        self.topic = topic
        self.func_name = func_name
        self.cause = cause
        super().__init__(
            f"AKShare API failed for topic '{topic}' "
            f"(func: {func_name}): {cause}"
        )


class AKShareDataEmptyError(AKShareError):
    """AKShare API è¿”å›ç©ºæ•°æ®ã€‚

    æŸäº›æƒ…å†µä¸‹ API è°ƒç”¨æˆåŠŸä½†è¿”å› None æˆ–ç©º DataFrameã€‚
    """

    def __init__(self, topic: str, func_name: str):
        self.topic = topic
        self.func_name = func_name
        super().__init__(
            f"AKShare returned empty data for topic '{topic}' "
            f"(func: {func_name})"
        )


class AKShareCollectionError(AKShareError):
    """æ¨¡å—A æ•´ä½“é‡‡é›†ç»ˆæ­¢å¼‚å¸¸ã€‚

    è§¦å‘åœºæ™¯ï¼š
    1) æ‰€æœ‰ä¸»é¢˜å‡é‡‡é›†å¤±è´¥ï¼›
    2) è¿ç»­è¶…æ—¶è¾¾åˆ°ç†”æ–­é˜ˆå€¼ã€‚
    """

    def __init__(self, symbol: str, errors: list[str]):
        self.symbol = symbol
        self.errors = errors
        super().__init__(
            f"AKShare collection aborted for {symbol}: "
            f"{len(errors)} errors"
        )
```

### 5.2 å¼‚å¸¸å¤„ç†ç­–ç•¥

| åœºæ™¯ | å¤„ç†æ–¹å¼ | ä¿æŠ¤å±‚ | topic_status |
|------|---------|--------|-------------|
| å•ä¸ª API è°ƒç”¨å¤±è´¥ | è®°å½•é”™è¯¯ï¼Œè·³è¿‡è¯¥ä¸»é¢˜ | `safe_call()` | `failed` |
| API è¿”å›ç©ºæ•°æ® | è®°å½•è­¦å‘Šï¼Œå­—æ®µä¸º `None` | `safe_call()` | `failed` |
| å…¨å¸‚åœºæ•°æ®ä¸­åˆ—åå˜åŒ– | è®°å½•é”™è¯¯ï¼Œè¿”å›ç©º DataFrame | `_safe_filter()` | `failed` |
| å…¨å¸‚åœºæ•°æ®ä¸­æœªæ‰¾åˆ°ç›®æ ‡è‚¡ç¥¨ï¼ˆAç±»ï¼‰ | è¿”å›ç»“æ„åŒ–"æœªå‘½ä¸­"ç»“æœ | ä¸šåŠ¡å±‚åˆ¤æ–­ | **`ok`**ï¼ˆè§ä¸‹æ–¹è¯´æ˜ï¼‰ |
| å…¨å¸‚åœºæ•°æ®ä¸­æœªæ‰¾åˆ°ç›®æ ‡è‚¡ç¥¨ï¼ˆBç±»ï¼‰ | è®°å½•è­¦å‘Šï¼Œè¿”å› `None` | ä¸šåŠ¡å±‚åˆ¤æ–­ | `failed`ï¼ˆè§ä¸‹æ–¹è¯´æ˜ï¼‰ |
| API æˆåŠŸä½†æ— ä¸šåŠ¡æ•°æ® | è¿”å› `available=False` ç­‰ç»“æ„åŒ–ç»“æœ | ä¸šåŠ¡å±‚ | **`no_data`** |
| è§£æé˜¶æ®µéé¢„æœŸå¼‚å¸¸ | è®°å½•é”™è¯¯ï¼Œè·³è¿‡è¯¥ä¸»é¢˜ | `_safe_collect()` | `failed` |
| æ‰€æœ‰ä¸»é¢˜å‡å¤±è´¥ | æŠ›å‡º `AKShareCollectionError` | `collect()` ä¸»æµç¨‹ | â€” |
| ç½‘ç»œè¶…æ—¶ï¼ˆå•æ¬¡ï¼‰ | è®°å½•é”™è¯¯ï¼Œè·³è¿‡ï¼ˆè½¯è¶…æ—¶ï¼‰ | `safe_call()` ä¸­ `FutureTimeoutError` | `failed` |
| è¿ç»­è¶…æ—¶è¾¾åˆ°ç†”æ–­é˜ˆå€¼ | æŠ›å‡º `AKShareCollectionError`ï¼Œä¸­æ­¢é‡‡é›† | `safe_call()` ç†”æ–­é€»è¾‘ | â€” |

> **"æœªæ‰¾åˆ°ç›®æ ‡è‚¡ç¥¨"åˆ†ç±»è¯´æ˜ï¼š**
>
> å…¨å¸‚åœºæ¥å£è¿”å›æ•°æ®åæœªåŒ¹é…åˆ°ç›®æ ‡è‚¡ç¥¨ï¼Œéœ€æŒ‰ä¸šåŠ¡è¯­ä¹‰åŒºåˆ†ä¸¤ç±»ï¼š
>
> | ç±»å‹ | åˆ¤å®šæ ‡å‡† | å…¸å‹ä¸»é¢˜ | topic_status | è¿”å›å€¼ |
> |------|---------|---------|-------------|--------|
> | **Aç±»ï¼šæœªå‘½ä¸­æœ¬èº«æ˜¯æœ‰æ•ˆç»“è®º** | åå•å‹æ¥å£ï¼Œ"ä¸åœ¨åˆ—è¡¨"æœ‰æ˜ç¡®ä¸šåŠ¡å«ä¹‰ | northboundï¼ˆä¸æŒæœ‰ï¼‰ã€pledge_ratioï¼ˆæ— è´¨æŠ¼ï¼‰ | `ok` | ç»“æ„åŒ–ç»“æœï¼ˆå¦‚ `held=False`ï¼‰ |
> | **Bç±»ï¼šæœªå‘½ä¸­æ„å‘³ç€æ•°æ®ç¼ºå¤±** | æŒ‰ä»£ç åº”å”¯ä¸€å‘½ä¸­çš„æ¥å£ï¼Œæœªå‘½ä¸­å±äºå¼‚å¸¸ | realtime_quoteï¼ˆåœç‰Œ/é€€å¸‚ï¼‰ | `failed` | `None` |
>
> å„ä¸»é¢˜çš„"æœªå‘½ä¸­"å½’å±ç”± `_collect_*()` æ–¹æ³•å†…éƒ¨å†³å®šï¼Œä¸åœ¨ `_safe_filter()` å±‚ä¸€åˆ€åˆ‡ã€‚

### 5.3 `AKShareCollector` ç±»ä¸ `safe_call()` æ–¹æ³•

ä»¥ä¸‹ä»£ç å—å¯¹åº” `module_a_akshare.py` æ–‡ä»¶ã€‚å¼€å¤´çš„ import åŒºå—æ˜¯è¯¥æ–‡ä»¶çš„**å®Œæ•´å¯¼å…¥æ¸…å•**ï¼Œ
ç¬¬å…­ç« æ‰€æœ‰ `_collect_*()` æ–¹æ³•å‡å±äºæ­¤ç±»ï¼Œå…±äº«æ­¤ import åŒºå—ã€‚

```python
"""Module A: AKShare structured data collection."""

from __future__ import annotations

import time
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError
from datetime import date, datetime

import akshare as ak
import pandas as pd

from stock_analyzer.config import (
    AKSHARE_CALL_INTERVAL,
    AKSHARE_CALL_TIMEOUT,
    AKSHARE_DIVIDEND_YEARS,
    AKSHARE_FINANCIAL_PERIODS,
    AKSHARE_FUND_FLOW_DAYS,
    AKSHARE_MARKET_CACHE_TTL_SEC,
    AKSHARE_MAX_CONSECUTIVE_TIMEOUTS,
    AKSHARE_SHAREHOLDER_PERIODS,
)
from stock_analyzer.exceptions import AKShareCollectionError
from stock_analyzer.logger import logger
from stock_analyzer.module_a_models import AKShareData, AKShareMeta
from stock_analyzer.utils import format_symbol, get_market


class AKShareMarketCache:
    """å…¨å¸‚åœº DataFrame ç¼“å­˜ï¼ˆè·¨è‚¡ç¥¨å¤ç”¨ï¼‰ã€‚"""

    def __init__(self, ttl_sec: int = AKSHARE_MARKET_CACHE_TTL_SEC):
        self.ttl_sec = ttl_sec
        self._store: dict[str, tuple[float, pd.DataFrame]] = {}

    def get(self, key: str) -> pd.DataFrame | None:
        item = self._store.get(key)
        if item is None:
            return None
        ts, df = item
        if time.time() - ts > self.ttl_sec:
            self._store.pop(key, None)
            return None
        # è¿”å›å‰¯æœ¬ï¼Œé¿å…è°ƒç”¨æ–¹ä¿®æ”¹ç¼“å­˜å¯¹è±¡
        return df.copy(deep=True)

    def set(self, key: str, df: pd.DataFrame) -> None:
        self._store[key] = (time.time(), df.copy(deep=True))


class AKShareCollector:
    """AKShare æ•°æ®é‡‡é›†å™¨ï¼Œå¸¦ç»Ÿä¸€å¼‚å¸¸å¤„ç†å’Œè°ƒç”¨é—´éš”æ§åˆ¶ã€‚"""

    # ä¸»é¢˜çŠ¶æ€å¸¸é‡
    STATUS_OK = "ok"              # é‡‡é›†æˆåŠŸï¼Œæœ‰ä¸šåŠ¡æ•°æ®
    STATUS_NO_DATA = "no_data"    # é‡‡é›†æˆåŠŸï¼Œä½†æ— ä¸šåŠ¡æ•°æ®ï¼ˆå¦‚ç¡®å®æ— ä¸šç»©é¢„å‘Šï¼‰
    STATUS_FAILED = "failed"      # é‡‡é›†å¤±è´¥ï¼ˆAPI å¼‚å¸¸/è¶…æ—¶/åˆ—åå˜åŒ–ç­‰ï¼‰

    def __init__(
        self,
        symbol: str,
        name: str,
        market_cache: AKShareMarketCache | None = None,
    ):
        self.symbol = symbol
        self.name = name
        self.errors: list[str] = []
        self.topic_status: dict[str, str] = {}  # æ¯ä¸ªä¸»é¢˜çš„é‡‡é›†çŠ¶æ€
        self._last_call_time: float = 0.0
        self._consecutive_timeouts: int = 0     # è¿ç»­è¶…æ—¶è®¡æ•°å™¨
        self.market_cache = market_cache or AKShareMarketCache()

    def _wait_interval(self) -> None:
        """ç¡®ä¿ä¸ä¸Šæ¬¡ AKShare è°ƒç”¨ä¹‹é—´æœ‰è¶³å¤Ÿé—´éš”ï¼Œé¿å… IP å°ç¦ã€‚"""
        elapsed = time.time() - self._last_call_time
        if elapsed < AKSHARE_CALL_INTERVAL:
            wait = AKSHARE_CALL_INTERVAL - elapsed
            logger.debug(f"Rate limit: waiting {wait:.1f}s before next AKShare call")
            time.sleep(wait)

    def safe_call(
        self,
        topic: str,
        func,
        *args,
        **kwargs,
    ) -> pd.DataFrame | None:
        """
        å®‰å…¨è°ƒç”¨ AKShare å‡½æ•°ï¼Œå¸¦è½¯è¶…æ—¶æ§åˆ¶ä¸è¿ç»­è¶…æ—¶ç†”æ–­ã€‚

        - è‡ªåŠ¨æ‰§è¡Œè°ƒç”¨é—´éš”ç­‰å¾…
        - é€šè¿‡ ThreadPoolExecutor å®ç°è½¯è¶…æ—¶ï¼ˆAKSHARE_CALL_TIMEOUTï¼‰
        - è¿ç»­è¶…æ—¶è¾¾åˆ° AKSHARE_MAX_CONSECUTIVE_TIMEOUTS æ—¶è§¦å‘ç†”æ–­
        - æ•è·æ‰€æœ‰å¼‚å¸¸ï¼Œè®°å½•åˆ° self.errors
        - è¿”å› DataFrame æˆ– Noneï¼ˆå¤±è´¥æ—¶ï¼‰

        Args:
            topic: æ•°æ®ä¸»é¢˜åç§°ï¼ˆç”¨äºæ—¥å¿—å’Œé”™è¯¯è®°å½•ï¼‰
            func: AKShare å‡½æ•°å¯¹è±¡
            *args, **kwargs: ä¼ é€’ç»™ func çš„å‚æ•°

        Returns:
            æˆåŠŸæ—¶è¿”å› DataFrameï¼Œå¤±è´¥æˆ–æ•°æ®ä¸ºç©ºæ—¶è¿”å› None

        Raises:
            AKShareCollectionError: è¿ç»­è¶…æ—¶æ¬¡æ•°è¾¾åˆ°ç†”æ–­é˜ˆå€¼æ—¶æŠ›å‡º

        è¶…æ—¶æœºåˆ¶è¯´æ˜ï¼ˆâš ï¸ è½¯è¶…æ—¶ï¼‰ï¼š
            AKShare åº•å±‚èµ° HTTP è¯·æ±‚ï¼ˆåŒæ­¥ï¼‰ï¼Œæ— æ³•ç”¨ asyncio.wait_for()ã€‚
            ä½¿ç”¨ ThreadPoolExecutor æäº¤åˆ°çº¿ç¨‹æ± ï¼Œé€šè¿‡ future.result(timeout=...)
            é™åˆ¶ä¸»çº¿ç¨‹çš„ç­‰å¾…æ—¶é—´ã€‚

            **é‡è¦é™åˆ¶ï¼š**
            - è¿™æ˜¯"è½¯è¶…æ—¶"ï¼šè¶…æ—¶åä¸»çº¿ç¨‹ç«‹å³æ¢å¤æ‰§è¡Œï¼Œä½†åº•å±‚çº¿ç¨‹ä¸­çš„
              HTTP è¯·æ±‚æ— æ³•è¢«å¼ºåˆ¶ç»ˆæ­¢ï¼Œä¼šç»§ç»­è¿è¡Œç›´åˆ°è‡ªç„¶ç»“æŸã€‚
            - ä½¿ç”¨ shutdown(wait=False) é¿å… executor é€€å‡ºæ—¶é˜»å¡ä¸»çº¿ç¨‹ã€‚
            - å¦‚æœéœ€è¦"ç¡¬è¶…æ—¶"ï¼ˆå¼ºåˆ¶ç»ˆæ­¢åº•å±‚è°ƒç”¨ï¼‰ï¼Œéœ€æ”¹ç”¨å­è¿›ç¨‹éš”ç¦»
              æ–¹æ¡ˆï¼ˆmultiprocessing + Process.kill()ï¼‰ï¼Œä½†å®ç°å¤æ‚åº¦è¾ƒé«˜ï¼Œ
              å½“å‰åœºæ™¯ï¼ˆAKShare HTTP è¯·æ±‚é€šå¸¸æœ‰è‡ªèº«çš„ socket è¶…æ—¶ï¼‰ä¸‹
              è½¯è¶…æ—¶å·²èƒ½æ»¡è¶³éœ€æ±‚ã€‚

        çº¿ç¨‹å †ç§¯é£é™©ä¸é˜²æŠ¤ï¼ˆâš ï¸ï¼‰ï¼š
            æ¯æ¬¡è¶…æ—¶ååº•å±‚çº¿ç¨‹ä»åœ¨åå°è¿è¡Œï¼Œè¿ç»­è¶…æ—¶ä¼šå¯¼è‡´çº¿ç¨‹çŸ­æ—¶å †ç§¯ã€‚
            æœ¬æ–¹æ³•é‡‡ç”¨ä»¥ä¸‹é˜²æŠ¤ç­–ç•¥ï¼š
            a) å…¨æµç¨‹ä¸²è¡Œè°ƒç”¨â€”â€”åŒä¸€æ—¶åˆ»åªæœ‰ 1 ä¸ª safe_call åœ¨æ‰§è¡Œï¼›
            b) è°ƒç”¨é—´éš”ï¼ˆAKSHARE_CALL_INTERVALï¼Œé»˜è®¤ 3sï¼‰å¤©ç„¶é™é€Ÿï¼›
            c) è¿ç»­è¶…æ—¶ç†”æ–­â€”â€”è¿ç»­ N æ¬¡ï¼ˆAKSHARE_MAX_CONSECUTIVE_TIMEOUTSï¼Œ
               é»˜è®¤ 3ï¼‰è¶…æ—¶åæŠ›å‡º AKShareCollectionErrorï¼Œä¸­æ­¢é‡‡é›†ï¼›
            d) ç”Ÿäº§ç¯å¢ƒå»ºè®®ç›‘æ§ threading.active_count()ï¼Œå¯¹çº¿ç¨‹æ•°è®¾å‘Šè­¦ã€‚

            æœ€åå †ç§¯æ•°é‡ = AKSHARE_MAX_CONSECUTIVE_TIMEOUTSï¼ˆé»˜è®¤ 3 ä¸ªçº¿ç¨‹ï¼‰ï¼Œ
            è¿™äº›çº¿ç¨‹åœ¨åº•å±‚ HTTP è¯·æ±‚å®Œæˆæˆ– socket è¶…æ—¶åä¼šè‡ªç„¶å›æ”¶ï¼Œ
            ä¸ä¼šæ— é™å¢é•¿ã€‚

        æ‰§è¡Œå™¨ç”Ÿå‘½å‘¨æœŸç­–ç•¥ï¼ˆè®¾è®¡æƒè¡¡ï¼‰ï¼š
            safe_call() æ¯æ¬¡è°ƒç”¨éƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ ThreadPoolExecutor(max_workers=1)ï¼Œ
            è€Œä¸æ˜¯å¤ç”¨å…¨å±€å•çº¿ç¨‹ executorã€‚è¿™æ ·åšçš„ç›®çš„ï¼š
            1) è½¯è¶…æ—¶åå°†â€œå¡ä½ä»»åŠ¡â€éš”ç¦»åœ¨å½“å‰è°ƒç”¨ä¸Šä¸‹æ–‡ï¼Œä¸é˜»å¡åç»­è°ƒç”¨æäº¤ï¼›
            2) é¿å…å…±äº«å•çº¿ç¨‹æ± ä¸‹ï¼Œå•ä¸ªå¡ä½ä»»åŠ¡å¯¼è‡´åç»­ä»»åŠ¡æ’é˜Ÿè¿é”è¶…æ—¶ã€‚
            ä»£ä»·æ˜¯æ¯æ¬¡è°ƒç”¨æœ‰è½»å¾®åˆ›å»º/é”€æ¯å¼€é”€ã€‚é‰´äºæ¨¡å—Aå•è½®è°ƒç”¨é‡çº¦ 12~15 æ¬¡ï¼Œ
            è¯¥å¼€é”€å¯æ¥å—ï¼Œä¼˜å…ˆä¿è¯è¶…æ—¶éš”ç¦»ä¸å¯æ¢å¤æ€§ã€‚
        """
        func_name = func.__name__
        self._wait_interval()

        # è®¾è®¡è¯´æ˜ï¼šæ¯æ¬¡è°ƒç”¨ç‹¬ç«‹åˆ›å»º executorï¼Œé¿å…å…±äº«å•çº¿ç¨‹æ± è¢«å¡ä½ä»»åŠ¡â€œå µæ­»â€ã€‚
        executor = ThreadPoolExecutor(max_workers=1)
        try:
            logger.info(f"Fetching [{topic}] via {func_name}...")
            self._last_call_time = time.time()

            future = executor.submit(func, *args, **kwargs)
            df = future.result(timeout=AKSHARE_CALL_TIMEOUT)

            # è°ƒç”¨æˆåŠŸï¼Œé‡ç½®è¿ç»­è¶…æ—¶è®¡æ•°å™¨
            self._consecutive_timeouts = 0

            if df is None or (isinstance(df, pd.DataFrame) and df.empty):
                msg = f"{topic}: è¿”å›æ•°æ®ä¸ºç©º ({func_name})"
                self.errors.append(msg)
                logger.warning(msg)
                return None

            logger.info(
                f"[{topic}] fetched successfully: "
                f"{len(df)} rows via {func_name}"
            )
            return df

        except FutureTimeoutError:
            self._consecutive_timeouts += 1
            msg = (
                f"{topic}: è°ƒç”¨è¶…æ—¶ï¼ˆ>{AKSHARE_CALL_TIMEOUT}sï¼‰({func_name})"
                f" [è¿ç»­è¶…æ—¶ {self._consecutive_timeouts}/"
                f"{AKSHARE_MAX_CONSECUTIVE_TIMEOUTS}]"
            )
            self.errors.append(msg)
            logger.error(msg)

            # ç†”æ–­ï¼šè¿ç»­è¶…æ—¶è¾¾åˆ°é˜ˆå€¼ï¼Œä¸­æ­¢é‡‡é›†
            if self._consecutive_timeouts >= AKSHARE_MAX_CONSECUTIVE_TIMEOUTS:
                breaker_msg = (
                    f"è¿ç»­è¶…æ—¶ {self._consecutive_timeouts} æ¬¡ï¼Œ"
                    f"è¾¾åˆ°ç†”æ–­é˜ˆå€¼ï¼Œä¸­æ­¢é‡‡é›†"
                )
                logger.critical(breaker_msg)
                raise AKShareCollectionError(
                    self.symbol, self.errors + [breaker_msg]
                )

            return None
        except KeyboardInterrupt:
            raise  # ä¸åæ²¡ç”¨æˆ·ä¸­æ–­
        except Exception as e:
            # éè¶…æ—¶å¼‚å¸¸ä¸ç´¯åŠ è¿ç»­è¶…æ—¶è®¡æ•°ï¼ˆç½‘ç»œéè¶…æ—¶é”™è¯¯å¯èƒ½æ˜¯å¶å‘çš„ï¼‰
            msg = f"{topic}: {type(e).__name__} - {str(e)[:200]} ({func_name})"
            self.errors.append(msg)
            logger.error(msg)
            return None
        finally:
            # wait=Falseï¼šä¸ç­‰å¾…åº•å±‚çº¿ç¨‹ç»“æŸï¼Œä¸»çº¿ç¨‹ç«‹å³ç»§ç»­ã€‚
            # åº•å±‚çº¿ç¨‹ä¼šåœ¨ HTTP è¯·æ±‚è‡ªç„¶ç»“æŸåè¢«å›æ”¶ã€‚
            executor.shutdown(wait=False)

    def safe_call_market_cached(
        self,
        cache_key: str,
        topic: str,
        func,
        *args,
        **kwargs,
    ) -> pd.DataFrame | None:
        """å¸¦ç¼“å­˜çš„å…¨å¸‚åœºè°ƒç”¨ï¼šå‘½ä¸­ç¼“å­˜åˆ™ç›´æ¥è¿”å›ï¼Œæœªå‘½ä¸­æ‰è¯·æ±‚ã€‚"""
        cached = self.market_cache.get(cache_key)
        if cached is not None:
            logger.info(f"[{topic}] cache hit: {cache_key}")
            return cached

        df = self.safe_call(topic, func, *args, **kwargs)
        if df is not None:
            self.market_cache.set(cache_key, df)
            logger.info(f"[{topic}] cache set: {cache_key}, rows={len(df)}")
        return df

    def _safe_filter(
        self,
        df: pd.DataFrame,
        column: str,
        value: str,
        topic: str,
        *,
        method: str = "eq",
    ) -> pd.DataFrame:
        """
        é˜²å¾¡æ€§ DataFrame åˆ—è¿‡æ»¤ã€‚

        å…ˆæ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨æ—¶è®°å½•é”™è¯¯å¹¶è¿”å›ç©º DataFrameï¼Œ
        é¿å… KeyError ç©¿é€åˆ°ä¸»æµç¨‹ã€‚

        Args:
            df: å¾…è¿‡æ»¤çš„ DataFrame
            column: ç›®æ ‡åˆ—åï¼ˆä¸­æ–‡åˆ—åï¼Œå¯èƒ½éš AKShare ç‰ˆæœ¬å˜åŒ–ï¼‰
            value: è¿‡æ»¤å€¼
            topic: æ‰€å±ä¸»é¢˜åï¼ˆç”¨äºé”™è¯¯æ—¥å¿—ï¼‰
            method: è¿‡æ»¤æ–¹å¼
                - "eq"       â†’ df[df[column] == value]
                - "contains"  â†’ df[df[column].str.contains(value, regex=False)]

        Returns:
            è¿‡æ»¤åçš„ DataFrameï¼ˆåˆ—ä¸å­˜åœ¨æ—¶è¿”å›ç©º DataFrameï¼‰
        """
        if column not in df.columns:
            msg = (
                f"{topic}: é¢„æœŸåˆ— '{column}' ä¸å­˜åœ¨ï¼Œ"
                f"å®é™…åˆ—å: {list(df.columns)[:10]}"
            )
            self.errors.append(msg)
            logger.warning(msg)
            return df.iloc[0:0]  # è¿”å›åŒç»“æ„çš„ç©º DataFrame

        if method == "eq":
            return df[df[column] == value]
        elif method == "contains":
            return df[df[column].str.contains(value, na=False, regex=False)]
        else:
            msg = (
                f"{topic}: æœªçŸ¥è¿‡æ»¤æ–¹å¼ method='{method}'ï¼Œ"
                "å›é€€åˆ° 'eq' ç²¾ç¡®åŒ¹é…"
            )
            self.errors.append(msg)
            logger.warning(msg)
            return df[df[column] == value]

    def _safe_collect(
        self,
        topic: str,
        collect_func,
        *args,
        **kwargs,
    ):
        """
        å®‰å…¨åŒ…è£…è§£æé€»è¾‘ï¼Œå¹¶è‡ªåŠ¨ç»´æŠ¤ topic_statusã€‚

        safe_call() ä»…ä¿æŠ¤ AKShare API è°ƒç”¨ï¼Œæœ¬æ–¹æ³•ä¿æŠ¤è§£æé˜¶æ®µï¼š
        æ•è· _collect_*() å†…éƒ¨çš„ä¸€åˆ‡éé¢„æœŸå¼‚å¸¸ï¼ˆå¦‚ KeyErrorã€TypeErrorï¼‰ï¼Œ
        ç¡®ä¿"å•ä¸»é¢˜å¤±è´¥ä¸ä¸­æ–­æ•´ä½“æµç¨‹"ã€‚

        çŠ¶æ€æ ‡è®°è§„åˆ™ï¼š
        - _collect_*() æ­£å¸¸è¿”å›é None ä¸”æœªé¢„è®¾çŠ¶æ€ â†’ STATUS_OK
        - _collect_*() æ­£å¸¸è¿”å› None â†’ STATUS_FAILED
        - _collect_*() å†…éƒ¨å·²è®¾ç½®è¿‡ topic_statusï¼ˆå¦‚ no_dataï¼‰â†’ ä¿æŒä¸å˜
        - _collect_*() æŠ›å¼‚å¸¸ â†’ STATUS_FAILED

        Args:
            topic: ä¸»é¢˜åï¼ˆç”¨äºé”™è¯¯æ—¥å¿—å’ŒçŠ¶æ€è·Ÿè¸ªï¼‰
            collect_func: _collect_* æ–¹æ³•
            *args, **kwargs: ä¼ é€’ç»™ collect_func çš„å‚æ•°

        Returns:
            collect_func çš„è¿”å›å€¼ï¼Œæˆ– Noneï¼ˆå¼‚å¸¸æ—¶ï¼‰
        """
        try:
            result = collect_func(*args, **kwargs)
            # å¦‚æœ _collect_*() å†…éƒ¨æ²¡æœ‰é¢„è®¾çŠ¶æ€ï¼Œè‡ªåŠ¨æ ‡è®°
            if topic not in self.topic_status:
                self.topic_status[topic] = (
                    self.STATUS_OK if result is not None else self.STATUS_FAILED
                )
            return result
        except (KeyboardInterrupt, AKShareCollectionError):
            raise  # ç†”æ–­å¼‚å¸¸å’Œç”¨æˆ·ä¸­æ–­ä¸åæ²¡ï¼Œå‘ä¸Šä¼ æ’­
        except Exception as e:
            msg = f"{topic}(è§£æé˜¶æ®µ): {type(e).__name__} - {str(e)[:200]}"
            self.errors.append(msg)
            logger.error(msg)
            self.topic_status[topic] = self.STATUS_FAILED
            return None
```

---

## å…­ã€12 ä¸ªæ•°æ®ä¸»é¢˜è¯¦ç»†è®¾è®¡

> **é˜…è¯»è¯´æ˜ï¼š** ä»¥ä¸‹æ‰€æœ‰ `_collect_*()` / `_parse_*()` / `_safe_float()` ç­‰æ–¹æ³•å‡å±äº
> `AKShareCollector` ç±»ï¼ˆå®šä¹‰äº 5.3 èŠ‚ï¼‰ï¼Œå…±äº« 5.3 èŠ‚å¼€å¤´çš„ import åŒºå—ã€‚
> å„ä»£ç ç‰‡æ®µçœç•¥äº† `import` å’Œ `class` å£°æ˜ä»¥å‡å°‘å†—ä½™ã€‚

### 6.1 ä¸»é¢˜â‘  å…¬å¸åŸºæœ¬ä¿¡æ¯

**AKShare å‡½æ•°ï¼š** `ak.stock_individual_info_em(symbol)`

**å…¥å‚æ ¼å¼ï¼š** `bare`ï¼ˆçº¯6ä½æ•°å­—ï¼‰

**è¿”å›æ ¼å¼ï¼š** DataFrameï¼Œä¸¤åˆ— `(item, value)`ï¼Œçº¦ 15-20 è¡Œ

**âš ï¸ åˆ—åæ³¨æ„ï¼š** `item` / `value` æ˜¯ `stock_individual_info_em` çš„æ¥å£ç‰¹æœ‰è‹±æ–‡åˆ—åï¼ˆåŒºåˆ«äºå¤šæ•°ä¸­æ–‡åˆ—æ¥å£ï¼‰ã€‚è§£æå‰éœ€å…ˆæ ¡éªŒåˆ—å­˜åœ¨ï¼›è‹¥ç‰ˆæœ¬å˜æ›´å¯¼è‡´åˆ—åå˜åŒ–ï¼Œåº”è®°å½• warning å¹¶é™çº§ä¸ºè¯¥ä¸»é¢˜å¤±è´¥ï¼ˆè¿”å› `None`ï¼‰ã€‚

**è¿”å›å­—æ®µç¤ºä¾‹ï¼š**
```
         item                value
0       æ€»å¸‚å€¼        2156.80äº¿
1     æµé€šå¸‚å€¼        2156.80äº¿
2        è¡Œä¸š               é“¶è¡Œ
3     ä¸Šå¸‚æ—¶é—´        1991-04-03
4      æ€»è‚¡æœ¬      194.06äº¿
5     æµé€šè‚¡      194.06äº¿
...
```

**é‡‡é›†å…¥å£ï¼ˆ`_collect_company_info`ï¼‰ï¼š**

```python
def _collect_company_info(self) -> dict | None:
    """é‡‡é›†å…¬å¸åŸºæœ¬ä¿¡æ¯ã€‚"""
    df = self.safe_call(
        "company_info",
        ak.stock_individual_info_em,
        symbol=self.symbol,
    )
    if df is None:
        return None

    # è¯¥æ¥å£æ˜¯ item-value ç»“æ„ï¼Œå…ˆæ ¡éªŒå…³é”®åˆ—æ˜¯å¦å­˜åœ¨
    required_cols = {"item", "value"}
    missing_cols = required_cols - set(df.columns)
    if missing_cols:
        msg = (
            "company_info: ç¼ºå°‘å…³é”®åˆ— "
            f"{sorted(missing_cols)}ï¼Œæ— æ³•è§£æ item-value ç»“æ„"
        )
        self.errors.append(msg)
        logger.warning(msg)
        return None

    # è§£æé˜¶æ®µå¼‚å¸¸ç”± _safe_collect() å…œåº•
    return self._parse_company_info(df)
```

**è§£æé€»è¾‘ï¼ˆ`_parse_company_info` + `_parse_number`ï¼‰ï¼š**

```python
def _parse_company_info(self, df: pd.DataFrame) -> dict:
    """å°† item-value æ ¼å¼çš„ DataFrame è§£æä¸ºå­—å…¸ã€‚"""
    info = {}
    lookup = dict(zip(df["item"], df["value"]))

    info["industry"] = str(lookup.get("è¡Œä¸š", ""))
    info["listing_date"] = str(lookup.get("ä¸Šå¸‚æ—¶é—´", ""))

    # æ•°å€¼å­—æ®µï¼šç»Ÿä¸€æ¢ç®—åˆ°"äº¿"ï¼ˆ_parse_number ä¼šè‡ªåŠ¨è¯†åˆ«"ä¸‡/äº¿"å•ä½ï¼‰
    info["total_market_cap"] = self._parse_number(lookup.get("æ€»å¸‚å€¼"), target_unit="äº¿")
    info["circulating_market_cap"] = self._parse_number(lookup.get("æµé€šå¸‚å€¼"), target_unit="äº¿")
    info["total_shares"] = self._parse_number(lookup.get("æ€»è‚¡æœ¬"), target_unit="äº¿")
    info["circulating_shares"] = self._parse_number(lookup.get("æµé€šè‚¡"), target_unit="äº¿")

    return info

@staticmethod
def _parse_number(value, target_unit: str = "äº¿") -> float | None:
    """è§£æ AKShare è¿”å›çš„æ•°å€¼å­—æ®µï¼ˆå¯èƒ½å«ä¸­æ–‡å•ä½ï¼‰ï¼Œç»Ÿä¸€æ¢ç®—åˆ°ç›®æ ‡å•ä½ã€‚

    AKShare ä¸åŒæ¥å£è¿”å›çš„æ•°å€¼å¯èƒ½å¸¦"äº¿"æˆ–"ä¸‡"å•ä½ï¼Œæœ¬æ–¹æ³•ä¼š
    è¯†åˆ«å•ä½å¹¶æ¢ç®—åˆ° target_unitï¼Œé¿å…é‡çº§é”™è¯¯ã€‚

    Args:
        value: åŸå§‹å€¼ï¼ˆstr / float / Noneï¼‰
        target_unit: ç›®æ ‡å•ä½ï¼Œ"äº¿" æˆ– "ä¸‡"ï¼Œé»˜è®¤ "äº¿"

    ç¤ºä¾‹ï¼ˆtarget_unit="äº¿"ï¼‰ï¼š
        "2156.80äº¿" â†’ 2156.80   ï¼ˆåŒå•ä½ï¼Œç›´æ¥å–æ•°ï¼‰
        "194.06äº¿"  â†’ 194.06
        "19406ä¸‡"   â†’ 1.9406    ï¼ˆä¸‡ â†’ äº¿ï¼ŒÃ· 10000ï¼‰
        "3.5"       â†’ 3.5       ï¼ˆæ— å•ä½ï¼Œå‡å®šå·²æ˜¯ç›®æ ‡å•ä½ï¼‰
        "-"          â†’ None
        None         â†’ None
    """
    if value is None:
        return None
    s = str(value).strip().replace(",", "")
    if s in ("", "-", "--", "nan"):
        return None

    # è¯†åˆ«å•ä½å¹¶æå–æ•°å€¼
    multiplier = 1.0
    if s.endswith("äº¿"):
        s = s[:-1]
        if target_unit == "ä¸‡":
            multiplier = 10000.0   # äº¿ â†’ ä¸‡
    elif s.endswith("ä¸‡"):
        s = s[:-1]
        if target_unit == "äº¿":
            multiplier = 0.0001    # ä¸‡ â†’ äº¿
    # æ— å•ä½ï¼šå‡å®šå·²æ˜¯ç›®æ ‡å•ä½ï¼Œmultiplier ä¿æŒ 1.0

    try:
        return round(float(s) * multiplier, 4)
    except (ValueError, TypeError):
        return None
```

### 6.2 ä¸»é¢˜â‘¡ å®æ—¶è¡Œæƒ…å¿«ç…§

**AKShare å‡½æ•°ï¼š** `ak.stock_zh_a_spot_em()`

**å…¥å‚æ ¼å¼ï¼š** æ— å‚æ•°ï¼ˆè¿”å›å…¨å¸‚åœº 5000+ åªè‚¡ç¥¨ï¼‰

**âš ï¸ æ³¨æ„ï¼š** å¿…é¡»ä»ç»“æœä¸­æŒ‰è‚¡ç¥¨ä»£ç è¿‡æ»¤

**è¿”å›å­—æ®µï¼ˆç­›é€‰åï¼‰ï¼š**
| DataFrame åˆ—å | è¾“å‡ºå­—æ®µ | è¯´æ˜ |
|----------------|---------|------|
| `æœ€æ–°ä»·` | `price` | å½“å‰ä»·æ ¼ |
| `æ¶¨è·Œå¹…` | `change_pct` | å½“æ—¥æ¶¨è·Œå¹…(%) |
| `æˆäº¤é‡` | `volume` | æˆäº¤é‡ï¼ˆæ‰‹ï¼‰ |
| `æˆäº¤é¢` | `turnover` | æˆäº¤é¢ï¼ˆå…ƒï¼‰ |
| `å¸‚ç›ˆç‡-åŠ¨æ€` | `pe_ttm` | åŠ¨æ€å¸‚ç›ˆç‡ |
| `å¸‚å‡€ç‡` | `pb` | å¸‚å‡€ç‡ |
| `æ¢æ‰‹ç‡` | `turnover_rate` | æ¢æ‰‹ç‡(%) |
| `é‡æ¯”` | `volume_ratio` | é‡æ¯” |
| `60æ—¥æ¶¨è·Œå¹…` | `change_60d_pct` | è¿‘60æ—¥æ¶¨è·Œå¹…(%) |
| `å¹´åˆè‡³ä»Šæ¶¨è·Œå¹…` | `change_ytd_pct` | å¹´åˆè‡³ä»Šæ¶¨è·Œå¹…(%) |

**è§£æé€»è¾‘ï¼š**

```python
def _collect_realtime_quote(self) -> dict | None:
    """é‡‡é›†å®æ—¶è¡Œæƒ…å¿«ç…§ã€‚"""
    df = self.safe_call_market_cached(
        "stock_zh_a_spot_em",
        "realtime_quote",
        ak.stock_zh_a_spot_em,
    )
    if df is None:
        return None

    row = self._safe_filter(df, "ä»£ç ", self.symbol, "realtime_quote")
    if row.empty:
        msg = f"realtime_quote: å…¨å¸‚åœºæ•°æ®ä¸­æœªæ‰¾åˆ° {self.symbol}"
        self.errors.append(msg)
        logger.warning(msg)
        return None

    r = row.iloc[0]
    return {
        "price": self._safe_float(r.get("æœ€æ–°ä»·")),
        "change_pct": self._safe_float(r.get("æ¶¨è·Œå¹…")),
        "volume": self._safe_float(r.get("æˆäº¤é‡")),
        "turnover": self._safe_float(r.get("æˆäº¤é¢")),
        "pe_ttm": self._safe_float(r.get("å¸‚ç›ˆç‡-åŠ¨æ€")),
        "pb": self._safe_float(r.get("å¸‚å‡€ç‡")),
        "turnover_rate": self._safe_float(r.get("æ¢æ‰‹ç‡")),
        "volume_ratio": self._safe_float(r.get("é‡æ¯”")),
        "change_60d_pct": self._safe_float(r.get("60æ—¥æ¶¨è·Œå¹…")),
        "change_ytd_pct": self._safe_float(r.get("å¹´åˆè‡³ä»Šæ¶¨è·Œå¹…")),
    }

@staticmethod
def _safe_float(value) -> float | None:
    """å®‰å…¨è½¬æ¢ä¸º floatï¼Œå¤„ç†å„ç§éæ³•å€¼ã€‚"""
    if value is None or (isinstance(value, float) and pd.isna(value)):
        return None
    try:
        return float(value)
    except (ValueError, TypeError):
        return None

@staticmethod
def _safe_int(value) -> int | None:
    """å®‰å…¨è½¬æ¢ä¸º intï¼Œå¤„ç†åƒåˆ†ä½å’Œæµ®ç‚¹å­—ç¬¦ä¸²ã€‚"""
    if value is None or (isinstance(value, float) and pd.isna(value)):
        return None
    s = str(value).replace(",", "").strip()
    if s in ("", "-", "--", "nan"):
        return None
    try:
        return int(float(s))
    except (ValueError, TypeError):
        return None
```

### 6.3 ä¸»é¢˜â‘¢ è´¢åŠ¡åˆ†ææŒ‡æ ‡

**AKShare å‡½æ•°ï¼š** `ak.stock_financial_analysis_indicator(stock)`

**å…¥å‚æ ¼å¼ï¼š** `bare`ï¼ˆå‚æ•°åæ˜¯ `stock`ï¼Œä¸æ˜¯ `symbol`ï¼‰

**è¿”å›æ ¼å¼ï¼š** DataFrameï¼Œ65+ åˆ—è´¢åŠ¡æŒ‡æ ‡ï¼ŒæŒ‰æŠ¥å‘ŠæœŸæ’åˆ—

**å…³é”®å­—æ®µæå–ï¼š**
| DataFrame åˆ—å | è¾“å‡ºå­—æ®µ | è¯´æ˜ |
|----------------|---------|------|
| `æŠ¥å‘ŠæœŸ` | `report_date` | æŠ¥å‘ŠæœŸæ—¥æœŸ |
| `æ‘Šè–„æ¯è‚¡æ”¶ç›Š(å…ƒ)` | `eps` | æ¯è‚¡æ”¶ç›Š |
| `æ¯è‚¡å‡€èµ„äº§_è°ƒæ•´å(å…ƒ)` | `net_asset_per_share` | æ¯è‚¡å‡€èµ„äº§ |
| `å‡€èµ„äº§æ”¶ç›Šç‡_æ‘Šè–„(%)` | `roe` | ROEï¼ˆæ‘Šè–„ï¼‰ |
| `é”€å”®æ¯›åˆ©ç‡(%)` | `gross_margin` | æ¯›åˆ©ç‡ |
| `é”€å”®å‡€åˆ©ç‡(%)` | `net_margin` | å‡€åˆ©ç‡ |
| `è¥ä¸šæ€»æ”¶å…¥åŒæ¯”å¢é•¿ç‡(%)` | `revenue_growth` | è¥æ”¶å¢é•¿ç‡ |
| `å½’å±æ¯å…¬å¸è‚¡ä¸œçš„å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡(%)` | `profit_growth` | å‡€åˆ©æ¶¦å¢é•¿ç‡ |
| `èµ„äº§è´Ÿå€ºç‡(%)` | `debt_ratio` | èµ„äº§è´Ÿå€ºç‡ |
| `æµåŠ¨æ¯”ç‡` | `current_ratio` | æµåŠ¨æ¯”ç‡ |

**âš ï¸ æ³¨æ„ï¼š** é“¶è¡Œè‚¡éƒ¨åˆ†æŒ‡æ ‡ï¼ˆå¦‚æ¯›åˆ©ç‡ã€æµåŠ¨æ¯”ç‡ï¼‰å¯èƒ½ä¸ºç©ºï¼Œå±äºæ­£å¸¸æƒ…å†µã€‚
**âš ï¸ æ’åºæ³¨æ„ï¼š** ä¸ä¾èµ– AKShare è¿”å›é¡ºåºã€‚éœ€å…ˆæŒ‰æŠ¥å‘ŠæœŸæ˜¾å¼é™åºï¼Œå†å–æœ€è¿‘ N æœŸã€‚

**è§£æé€»è¾‘ï¼š**

```python
def _collect_financial_indicators(self) -> list[dict] | None:
    """é‡‡é›†è´¢åŠ¡åˆ†ææŒ‡æ ‡ï¼ˆå–æœ€è¿‘ N æœŸï¼‰ã€‚"""
    df = self.safe_call(
        "financial_indicators",
        ak.stock_financial_analysis_indicator,
        stock=self.symbol,
    )
    if df is None:
        return None

    # æ˜¾å¼æ’åºåå†æˆªå–ï¼Œé¿å…ä¾èµ– AKShare é»˜è®¤è¿”å›é¡ºåº
    if "æŠ¥å‘ŠæœŸ" in df.columns:
        df = (
            df.assign(_report_date=pd.to_datetime(df["æŠ¥å‘ŠæœŸ"], errors="coerce"))
            .sort_values("_report_date", ascending=False, na_position="last")
            .drop(columns=["_report_date"])
        )
    else:
        msg = "financial_indicators: ç¼ºå°‘åˆ— 'æŠ¥å‘ŠæœŸ'ï¼ŒæŒ‰åŸå§‹é¡ºåºæˆªå–æœ€è¿‘NæœŸ"
        self.errors.append(msg)
        logger.warning(msg)

    # å–æœ€è¿‘ N æœŸ
    df = df.head(AKSHARE_FINANCIAL_PERIODS)

    results = []
    for _, row in df.iterrows():
        results.append({
            "report_date": str(row.get("æŠ¥å‘ŠæœŸ", "")),
            "eps": self._safe_float(row.get("æ‘Šè–„æ¯è‚¡æ”¶ç›Š(å…ƒ)")),
            "net_asset_per_share": self._safe_float(
                row.get("æ¯è‚¡å‡€èµ„äº§_è°ƒæ•´å(å…ƒ)")
            ),
            "roe": self._safe_float(row.get("å‡€èµ„äº§æ”¶ç›Šç‡_æ‘Šè–„(%)")),
            "gross_margin": self._safe_float(row.get("é”€å”®æ¯›åˆ©ç‡(%)")),
            "net_margin": self._safe_float(row.get("é”€å”®å‡€åˆ©ç‡(%)")),
            "revenue_growth": self._safe_float(
                row.get("è¥ä¸šæ€»æ”¶å…¥åŒæ¯”å¢é•¿ç‡(%)")
            ),
            "profit_growth": self._safe_float(
                row.get("å½’å±æ¯å…¬å¸è‚¡ä¸œçš„å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡(%)")
            ),
            "debt_ratio": self._safe_float(row.get("èµ„äº§è´Ÿå€ºç‡(%)")),
            "current_ratio": self._safe_float(row.get("æµåŠ¨æ¯”ç‡")),
        })

    return results
```

### 6.4 ä¸»é¢˜â‘£ ä¼°å€¼å†å²æ•°æ®

**AKShare å‡½æ•°ï¼š** `ak.stock_a_lg_indicator(stock)`

**å…¥å‚æ ¼å¼ï¼š** `bare`ï¼ˆå‚æ•°åæ˜¯ `stock`ï¼‰

**è¿”å›æ ¼å¼ï¼š** DataFrameï¼Œ**è‹±æ–‡åˆ—å**ï¼ˆAKShare å°‘æ•°ä½¿ç”¨è‹±æ–‡åˆ—åçš„å‡½æ•°ï¼‰

**å…³é”®åˆ—ï¼š** `trade_date`, `pe`, `pe_ttm`, `pb`, `ps`, `ps_ttm`, `dv_ratio`, `dv_ttm`, `total_mv`
**âš ï¸ æ’åºæ³¨æ„ï¼š** ä¸ä¾èµ– AKShare è¿”å›é¡ºåºã€‚éœ€å…ˆæŒ‰ `trade_date` æ˜¾å¼å‡åºï¼Œå†å– `iloc[-1]` ä½œä¸ºå½“å‰å€¼ã€‚

**æ ¸å¿ƒè®¡ç®— â€” å†å²åˆ†ä½æ•°ï¼š**

```python
def _collect_valuation_history(self) -> dict | None:
    """é‡‡é›†ä¼°å€¼å†å²æ•°æ®ï¼Œè®¡ç®—å½“å‰ä¼°å€¼çš„å†å²åˆ†ä½æ•°ã€‚"""
    df = self.safe_call(
        "valuation_history",
        ak.stock_a_lg_indicator,
        stock=self.symbol,
    )
    if df is None:
        return None

    # æ˜¾å¼æ’åºåå†å–â€œæœ€æ–°å€¼â€ï¼Œé¿å…ä¾èµ– AKShare é»˜è®¤è¿”å›é¡ºåº
    if "trade_date" in df.columns:
        df = (
            df.assign(_trade_date=pd.to_datetime(df["trade_date"], errors="coerce"))
            .sort_values("_trade_date", ascending=True, na_position="last")
            .drop(columns=["_trade_date"])
        )
    else:
        msg = "valuation_history: ç¼ºå°‘åˆ— 'trade_date'ï¼ŒæŒ‰åŸå§‹é¡ºåºè®¡ç®—å½“å‰å€¼ä¸åˆ†ä½æ•°"
        self.errors.append(msg)
        logger.warning(msg)

    # å–æœ€æ–°ä¸€è¡Œä½œä¸ºå½“å‰å€¼
    latest = df.iloc[-1]

    current_pe_ttm = self._safe_float(latest.get("pe_ttm"))
    current_pb = self._safe_float(latest.get("pb"))

    # è®¡ç®—åˆ†ä½æ•°ï¼ˆåˆ—ç¼ºå¤±æ—¶ä»…é™çº§è¯¥å­—æ®µï¼Œä¸è®©æ•´ä¸ªä¸»é¢˜å¤±è´¥ï¼‰
    pe_series = df.get("pe_ttm")
    if pe_series is None:
        msg = "valuation_history: ç¼ºå°‘åˆ— 'pe_ttm'ï¼Œpe_percentile ç½®ä¸º None"
        self.errors.append(msg)
        logger.warning(msg)
        pe_percentile = None
    else:
        pe_percentile = self._calc_percentile(pe_series, latest.get("pe_ttm"))

    pb_series = df.get("pb")
    if pb_series is None:
        msg = "valuation_history: ç¼ºå°‘åˆ— 'pb'ï¼Œpb_percentile ç½®ä¸º None"
        self.errors.append(msg)
        logger.warning(msg)
        pb_percentile = None
    else:
        pb_percentile = self._calc_percentile(pb_series, latest.get("pb"))

    # ç”Ÿæˆç®€è¦æè¿°
    pe_desc = self._percentile_description("PE", pe_percentile)
    pb_desc = self._percentile_description("PB", pb_percentile)

    return {
        "current_pe_ttm": current_pe_ttm,
        "current_pb": current_pb,
        "pe_percentile": pe_percentile,
        "pb_percentile": pb_percentile,
        "current_ps_ttm": self._safe_float(latest.get("ps_ttm")),
        "current_dv_ttm": self._safe_float(latest.get("dv_ttm")),
        "history_summary": f"{pe_desc}ï¼›{pb_desc}",
    }

@staticmethod
def _calc_percentile(series: pd.Series, current_value) -> float | None:
    """è®¡ç®—å½“å‰å€¼åœ¨å†å²åºåˆ—ä¸­çš„ç™¾åˆ†ä½æ•°ã€‚

    Returns:
        ç™¾åˆ†ä½æ•°ï¼ˆ0-100ï¼‰ï¼Œæˆ– Noneï¼ˆæ•°æ®ä¸è¶³æ—¶ï¼‰
    """
    # å…ˆæ•°å€¼åŒ–ï¼Œé¿å…å­—ç¬¦ä¸²/æ··åˆç±»å‹æ¯”è¾ƒå¯¼è‡´åˆ†ä½æ•°é”™è¯¯
    clean = pd.to_numeric(series, errors="coerce").dropna()
    current_numeric = pd.to_numeric(current_value, errors="coerce")
    if len(clean) < 10 or pd.isna(current_numeric):
        return None
    rank = (clean < float(current_numeric)).sum()
    return round(rank / len(clean) * 100, 1)

@staticmethod
def _percentile_description(indicator: str, percentile: float | None) -> str:
    """æ ¹æ®åˆ†ä½æ•°ç”Ÿæˆæè¿°ã€‚"""
    if percentile is None:
        return f"{indicator}å†å²åˆ†ä½æ•°æ®ä¸è¶³"
    if percentile < 20:
        level = "æä½ä½ç½®ï¼ˆå†å²åº•éƒ¨åŒºåŸŸï¼‰"
    elif percentile < 40:
        level = "åä½ä½ç½®"
    elif percentile < 60:
        level = "ä¸­ç­‰ä½ç½®"
    elif percentile < 80:
        level = "åé«˜ä½ç½®"
    else:
        level = "æé«˜ä½ç½®ï¼ˆå†å²é¡¶éƒ¨åŒºåŸŸï¼‰"
    return f"{indicator}å†å²åˆ†ä½{percentile}%ï¼Œå¤„äº{level}"
```

### 6.5 ä¸»é¢˜â‘¤ è¡Œä¸šä¼°å€¼å¯¹æ¯”

**AKShare å‡½æ•°ï¼š** `ak.stock_zh_valuation_comparison_em(symbol)`

**å…¥å‚æ ¼å¼ï¼š** `upper`ï¼ˆå¤§å†™å‰ç¼€ï¼Œå¦‚ `"SZ000001"`ï¼‰

```python
def _collect_valuation_vs_industry(self) -> dict | None:
    """é‡‡é›†è¡Œä¸šä¼°å€¼å¯¹æ¯”æ•°æ®ã€‚"""
    upper_symbol = format_symbol(self.symbol, "upper")
    df = self.safe_call(
        "valuation_vs_industry",
        ak.stock_zh_valuation_comparison_em,
        symbol=upper_symbol,
    )
    if df is None:
        return None

    # æå–ä¸ªè‚¡å’Œè¡Œä¸šçš„ PE/PB å¯¹æ¯”
    # âš ï¸ æ³¨æ„ï¼šè¯¥å‡½æ•°è¿”å›çš„åˆ—åå¯èƒ½éš AKShare ç‰ˆæœ¬å˜åŒ–ï¼Œéœ€è¦åšé˜²å¾¡æ€§è§£æ
    row = df.iloc[0] if len(df) > 0 else {}
    return {
        "stock_pe": self._safe_float(row.get("ä¸ªè‚¡PE")),
        "industry_avg_pe": self._safe_float(row.get("è¡Œä¸šPE(å¹³å‡)")),
        "industry_median_pe": self._safe_float(row.get("è¡Œä¸šPE(ä¸­ä½æ•°)")),
        "stock_pb": self._safe_float(row.get("ä¸ªè‚¡PB")),
        "industry_avg_pb": self._safe_float(row.get("è¡Œä¸šPB(å¹³å‡)")),
        "relative_valuation": self._judge_relative_valuation(
            self._safe_float(row.get("ä¸ªè‚¡PE")),
            self._safe_float(row.get("è¡Œä¸šPE(å¹³å‡)")),
        ),
    }

@staticmethod
def _judge_relative_valuation(
    stock_pe: float | None, industry_pe: float | None
) -> str:
    """åˆ¤æ–­ä¸ªè‚¡ä¼°å€¼ç›¸å¯¹è¡Œä¸šçš„ä½ç½®ã€‚"""
    # PE<=0ï¼ˆäºæŸï¼‰æ—¶ä¸åšç›¸å¯¹ä¼°å€¼æ¯”è¾ƒï¼Œé¿å…äº§ç”Ÿè¯¯å¯¼æ€§ç»“è®º
    if stock_pe is None or industry_pe is None or stock_pe <= 0 or industry_pe <= 0:
        return "æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­"
    ratio = stock_pe / industry_pe
    if ratio < 0.8:
        return "æ˜æ˜¾ä½äºè¡Œä¸šå¹³å‡"
    elif ratio < 0.95:
        return "ç•¥ä½äºè¡Œä¸šå¹³å‡"
    elif ratio < 1.05:
        return "æ¥è¿‘è¡Œä¸šå¹³å‡"
    elif ratio < 1.2:
        return "ç•¥é«˜äºè¡Œä¸šå¹³å‡"
    else:
        return "æ˜æ˜¾é«˜äºè¡Œä¸šå¹³å‡"
```

### 6.6 ä¸»é¢˜â‘¥ ä¸ªè‚¡èµ„é‡‘æµå‘

**AKShare å‡½æ•°ï¼š** `ak.stock_individual_fund_flow(stock, market)`

**å…¥å‚æ ¼å¼ï¼š** `bare` + `market` å‚æ•°

**çª—å£è¯´æ˜ï¼š**
- `recent_days` æ˜ç»†çª—å£ç”± `AKSHARE_FUND_FLOW_DAYS` æ§åˆ¶ï¼ˆå±•ç¤ºç”¨ï¼‰ï¼›
- `summary` å›ºå®šè¾“å‡º `5æ—¥` ä¸ `10æ—¥` æ±‡æ€»ï¼ˆä¸ä¸‹æ¸¸ schema å­—æ®µåå¯¹é½ï¼‰ï¼›
- è‹¥å†å²æ•°æ®ä¸è¶³ 5/10 æ—¥ï¼Œå¯¹åº”æ±‡æ€»å­—æ®µç½® `None` å¹¶è®°å½• warningï¼Œé¿å…â€œ3æ—¥æ•°æ®è¢«æ ‡æ³¨ä¸º5æ—¥æ±‡æ€»â€ã€‚
**âš ï¸ æ’åºæ³¨æ„ï¼š** ä¸ä¾èµ– AKShare è¿”å›é¡ºåºã€‚éœ€å…ˆæŒ‰ `æ—¥æœŸ` æ˜¾å¼å‡åºï¼Œå†ä½¿ç”¨ `tail()` å–æœ€è¿‘ N æ—¥ã€‚

```python
def _collect_fund_flow(self) -> dict | None:
    """é‡‡é›†ä¸ªè‚¡èµ„é‡‘æµå‘æ•°æ®ã€‚"""
    market = get_market(self.symbol)
    df = self.safe_call(
        "fund_flow",
        ak.stock_individual_fund_flow,
        stock=self.symbol,
        market=market,
    )
    if df is None:
        return None

    # æ˜¾å¼æ’åºåå†åš tailï¼Œé¿å…ä¾èµ– AKShare é»˜è®¤è¿”å›é¡ºåº
    if "æ—¥æœŸ" in df.columns:
        df = (
            df.assign(_flow_date=pd.to_datetime(df["æ—¥æœŸ"], errors="coerce"))
            .sort_values("_flow_date", ascending=True, na_position="last")
            .drop(columns=["_flow_date"])
        )
    else:
        msg = "fund_flow: ç¼ºå°‘åˆ— 'æ—¥æœŸ'ï¼ŒæŒ‰åŸå§‹é¡ºåºè®¡ç®—æ˜ç»†ä¸æ±‡æ€»"
        self.errors.append(msg)
        logger.warning(msg)

    # å–æœ€è¿‘ N å¤©æ˜ç»†
    recent = df.tail(AKSHARE_FUND_FLOW_DAYS)
    detail = []
    for _, row in recent.iterrows():
        detail.append({
            "date": str(row.get("æ—¥æœŸ", "")),
            "main_net_inflow": self._safe_float(row.get("ä¸»åŠ›å‡€æµå…¥-å‡€é¢")),
            "main_net_inflow_pct": self._safe_float(
                row.get("ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”")
            ),
        })

    # æ±‡æ€»ç»Ÿè®¡ï¼ˆå›ºå®š 5æ—¥/10æ—¥çª—å£ï¼Œä¸ schema ä¿æŒä¸€è‡´ï¼‰
    summary_5d_window = 5
    summary_10d_window = 10
    main_col = "ä¸»åŠ›å‡€æµå…¥-å‡€é¢"
    total_5d = None
    total_10d = None
    if main_col in df.columns:
        if len(df) >= summary_5d_window:
            total_5d = self._safe_float(
                df.tail(summary_5d_window)[main_col].sum()
            )
        else:
            msg = (
                f"fund_flow: å†å²æ•°æ®ä¸è¶³ {summary_5d_window} æ—¥ï¼Œ"
                "main_net_inflow_5d_total ç½®ä¸º None"
            )
            self.errors.append(msg)
            logger.warning(msg)

        if len(df) >= summary_10d_window:
            total_10d = self._safe_float(
                df.tail(summary_10d_window)[main_col].sum()
            )
        else:
            msg = (
                f"fund_flow: å†å²æ•°æ®ä¸è¶³ {summary_10d_window} æ—¥ï¼Œ"
                "main_net_inflow_10d_total ç½®ä¸º None"
            )
            self.errors.append(msg)
            logger.warning(msg)
    else:
        msg = "fund_flow: ç¼ºå°‘åˆ— 'ä¸»åŠ›å‡€æµå…¥-å‡€é¢'ï¼Œæ±‡æ€»å­—æ®µç½®ä¸º None"
        self.errors.append(msg)
        logger.warning(msg)

    trend = self._judge_fund_flow_trend(total_5d, total_10d)

    return {
        "recent_days": detail,
        "summary": {
            "main_net_inflow_5d_total": total_5d,
            "main_net_inflow_10d_total": total_10d,
            "trend": trend,
        },
    }

@staticmethod
def _judge_fund_flow_trend(
    total_5d: float | None, total_10d: float | None
) -> str:
    """æ ¹æ®èµ„é‡‘æµå‘è¶‹åŠ¿ç”Ÿæˆæè¿°ã€‚"""
    parts = []
    if total_5d is not None:
        direction = "å‡€æµå…¥" if total_5d >= 0 else "å‡€æµå‡º"
        parts.append(f"è¿‘5æ—¥ä¸»åŠ›{direction}")
    if total_10d is not None:
        direction = "å‡€æµå…¥" if total_10d >= 0 else "å‡€æµå‡º"
        parts.append(f"è¿‘10æ—¥æ•´ä½“{direction}")
    return "ï¼Œ".join(parts) if parts else "æ•°æ®ä¸è¶³"
```

### 6.7 ä¸»é¢˜â‘¦ æ¿å—èµ„é‡‘æµå‘

**AKShare å‡½æ•°ï¼š**
- `ak.stock_board_industry_fund_flow_rank_em(indicator="ä»Šæ—¥")`
- `ak.stock_board_concept_fund_flow_rank_em(indicator="ä»Šæ—¥")`

**âš ï¸ æ³¨æ„ï¼š** éœ€è¦å…ˆçŸ¥é“ç›®æ ‡è‚¡ç¥¨æ‰€å±è¡Œä¸šï¼ˆä»ä¸»é¢˜â‘ è·å–ï¼‰ï¼Œå†ä»å…¨å¸‚åœºæ¿å—æ•°æ®ä¸­æŸ¥æ‰¾ã€‚
**âš ï¸ åŒ¹é…æ³¨æ„ï¼š** è¡Œä¸šåŒ¹é…ä¼˜å…ˆ `eq` ç²¾ç¡®å‘½ä¸­ï¼Œæœªå‘½ä¸­æ‰å›é€€ `contains`ï¼ˆå¹¶è®°å½• warningï¼‰ã€‚
**âš ï¸ æ’åºæ³¨æ„ï¼š** çƒ­é—¨æ¦‚å¿µ Top5 ä¼˜å…ˆæŒ‰æ˜¾å¼æ’ååˆ—æ’åºï¼›è‹¥æ— æ’ååˆ—ï¼ŒæŒ‰ `ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢` é™åºæ’åºï¼Œå†æˆªå–å‰ 5ã€‚

```python
def _collect_sector_flow(self, industry: str) -> dict | None:
    """é‡‡é›†æ¿å—èµ„é‡‘æµå‘æ•°æ®ã€‚

    Args:
        industry: ç›®æ ‡è‚¡ç¥¨æ‰€å±è¡Œä¸šåç§°ï¼ˆä»ä¸»é¢˜â‘ è·å–ï¼‰
    """
    result: dict = {}

    # è¡Œä¸šæ¿å—èµ„é‡‘æµå‘
    df_industry = self.safe_call_market_cached(
        "stock_board_industry_fund_flow_rank_em:ä»Šæ—¥",
        "sector_flow_industry",
        ak.stock_board_industry_fund_flow_rank_em,
        indicator="ä»Šæ—¥",
    )
    if df_industry is not None and industry:
        # å…ˆç²¾ç¡®åŒ¹é…ï¼Œé¿å…â€œç™½é…’/ç™½é…’â…¡â€ç­‰ç›¸ä¼¼åç§°è¯¯å‘½ä¸­
        match = self._safe_filter(
            df_industry, "åç§°", industry,
            "sector_flow_industry", method="eq",
        )
        if match.empty:
            fuzzy_match = self._safe_filter(
                df_industry, "åç§°", industry,
                "sector_flow_industry", method="contains",
            )
            if not fuzzy_match.empty:
                hit_name = str(fuzzy_match.iloc[0].get("åç§°", ""))
                msg = (
                    f"sector_flow_industry: è¡Œä¸š '{industry}' æœªç²¾ç¡®å‘½ä¸­ï¼Œ"
                    f"å›é€€åˆ°åŒ…å«åŒ¹é…å¹¶å‘½ä¸­ '{hit_name}'"
                )
                self.errors.append(msg)
                logger.warning(msg)
                match = fuzzy_match
        if not match.empty:
            row = match.iloc[0]
            result["industry_name"] = industry

            # æ’åè·å–ä¼˜å…ˆçº§ï¼š
            # 1) è‹¥å­˜åœ¨æ˜¾å¼æ’ååˆ—ï¼Œä¼˜å…ˆä½¿ç”¨è¯¥åˆ—ï¼›
            # 2) å¦åˆ™å›é€€åˆ°â€œå½“å‰ DataFrame é¡ºåºâ€çš„è¡Œä½ç½®ï¼ˆreset_index åï¼‰+1ã€‚
            rank_col = None
            for c in ("æ’å", "åºå·", "åæ¬¡"):
                if c in df_industry.columns:
                    rank_col = c
                    break

            if rank_col is not None:
                rank_val = self._safe_float(row.get(rank_col))
                result["industry_rank"] = (
                    int(rank_val) if rank_val is not None else None
                )
            else:
                # è¿™é‡Œçš„æ’åè¯­ä¹‰æ˜¯â€œæŒ‰å½“å‰è¿”å›é¡ºåºçš„ç›¸å¯¹ä½ç½®â€ï¼Œä¸ä¾èµ–åŸå§‹ index
                pos_df = df_industry.reset_index(drop=True)
                matched_name = str(row.get("åç§°", ""))
                pos_match = self._safe_filter(
                    pos_df, "åç§°", matched_name,
                    "sector_flow_industry", method="eq",
                )
                if pos_match.empty and matched_name:
                    pos_match = self._safe_filter(
                        pos_df, "åç§°", matched_name,
                        "sector_flow_industry", method="contains",
                    )
                result["industry_rank"] = (
                    int(pos_match.index[0]) + 1 if not pos_match.empty else None
                )

            result["industry_net_inflow_today"] = self._safe_float(
                row.get("ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢")
            )
        else:
            msg = (
                f"sector_flow_industry: è¡Œä¸š '{industry}' åœ¨æ¿å—æ•°æ®ä¸­"
                "ç²¾ç¡®å’Œæ¨¡ç³ŠåŒ¹é…å‡æœªå‘½ä¸­"
            )
            self.errors.append(msg)
            logger.warning(msg)
            result["industry_name"] = industry
            result["industry_rank"] = None
            result["industry_net_inflow_today"] = None

    # æ¦‚å¿µæ¿å—ï¼ˆè·å–å…¨å¸‚åœºçƒ­é—¨æ¦‚å¿µ Top 5ï¼‰
    df_concept = self.safe_call_market_cached(
        "stock_board_concept_fund_flow_rank_em:ä»Šæ—¥",
        "sector_flow_concept",
        ak.stock_board_concept_fund_flow_rank_em,
        indicator="ä»Šæ—¥",
    )
    if df_concept is not None:
        # æ˜¾å¼æ’åºåå†æˆªå– Top5ï¼Œé¿å…ä¾èµ– AKShare é»˜è®¤è¿”å›é¡ºåº
        concept_sorted = df_concept
        concept_rank_col = None
        for c in ("æ’å", "åºå·", "åæ¬¡"):
            if c in df_concept.columns:
                concept_rank_col = c
                break

        if concept_rank_col is not None:
            concept_sorted = (
                df_concept.assign(
                    _rank_num=pd.to_numeric(df_concept[concept_rank_col], errors="coerce")
                )
                .sort_values("_rank_num", ascending=True, na_position="last")
                .drop(columns=["_rank_num"])
            )
        elif "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢" in df_concept.columns:
            concept_sorted = (
                df_concept.assign(
                    _inflow_num=pd.to_numeric(df_concept["ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢"], errors="coerce")
                )
                .sort_values("_inflow_num", ascending=False, na_position="last")
                .drop(columns=["_inflow_num"])
            )
        else:
            msg = (
                "sector_flow_concept: ç¼ºå°‘æ’åºåˆ—ï¼ˆæ’å/åºå·/åæ¬¡/ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢ï¼‰ï¼Œ"
                "æŒ‰åŸå§‹é¡ºåºæˆªå– Top5"
            )
            self.errors.append(msg)
            logger.warning(msg)

        top5 = concept_sorted.head(5)
        result["hot_concepts_top5"] = [
            {
                "name": str(row.get("åç§°", "")),
                "net_inflow": self._safe_float(row.get("ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢")),
            }
            for _, row in top5.iterrows()
        ]
    # df_concept ä¸º None æ—¶ä¸å¼ºè¡Œå†™å…¥ç©ºåˆ—è¡¨ï¼š
    # è®© result ä¿æŒâ€œçœŸå®é‡‡é›†æˆåŠŸè¯­ä¹‰â€ï¼Œé¿å…åœ¨ä¸¤è·¯ API éƒ½å¤±è´¥æ—¶è¢«è¯¯åˆ¤ä¸º STATUS_OK

    return result if result else None
```

### 6.8 ä¸»é¢˜â‘§ åŒ—å‘èµ„é‡‘æŒä»“

**AKShare å‡½æ•°ï¼š** `ak.stock_hsgt_hold_stock_em(market="åŒ—å‘", indicator="ä»Šæ—¥æ’è¡Œ")`

**âš ï¸ ç‰¹åˆ«æ³¨æ„ï¼š** 2024å¹´8æœˆèµ·ï¼ŒåŒ—å‘èµ„é‡‘ä¸ªè‚¡æŠ«éœ²è§„åˆ™æœ‰å˜ï¼Œæ•°æ®å¯èƒ½ä¸å®Œæ•´ã€‚

```python
def _collect_northbound(self) -> dict | None:
    """é‡‡é›†åŒ—å‘èµ„é‡‘æŒä»“æ•°æ®ã€‚"""
    df = self.safe_call_market_cached(
        "stock_hsgt_hold_stock_em:åŒ—å‘:ä»Šæ—¥æ’è¡Œ",
        "northbound",
        ak.stock_hsgt_hold_stock_em,
        market="åŒ—å‘",
        indicator="ä»Šæ—¥æ’è¡Œ",
    )
    if df is None:
        return None

    # ä»å…¨å¸‚åœºæ•°æ®ä¸­æŸ¥æ‰¾ç›®æ ‡è‚¡ç¥¨
    row = self._safe_filter(df, "ä»£ç ", self.symbol, "northbound")
    if row.empty:
        # âœ… è¿™é‡Œè¿”å›é None æ˜¯æ­£ç¡®çš„ï¼šAPI æˆåŠŸã€æ•°æ®å®Œæ•´ï¼Œ
        #    "ä¸åœ¨æŒä»“åå•"æœ¬èº«å°±æ˜¯æœ‰ä»·å€¼çš„æŸ¥è¯¢ç»“è®ºï¼ˆâ‰  é‡‡é›†å¤±è´¥ï¼‰ã€‚
        #    ä¸ earnings_forecast çš„ "available=False" ä¸åŒï¼š
        #    åè€…æ˜¯"æ‰€æœ‰ API éƒ½æ²¡è¿”å›ç›®æ ‡æ•°æ®"ï¼Œå±äºé‡‡é›†å¤±è´¥ã€‚
        return {
            "held": False,
            "shares_held": None,
            "market_value": None,
            "change_pct": None,
            "note": "æœªåœ¨åŒ—å‘èµ„é‡‘æŒä»“åå•ä¸­æ‰¾åˆ°ï¼ˆå¯èƒ½æœªæŒæœ‰æˆ–æŠ«éœ²è§„åˆ™é™åˆ¶ï¼‰",
        }

    r = row.iloc[0]
    return {
        "held": True,
        "shares_held": self._safe_float(r.get("æŒè‚¡æ•°é‡")),
        "market_value": self._safe_float(r.get("æŒè‚¡å¸‚å€¼")),
        "change_pct": self._safe_float(r.get("æŒè‚¡æ•°é‡å˜åŒ–-å¢å‡æ¯”ä¾‹")),
        "note": "åŒ—å‘èµ„é‡‘æŠ«éœ²è§„åˆ™2024å¹´8æœˆåæœ‰å˜åŒ–ï¼Œæ•°æ®ä»…ä¾›å‚è€ƒ",
    }
```

### 6.9 ä¸»é¢˜â‘¨ è‚¡ä¸œæˆ·æ•°

**AKShare å‡½æ•°ï¼š** `ak.stock_zh_a_gdhs_detail_em(symbol)`

**å…¥å‚æ ¼å¼ï¼š** `bare`

**âš ï¸ æ’åºæ³¨æ„ï¼š** ä¸ä¾èµ– AKShare è¿”å›é¡ºåºã€‚éœ€å…ˆæŒ‰ç»Ÿè®¡æˆªæ­¢æ—¥æ˜¾å¼é™åºï¼Œå†å–æœ€è¿‘ N æœŸã€‚

```python
def _collect_shareholder_count(self) -> list[dict] | None:
    """é‡‡é›†è‚¡ä¸œæˆ·æ•°å˜åŒ–æ•°æ®ã€‚"""
    df = self.safe_call(
        "shareholder_count",
        ak.stock_zh_a_gdhs_detail_em,
        symbol=self.symbol,
    )
    if df is None:
        return None

    # æ˜¾å¼æ’åºåå†æˆªå–ï¼Œé¿å…ä¾èµ– AKShare é»˜è®¤è¿”å›é¡ºåº
    if "è‚¡ä¸œæˆ·æ•°ç»Ÿè®¡æˆªæ­¢æ—¥" in df.columns:
        df = (
            df.assign(_stat_date=pd.to_datetime(df["è‚¡ä¸œæˆ·æ•°ç»Ÿè®¡æˆªæ­¢æ—¥"], errors="coerce"))
            .sort_values("_stat_date", ascending=False, na_position="last")
            .drop(columns=["_stat_date"])
        )
    else:
        msg = "shareholder_count: ç¼ºå°‘åˆ— 'è‚¡ä¸œæˆ·æ•°ç»Ÿè®¡æˆªæ­¢æ—¥'ï¼ŒæŒ‰åŸå§‹é¡ºåºæˆªå–æœ€è¿‘NæœŸ"
        self.errors.append(msg)
        logger.warning(msg)

    # å–æœ€è¿‘ N æœŸ
    df = df.head(AKSHARE_SHAREHOLDER_PERIODS)

    results = []
    for _, row in df.iterrows():
        results.append({
            "date": str(row.get("è‚¡ä¸œæˆ·æ•°ç»Ÿè®¡æˆªæ­¢æ—¥", "")),
            "count": self._safe_int(row.get("è‚¡ä¸œæˆ·æ•°-æœ¬æ¬¡")),
            "change_pct": self._safe_float(row.get("è‚¡ä¸œæˆ·æ•°-å¢å‡æ¯”ä¾‹")),
        })

    return results
```

### 6.10 ä¸»é¢˜â‘© åˆ†çº¢å†å²

**AKShare å‡½æ•°ï¼š** `ak.stock_history_dividend(symbol, indicator="åˆ†çº¢")`

**å…¥å‚æ ¼å¼ï¼š** `lower`ï¼ˆå°å†™å‰ç¼€ï¼Œå¦‚ `"sz000001"`ï¼‰

**âš ï¸ æ’åºæ³¨æ„ï¼š** ä¸ä¾èµ– AKShare è¿”å›é¡ºåºã€‚éœ€å…ˆæŒ‰æ—¶é—´æ˜¾å¼é™åºï¼Œå†å–æœ€è¿‘ N å¹´ã€‚

```python
def _collect_dividend_history(self) -> list[dict] | None:
    """é‡‡é›†åˆ†çº¢å†å²æ•°æ®ã€‚"""
    lower_symbol = format_symbol(self.symbol, "lower")
    df = self.safe_call(
        "dividend_history",
        ak.stock_history_dividend,
        symbol=lower_symbol,
        indicator="åˆ†çº¢",
    )
    if df is None:
        return None

    # æ˜¾å¼æ’åºåå†æˆªå–ï¼Œé¿å…ä¾èµ– AKShare é»˜è®¤è¿”å›é¡ºåº
    if "å¹´åº¦" in df.columns:
        # å…¼å®¹ "2023" / "2023-12-31" ç­‰æ ¼å¼ï¼Œæå– 4 ä½å¹´ä»½åé™åº
        df = (
            df.assign(
                _year_num=pd.to_numeric(
                    df["å¹´åº¦"].astype(str).str.extract(r"(\d{4})", expand=False),
                    errors="coerce",
                )
            )
            .sort_values("_year_num", ascending=False, na_position="last")
            .drop(columns=["_year_num"])
        )
    elif "é™¤æƒé™¤æ¯æ—¥" in df.columns:
        # è‹¥æ— â€œå¹´åº¦â€åˆ—ï¼Œå›é€€åˆ°é™¤æƒé™¤æ¯æ—¥æ’åº
        df = (
            df.assign(_ex_date=pd.to_datetime(df["é™¤æƒé™¤æ¯æ—¥"], errors="coerce"))
            .sort_values("_ex_date", ascending=False, na_position="last")
            .drop(columns=["_ex_date"])
        )
    else:
        msg = "dividend_history: ç¼ºå°‘æ’åºåˆ—ï¼ˆå¹´åº¦/é™¤æƒé™¤æ¯æ—¥ï¼‰ï¼ŒæŒ‰åŸå§‹é¡ºåºæˆªå–"
        self.errors.append(msg)
        logger.warning(msg)

    # å–æœ€è¿‘ N å¹´
    df = df.head(AKSHARE_DIVIDEND_YEARS)

    results = []
    for _, row in df.iterrows():
        results.append({
            "year": str(row.get("å¹´åº¦", "")),
            "dividend_per_share": self._safe_float(row.get("ç´¯è®¡è‚¡æ¯")),
            "ex_date": str(row.get("é™¤æƒé™¤æ¯æ—¥", "")),
        })

    return results
```

### 6.11 ä¸»é¢˜â‘ª ä¸šç»©é¢„å‘Š

**AKShare å‡½æ•°ï¼š** `ak.stock_yjyg_em(date)`

**å…¥å‚æ ¼å¼ï¼š** æ—¥æœŸæ ¼å¼ `YYYYMMDD`ï¼ˆå¿…é¡»æ˜¯å­£åº¦æœ«æ—¥æœŸï¼‰

**âš ï¸ æ³¨æ„ï¼š** è¿”å›å…¨å¸‚åœºæ•°æ®ï¼Œéœ€è‡ªè¡Œç­›é€‰ã€‚

```python
def _collect_earnings_forecast(self) -> dict | None:
    """é‡‡é›†ä¸šç»©é¢„å‘Šæ•°æ®ã€‚

    ç­–ç•¥ï¼šä»æœ€è¿‘çš„å­£åº¦æœ«æ—¥æœŸå¼€å§‹å€’æ¨æŸ¥æ‰¾ï¼Œç›´åˆ°æ‰¾åˆ°è¯¥è‚¡ç¥¨çš„é¢„å‘Šã€‚

    çŠ¶æ€åˆ¤å®šï¼š
    - æ‰¾åˆ°é¢„å‘Š â†’ STATUS_OK + available=True
    - è‡³å°‘æœ‰ä¸€æ¬¡ API æˆåŠŸè¿”å›ä½†æœªåŒ¹é…åˆ° â†’ STATUS_NO_DATA + available=False
    - æ‰€æœ‰ API è°ƒç”¨å‡å¤±è´¥ â†’ è¿”å› Noneï¼ˆäº¤ç»™ _safe_collect æ ‡è®° STATUS_FAILEDï¼‰
    """
    # ç”Ÿæˆæœ€è¿‘çš„å­£åº¦æœ«æ—¥æœŸåˆ—è¡¨ï¼ˆå€’åºï¼‰
    quarter_ends = self._get_recent_quarter_ends(lookback=4)
    had_any_successful_fetch = False

    for qe_date in quarter_ends:
        df = self.safe_call_market_cached(
            f"stock_yjyg_em:{qe_date}",
            "earnings_forecast",
            ak.stock_yjyg_em,
            date=qe_date,
        )
        if df is None:
            continue

        # è‡³å°‘æœ‰ä¸€æ¬¡ API æˆåŠŸæ‹¿åˆ°äº†å…¨å¸‚åœºæ•°æ®
        had_any_successful_fetch = True

        row = self._safe_filter(df, "è‚¡ç¥¨ä»£ç ", self.symbol, "earnings_forecast")
        if row.empty:
            continue

        r = row.iloc[0]
        self.topic_status["earnings_forecast"] = self.STATUS_OK
        return {
            "latest_period": qe_date,
            "forecast_type": str(r.get("ä¸šç»©å˜åŠ¨ç±»å‹", "")),
            "forecast_range": str(r.get("é¢„æµ‹å†…å®¹", "")),
            "available": True,
        }

    if had_any_successful_fetch:
        # API æˆåŠŸä½†è¯¥è‚¡ç¥¨ç¡®å®æ— ä¸šç»©é¢„å‘Š
        logger.info(
            f"earnings_forecast: æœ€è¿‘ {len(quarter_ends)} ä¸ªå­£åº¦å‡æœªæ‰¾åˆ° "
            f"{self.symbol} çš„ä¸šç»©é¢„å‘Šï¼ˆAPI æ­£å¸¸ï¼Œè¯¥è‚¡ç¥¨æ— é¢„å‘Šï¼‰"
        )
        self.topic_status["earnings_forecast"] = self.STATUS_NO_DATA
        return {
            "latest_period": None,
            "forecast_type": None,
            "forecast_range": None,
            "available": False,
        }
    else:
        # æ‰€æœ‰ API è°ƒç”¨å‡å¤±è´¥ â†’ è¿”å› Noneï¼Œ_safe_collect ä¼šæ ‡è®° STATUS_FAILED
        logger.warning(
            f"earnings_forecast: {len(quarter_ends)} æ¬¡ API è°ƒç”¨å…¨éƒ¨å¤±è´¥"
        )
        return None

@staticmethod
def _get_recent_quarter_ends(
    lookback: int = 4,
    today: date | None = None,
) -> list[str]:
    """è·å–æœ€è¿‘ N ä¸ªå·²è¿‡å»çš„å­£åº¦æœ«æ—¥æœŸï¼ˆYYYYMMDD æ ¼å¼ï¼Œå€’åºï¼‰ã€‚

    ç®—æ³•ï¼šä»å½“å‰å¹´ä»½å¼€å§‹ï¼Œæšä¸¾æ‰€æœ‰å­£åº¦æœ«æ—¥æœŸï¼ˆ12/31, 09/30, 06/30, 03/31ï¼‰ï¼Œ
    ä»…ä¿ç•™ <= today çš„æ—¥æœŸï¼Œå–æœ€è¿‘ lookback ä¸ªã€‚

    Args:
        lookback: è¿”å›çš„å­£åº¦æœ«æ—¥æœŸä¸ªæ•°
        today: åŸºå‡†æ—¥æœŸï¼ˆé»˜è®¤ None è¡¨ç¤ºä½¿ç”¨ date.today()ï¼Œ
               æµ‹è¯•æ—¶å¯ç›´æ¥æ³¨å…¥ä»¥é¿å… mockï¼‰

    ç¤ºä¾‹ï¼ˆtoday = 2026-02-07, lookback = 4ï¼‰ï¼š
        â†’ ["20251231", "20250930", "20250630", "20250331"]
    """
    if today is None:
        today = date.today()

    # å­£åº¦æœ«æ—¥æœŸæ¨¡æ¿ï¼ˆæœˆ, æ—¥ï¼‰ï¼Œå€’åºæ’åˆ—
    _QUARTER_ENDS = [(12, 31), (9, 30), (6, 30), (3, 31)]

    results: list[str] = []
    year = today.year

    while len(results) < lookback:
        for q_month, q_day in _QUARTER_ENDS:
            qe_date = date(year, q_month, q_day)
            if qe_date <= today:
                results.append(f"{year}{q_month:02d}{q_day:02d}")
                if len(results) >= lookback:
                    break
        year -= 1

    return results
```

### 6.12 ä¸»é¢˜â‘« è‚¡æƒè´¨æŠ¼

**AKShare å‡½æ•°ï¼š** `ak.stock_gpzy_pledge_ratio_em()`

**âš ï¸ æ³¨æ„ï¼š** è¿”å›å…¨å¸‚åœºæ•°æ®ï¼Œéœ€è‡ªè¡Œç­›é€‰ã€‚

```python
def _collect_pledge_ratio(self) -> dict | None:
    """é‡‡é›†è‚¡æƒè´¨æŠ¼æ•°æ®ã€‚"""
    df = self.safe_call_market_cached(
        "stock_gpzy_pledge_ratio_em",
        "pledge_ratio",
        ak.stock_gpzy_pledge_ratio_em,
    )
    if df is None:
        return None

    row = self._safe_filter(df, "è‚¡ç¥¨ä»£ç ", self.symbol, "pledge_ratio")
    if row.empty:
        # âœ… API æˆåŠŸï¼Œä¸åœ¨åˆ—è¡¨ = æ— è´¨æŠ¼ï¼Œæ˜¯æœ‰æ•ˆæŸ¥è¯¢ç»“è®ºï¼Œè¿”å›é None
        return {"ratio_pct": 0.0, "pledged_shares": None, "risk_level": "ä½"}

    r = row.iloc[0]
    ratio = self._safe_float(r.get("è´¨æŠ¼æ¯”ä¾‹"))
    risk = self._judge_pledge_risk(ratio)

    return {
        "ratio_pct": ratio,
        "pledged_shares": self._safe_float(r.get("è´¨æŠ¼è‚¡æ•°")),
        "risk_level": risk,
    }

@staticmethod
def _judge_pledge_risk(ratio: float | None) -> str:
    """æ ¹æ®è´¨æŠ¼æ¯”ä¾‹åˆ¤æ–­é£é™©ç­‰çº§ã€‚"""
    if ratio is None or ratio < 10:
        return "ä½"
    elif ratio < 30:
        return "ä¸­"
    elif ratio < 50:
        return "é«˜"
    else:
        return "æé«˜"
```

---

## ä¸ƒã€Pydantic æ•°æ®æ¨¡å‹

### 7.1 æ¨¡å‹å®šä¹‰æ–‡ä»¶

åœ¨ `stock_analyzer/module_a_models.py` ä¸­å®šä¹‰ï¼š

```python
"""Pydantic models for module A (AKShare data collection)."""

from typing import Literal

from pydantic import BaseModel, Field


# ============================================================
# å…ƒæ•°æ®
# ============================================================

class AKShareMeta(BaseModel):
    """é‡‡é›†å…ƒæ•°æ®ã€‚"""
    symbol: str = Field(description="è‚¡ç¥¨ä»£ç ï¼ˆçº¯6ä½æ•°å­—ï¼‰")
    name: str = Field(description="è‚¡ç¥¨åç§°")
    query_time: str = Field(description="é‡‡é›†æ—¶é—´ ISO æ ¼å¼")
    data_errors: list[str] = Field(
        default_factory=list,
        description="é‡‡é›†è¿‡ç¨‹ä¸­é‡åˆ°çš„é”™è¯¯åˆ—è¡¨",
    )
    successful_topics: int = Field(
        default=0,
        description="æˆåŠŸé‡‡é›†çš„ä¸»é¢˜æ•°ï¼ˆok + no_dataï¼Œæ€»å…±12ä¸ªï¼‰",
    )
    topic_status: dict[str, str] = Field(
        default_factory=dict,
        description=(
            "æ¯ä¸ªä¸»é¢˜çš„é‡‡é›†çŠ¶æ€ã€‚"
            "ok=æœ‰æ•°æ®, no_data=æˆåŠŸä½†æ— ä¸šåŠ¡æ•°æ®, failed=å¤±è´¥"
        ),
    )


# ============================================================
# å„ä¸»é¢˜æ•°æ®æ¨¡å‹
# ============================================================

class CompanyInfo(BaseModel):
    """ä¸»é¢˜â‘ ï¼šå…¬å¸åŸºæœ¬ä¿¡æ¯ã€‚"""
    industry: str = Field(default="", description="æ‰€å±è¡Œä¸š")
    listing_date: str = Field(default="", description="ä¸Šå¸‚æ—¥æœŸ")
    total_market_cap: float | None = Field(
        default=None, description="æ€»å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰"
    )
    circulating_market_cap: float | None = Field(
        default=None, description="æµé€šå¸‚å€¼ï¼ˆäº¿å…ƒï¼‰"
    )
    total_shares: float | None = Field(
        default=None, description="æ€»è‚¡æœ¬ï¼ˆäº¿è‚¡ï¼‰"
    )
    circulating_shares: float | None = Field(
        default=None, description="æµé€šè‚¡ï¼ˆäº¿è‚¡ï¼‰"
    )


class RealtimeQuote(BaseModel):
    """ä¸»é¢˜â‘¡ï¼šå®æ—¶è¡Œæƒ…å¿«ç…§ã€‚"""
    price: float | None = Field(default=None, description="æœ€æ–°ä»·")
    change_pct: float | None = Field(default=None, description="æ¶¨è·Œå¹…(%)")
    volume: float | None = Field(default=None, description="æˆäº¤é‡")
    turnover: float | None = Field(default=None, description="æˆäº¤é¢")
    pe_ttm: float | None = Field(default=None, description="åŠ¨æ€å¸‚ç›ˆç‡")
    pb: float | None = Field(default=None, description="å¸‚å‡€ç‡")
    turnover_rate: float | None = Field(default=None, description="æ¢æ‰‹ç‡(%)")
    volume_ratio: float | None = Field(default=None, description="é‡æ¯”")
    change_60d_pct: float | None = Field(
        default=None, description="60æ—¥æ¶¨è·Œå¹…(%)"
    )
    change_ytd_pct: float | None = Field(
        default=None, description="å¹´åˆè‡³ä»Šæ¶¨è·Œå¹…(%)"
    )


class FinancialIndicator(BaseModel):
    """ä¸»é¢˜â‘¢ï¼šå•æœŸè´¢åŠ¡åˆ†ææŒ‡æ ‡ã€‚"""
    report_date: str = Field(description="æŠ¥å‘ŠæœŸ")
    eps: float | None = Field(default=None, description="æ¯è‚¡æ”¶ç›Š(å…ƒ)")
    net_asset_per_share: float | None = Field(
        default=None, description="æ¯è‚¡å‡€èµ„äº§(å…ƒ)"
    )
    roe: float | None = Field(default=None, description="ROE(%)")
    gross_margin: float | None = Field(
        default=None, description="æ¯›åˆ©ç‡(%)"
    )
    net_margin: float | None = Field(
        default=None, description="å‡€åˆ©ç‡(%)"
    )
    revenue_growth: float | None = Field(
        default=None, description="è¥æ”¶åŒæ¯”å¢é•¿ç‡(%)"
    )
    profit_growth: float | None = Field(
        default=None, description="å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡(%)"
    )
    debt_ratio: float | None = Field(
        default=None, description="èµ„äº§è´Ÿå€ºç‡(%)"
    )
    current_ratio: float | None = Field(
        default=None, description="æµåŠ¨æ¯”ç‡"
    )


class ValuationHistory(BaseModel):
    """ä¸»é¢˜â‘£ï¼šä¼°å€¼å†å²æ•°æ®ä¸åˆ†ä½æ•°ã€‚"""
    current_pe_ttm: float | None = Field(default=None, description="å½“å‰PE(TTM)")
    current_pb: float | None = Field(default=None, description="å½“å‰PB")
    pe_percentile: float | None = Field(
        default=None, description="PEå†å²åˆ†ä½æ•°(0-100)"
    )
    pb_percentile: float | None = Field(
        default=None, description="PBå†å²åˆ†ä½æ•°(0-100)"
    )
    current_ps_ttm: float | None = Field(default=None, description="å½“å‰PS(TTM)")
    current_dv_ttm: float | None = Field(
        default=None, description="å½“å‰è‚¡æ¯ç‡(TTM,%)"
    )
    history_summary: str = Field(
        default="", description="ä¼°å€¼åˆ†ä½æè¿°"
    )


class ValuationVsIndustry(BaseModel):
    """ä¸»é¢˜â‘¤ï¼šè¡Œä¸šä¼°å€¼å¯¹æ¯”ã€‚"""
    stock_pe: float | None = Field(default=None, description="ä¸ªè‚¡PE")
    industry_avg_pe: float | None = Field(
        default=None, description="è¡Œä¸šå¹³å‡PE"
    )
    industry_median_pe: float | None = Field(
        default=None, description="è¡Œä¸šä¸­ä½æ•°PE"
    )
    stock_pb: float | None = Field(default=None, description="ä¸ªè‚¡PB")
    industry_avg_pb: float | None = Field(
        default=None, description="è¡Œä¸šå¹³å‡PB"
    )
    relative_valuation: str = Field(
        default="", description="ç›¸å¯¹ä¼°å€¼åˆ¤æ–­"
    )


class FundFlowDay(BaseModel):
    """å•æ—¥èµ„é‡‘æµå‘ã€‚"""
    date: str = Field(description="æ—¥æœŸ")
    main_net_inflow: float | None = Field(
        default=None, description="ä¸»åŠ›å‡€æµå…¥(ä¸‡å…ƒ)"
    )
    main_net_inflow_pct: float | None = Field(
        default=None, description="ä¸»åŠ›å‡€æµå…¥å æ¯”(%)"
    )


class FundFlowSummary(BaseModel):
    """èµ„é‡‘æµå‘æ±‡æ€»ã€‚"""
    main_net_inflow_5d_total: float | None = Field(
        default=None, description="è¿‘5æ—¥ä¸»åŠ›å‡€æµå…¥åˆè®¡(ä¸‡å…ƒï¼Œä¸è¶³5æ—¥åˆ™ä¸ºNone)"
    )
    main_net_inflow_10d_total: float | None = Field(
        default=None, description="è¿‘10æ—¥ä¸»åŠ›å‡€æµå…¥åˆè®¡(ä¸‡å…ƒï¼Œä¸è¶³10æ—¥åˆ™ä¸ºNone)"
    )
    trend: str = Field(default="", description="èµ„é‡‘æµå‘è¶‹åŠ¿æè¿°")


class FundFlow(BaseModel):
    """ä¸»é¢˜â‘¥ï¼šä¸ªè‚¡èµ„é‡‘æµå‘ã€‚"""
    recent_days: list[FundFlowDay] = Field(default_factory=list)
    summary: FundFlowSummary = Field(default_factory=FundFlowSummary)


class HotConcept(BaseModel):
    """çƒ­é—¨æ¦‚å¿µæ¿å—ã€‚"""
    name: str
    net_inflow: float | None = None


class SectorFlow(BaseModel):
    """ä¸»é¢˜â‘¦ï¼šæ¿å—èµ„é‡‘æµå‘ã€‚"""
    industry_name: str = Field(default="", description="æ‰€å±è¡Œä¸šåç§°")
    industry_rank: int | None = Field(
        default=None, description="è¡Œä¸šæ¿å—èµ„é‡‘æµå‘æ’å"
    )
    industry_net_inflow_today: float | None = Field(
        default=None, description="è¡Œä¸šæ¿å—ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥"
    )
    hot_concepts_top5: list[HotConcept] = Field(default_factory=list)


class Northbound(BaseModel):
    """ä¸»é¢˜â‘§ï¼šåŒ—å‘èµ„é‡‘æŒä»“ã€‚"""
    held: bool = Field(default=False, description="æ˜¯å¦åœ¨åŒ—å‘æŒä»“åå•ä¸­")
    shares_held: float | None = Field(
        default=None, description="æŒè‚¡æ•°é‡"
    )
    market_value: float | None = Field(
        default=None, description="æŒè‚¡å¸‚å€¼"
    )
    change_pct: float | None = Field(
        default=None, description="æŒè‚¡æ•°é‡å¢å‡æ¯”ä¾‹(%)"
    )
    note: str = Field(
        default="", description="å¤‡æ³¨ï¼ˆå¦‚æŠ«éœ²è§„åˆ™å˜åŒ–æé†’ï¼‰"
    )


class ShareholderCount(BaseModel):
    """å•æœŸè‚¡ä¸œæˆ·æ•°ã€‚"""
    date: str = Field(description="ç»Ÿè®¡æˆªæ­¢æ—¥")
    count: int | None = Field(default=None, description="è‚¡ä¸œæˆ·æ•°ï¼ˆæ•´æ•°ï¼‰")
    change_pct: float | None = Field(
        default=None, description="å¢å‡æ¯”ä¾‹(%)"
    )


class DividendRecord(BaseModel):
    """å•å¹´åˆ†çº¢è®°å½•ã€‚"""
    year: str = Field(description="å¹´åº¦")
    dividend_per_share: float | None = Field(
        default=None, description="ç´¯è®¡è‚¡æ¯(å…ƒ/è‚¡)"
    )
    ex_date: str = Field(default="", description="é™¤æƒé™¤æ¯æ—¥")


class EarningsForecast(BaseModel):
    """ä¸»é¢˜â‘ªï¼šä¸šç»©é¢„å‘Šã€‚"""
    latest_period: str | None = Field(
        default=None, description="æœ€æ–°é¢„å‘ŠæŠ¥å‘ŠæœŸ"
    )
    forecast_type: str | None = Field(
        default=None, description="ä¸šç»©å˜åŠ¨ç±»å‹"
    )
    forecast_range: str | None = Field(
        default=None, description="é¢„æµ‹å†…å®¹"
    )
    available: bool = Field(default=False, description="æ˜¯å¦æœ‰ä¸šç»©é¢„å‘Š")


class PledgeRatio(BaseModel):
    """ä¸»é¢˜â‘«ï¼šè‚¡æƒè´¨æŠ¼ã€‚"""
    ratio_pct: float | None = Field(
        default=None, description="è´¨æŠ¼æ¯”ä¾‹(%)"
    )
    pledged_shares: float | None = Field(
        default=None, description="è´¨æŠ¼è‚¡æ•°"
    )
    risk_level: Literal["ä½", "ä¸­", "é«˜", "æé«˜"] = Field(
        default="ä½", description="è´¨æŠ¼é£é™©ç­‰çº§"
    )


# ============================================================
# é¡¶å±‚è¾“å‡ºæ¨¡å‹
# ============================================================

class AKShareData(BaseModel):
    """æ¨¡å—A æœ€ç»ˆè¾“å‡ºã€‚

    å¯¹åº”æ¦‚è¦è®¾è®¡ä¸­ akshare_data.json çš„ç»“æ„ã€‚
    æ‰€æœ‰å­—æ®µå‡ä¸ºå¯é€‰ï¼ˆNone è¡¨ç¤ºé‡‡é›†å¤±è´¥æˆ–æ•°æ®ä¸å¯ç”¨ï¼‰ã€‚
    """
    meta: AKShareMeta
    company_info: CompanyInfo | None = None
    realtime_quote: RealtimeQuote | None = None
    financial_indicators: list[FinancialIndicator] | None = None
    valuation_history: ValuationHistory | None = None
    valuation_vs_industry: ValuationVsIndustry | None = None
    fund_flow: FundFlow | None = None
    sector_flow: SectorFlow | None = None
    northbound: Northbound | None = None
    shareholder_count: list[ShareholderCount] | None = None
    dividend_history: list[DividendRecord] | None = None
    earnings_forecast: EarningsForecast | None = None
    pledge_ratio: PledgeRatio | None = None
```

---

## å…«ã€ä¸»æµç¨‹ç¼–æ’

### 8.1 `AKShareCollector.collect()` æ–¹æ³•

```python
def collect(self) -> AKShareData:
    """
    æ‰§è¡Œå…¨éƒ¨12ä¸ªä¸»é¢˜çš„æ•°æ®é‡‡é›†ï¼Œä¸²è¡Œè°ƒç”¨ï¼Œå¸¦é—´éš”æ§åˆ¶ã€‚

    Returns:
        AKShareData Pydantic å¯¹è±¡

    Raises:
        AKShareCollectionError: æ•´ä½“é‡‡é›†ç»ˆæ­¢ï¼ˆæ‰€æœ‰ä¸»é¢˜å¤±è´¥æˆ–è¿ç»­è¶…æ—¶ç†”æ–­ï¼‰
    """
    # æ³¨ï¼šdatetime å·²åœ¨æ¨¡å—é¡¶å±‚ç»Ÿä¸€å¯¼å…¥ï¼ˆè§ 5.3 èŠ‚ import åŒºå—ï¼‰ï¼Œ
    #     æ­¤å¤„æ— éœ€é‡å¤ importã€‚

    results: dict = {}
    industry: str = ""

    # â”€â”€ ä¸»é¢˜â‘ ï¼šå…¬å¸åŸºæœ¬ä¿¡æ¯ï¼ˆæœ€å…ˆæ‰§è¡Œï¼Œå› ä¸ºåç»­ä¸»é¢˜éœ€è¦è¡Œä¸šä¿¡æ¯ï¼‰â”€â”€
    # æ³¨ï¼šæ‰€æœ‰ _collect_*() å‡é€šè¿‡ _safe_collect() åŒ…è£…ï¼Œ
    #     ç¡®ä¿è§£æé˜¶æ®µçš„å¼‚å¸¸ï¼ˆå¦‚ KeyErrorã€TypeErrorï¼‰ä¸ä¼šä¸­æ–­ä¸»æµç¨‹ã€‚
    info = self._safe_collect("company_info", self._collect_company_info)
    if info is not None:
        results["company_info"] = info
        industry = info.get("industry", "")

    # â”€â”€ ä¸»é¢˜â‘¡ï¼šå®æ—¶è¡Œæƒ…å¿«ç…§ â”€â”€
    quote = self._safe_collect("realtime_quote", self._collect_realtime_quote)
    if quote is not None:
        results["realtime_quote"] = quote

    # â”€â”€ ä¸»é¢˜â‘¢ï¼šè´¢åŠ¡åˆ†ææŒ‡æ ‡ â”€â”€
    financial = self._safe_collect(
        "financial_indicators", self._collect_financial_indicators
    )
    if financial is not None:
        results["financial_indicators"] = financial

    # â”€â”€ ä¸»é¢˜â‘£ï¼šä¼°å€¼å†å²æ•°æ® â”€â”€
    valuation = self._safe_collect(
        "valuation_history", self._collect_valuation_history
    )
    if valuation is not None:
        results["valuation_history"] = valuation

    # â”€â”€ ä¸»é¢˜â‘¤ï¼šè¡Œä¸šä¼°å€¼å¯¹æ¯” â”€â”€
    vs_industry = self._safe_collect(
        "valuation_vs_industry", self._collect_valuation_vs_industry
    )
    if vs_industry is not None:
        results["valuation_vs_industry"] = vs_industry

    # â”€â”€ ä¸»é¢˜â‘¥ï¼šä¸ªè‚¡èµ„é‡‘æµå‘ â”€â”€
    fund = self._safe_collect("fund_flow", self._collect_fund_flow)
    if fund is not None:
        results["fund_flow"] = fund

    # â”€â”€ ä¸»é¢˜â‘¦ï¼šæ¿å—èµ„é‡‘æµå‘ â”€â”€
    sector = self._safe_collect(
        "sector_flow", self._collect_sector_flow, industry
    )
    if sector is not None:
        results["sector_flow"] = sector

    # â”€â”€ ä¸»é¢˜â‘§ï¼šåŒ—å‘èµ„é‡‘æŒä»“ â”€â”€
    northbound = self._safe_collect("northbound", self._collect_northbound)
    if northbound is not None:
        results["northbound"] = northbound

    # â”€â”€ ä¸»é¢˜â‘¨ï¼šè‚¡ä¸œæˆ·æ•° â”€â”€
    shareholders = self._safe_collect(
        "shareholder_count", self._collect_shareholder_count
    )
    if shareholders is not None:
        results["shareholder_count"] = shareholders

    # â”€â”€ ä¸»é¢˜â‘©ï¼šåˆ†çº¢å†å² â”€â”€
    dividends = self._safe_collect(
        "dividend_history", self._collect_dividend_history
    )
    if dividends is not None:
        results["dividend_history"] = dividends

    # â”€â”€ ä¸»é¢˜â‘ªï¼šä¸šç»©é¢„å‘Š â”€â”€
    forecast = self._safe_collect(
        "earnings_forecast", self._collect_earnings_forecast
    )
    if forecast is not None:
        results["earnings_forecast"] = forecast

    # â”€â”€ ä¸»é¢˜â‘«ï¼šè‚¡æƒè´¨æŠ¼ â”€â”€
    pledge = self._safe_collect("pledge_ratio", self._collect_pledge_ratio)
    if pledge is not None:
        results["pledge_ratio"] = pledge

    # â”€â”€ ç»Ÿè®¡æˆåŠŸæ•° â”€â”€
    # åŸºäº topic_status åˆ¤å®šï¼Œä¸å†ä¾èµ– "v is not None"ã€‚
    # ä¸‰ç§çŠ¶æ€ï¼š
    #   STATUS_OK      â†’ é‡‡é›†æˆåŠŸï¼Œæœ‰ä¸šåŠ¡æ•°æ®ï¼ˆè®¡å…¥æˆåŠŸï¼‰
    #   STATUS_NO_DATA â†’ é‡‡é›†æˆåŠŸï¼Œä½†æ— ä¸šåŠ¡æ•°æ®ï¼ˆè®¡å…¥æˆåŠŸï¼‰
    #   STATUS_FAILED  â†’ é‡‡é›†å¤±è´¥ï¼ˆä¸è®¡å…¥æˆåŠŸï¼‰
    successful = sum(
        1 for s in self.topic_status.values()
        if s in (self.STATUS_OK, self.STATUS_NO_DATA)
    )
    failed = sum(
        1 for s in self.topic_status.values()
        if s == self.STATUS_FAILED
    )

    if successful == 0:
        raise AKShareCollectionError(self.symbol, self.errors)

    logger.info(
        f"AKShare collection completed for {self.symbol}: "
        f"{successful}/12 topics succeeded "
        f"({failed} failed, {len(self.errors)} errors)"
    )

    # â”€â”€ ç»„è£…æœ€ç»ˆè¾“å‡º â”€â”€
    return AKShareData(
        meta=AKShareMeta(
            symbol=self.symbol,
            name=self.name,
            query_time=datetime.now().isoformat(),
            data_errors=self.errors,
            successful_topics=successful,
            topic_status=dict(self.topic_status),
        ),
        **results,
    )
```

### 8.2 æ¨¡å—å…¥å£å‡½æ•°

åŒå± `module_a_akshare.py`ï¼Œå…±äº« 5.3 èŠ‚çš„ import åŒºå—ã€‚

```python
def collect_akshare_data(
    symbol: str,
    name: str,
    market_cache: AKShareMarketCache | None = None,
) -> AKShareData:
    """
    æ¨¡å—A å¯¹å¤–å…¥å£å‡½æ•°ã€‚

    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆçº¯6ä½æ•°å­—ï¼Œå¦‚ "000001"ï¼‰
        name: è‚¡ç¥¨åç§°ï¼ˆå¦‚ "å¹³å®‰é“¶è¡Œ"ï¼‰
        market_cache: å¯é€‰çš„å…¨å¸‚åœºç¼“å­˜å¯¹è±¡ï¼›æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨æ—¶å¯å¤ç”¨

    Returns:
        AKShareData Pydantic å¯¹è±¡

    Raises:
        ValueError: symbol æ ¼å¼ä¸åˆæ³•
        AKShareCollectionError: æ•´ä½“é‡‡é›†ç»ˆæ­¢ï¼ˆæ‰€æœ‰ä¸»é¢˜å¤±è´¥æˆ–è¿ç»­è¶…æ—¶ç†”æ–­ï¼‰
    """
    # æ ¡éªŒå…¥å‚
    if not symbol.isdigit() or len(symbol) != 6:
        raise ValueError(
            f"Invalid symbol: '{symbol}', expected 6-digit string"
        )

    logger.info(f"Starting AKShare data collection for {symbol} ({name})")
    collector = AKShareCollector(symbol, name, market_cache=market_cache)
    result = collector.collect()
    logger.info(
        f"AKShare data collection finished for {symbol}: "
        f"{result.meta.successful_topics}/12 topics, "
        f"{len(result.meta.data_errors)} errors"
    )
    return result
```

### 8.3 å‘½ä»¤è¡Œè¿è¡Œè„šæœ¬ `run_module_a.py`

ä¸ `run_module_b.py` ä¿æŒä¸€è‡´çš„é£æ ¼ï¼Œæä¾›ç‹¬ç«‹è¿è¡Œå…¥å£ï¼š

```python
"""Quick runner for module A AKShare data collection â€” run directly to test.

Usage (from project root):
    python stock_analyzer/run_module_a.py
    python stock_analyzer/run_module_a.py 600519 è´µå·èŒ…å°
    python stock_analyzer/run_module_a.py 600519.SH è´µå·èŒ…å°
"""

import json
import sys
from pathlib import Path

# Allow running from any working directory
sys.path.insert(0, str(Path(__file__).parent.parent))

from stock_analyzer.utils import normalize_symbol                # noqa: E402
from stock_analyzer.module_a_akshare import collect_akshare_data  # noqa: E402


def main() -> None:
    raw_symbol = sys.argv[1] if len(sys.argv) > 1 else "000001"
    name = sys.argv[2] if len(sys.argv) > 2 else "å¹³å®‰é“¶è¡Œ"

    # è‡ªåŠ¨æ¸…æ´—ä»£ç æ ¼å¼ï¼š600519.SH â†’ 600519
    symbol = normalize_symbol(raw_symbol)

    print(f"[module A] å¼€å§‹é‡‡é›†: {symbol} {name}\n")

    result = collect_akshare_data(symbol=symbol, name=name)

    # è¾“å‡ºåˆ°æ§åˆ¶å°
    print(json.dumps(result.model_dump(), ensure_ascii=False, indent=2))

    # åŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    output_path = output_dir / f"{symbol}_akshare_data.json"
    output_path.write_text(
        json.dumps(result.model_dump(), ensure_ascii=False, indent=2),
        encoding="utf-8",
    )
    print(f"\n[module A] ç»“æœå·²ä¿å­˜åˆ° {output_path}")


if __name__ == "__main__":
    main()
```

**ä¸ `run_module_b.py` çš„å·®å¼‚ï¼š**

| å¯¹æ¯”é¡¹ | `run_module_a.py` | `run_module_b.py` |
|--------|-------------------|-------------------|
| å‘½ä»¤è¡Œå‚æ•° | `symbol name`ï¼ˆ2ä¸ªï¼‰ | `symbol name industry`ï¼ˆ3ä¸ªï¼‰ |
| ä»£ç æ¸…æ´— | âœ… `normalize_symbol()` è‡ªåŠ¨æ¸…æ´— | âŒ ç›´æ¥é€ä¼  |
| æ‰§è¡Œæ–¹å¼ | åŒæ­¥ï¼ˆ`def main()`ï¼‰ | å¼‚æ­¥ï¼ˆ`async def main()` + `asyncio.run()`ï¼‰ |
| è¾“å‡ºæ–‡ä»¶ | âœ… è‡ªåŠ¨ä¿å­˜åˆ° `output/` | âŒ ä»…æ‰“å°åˆ°æ§åˆ¶å° |
| é»˜è®¤è‚¡ç¥¨ | `000001 å¹³å®‰é“¶è¡Œ` | `600000.SH æµ¦å‘é“¶è¡Œ` |

**ç”¨æ³•ç¤ºä¾‹ï¼š**

```bash
# é»˜è®¤ï¼ˆå¹³å®‰é“¶è¡Œï¼‰
python stock_analyzer/run_module_a.py

# æŒ‡å®šçº¯ä»£ç 
python stock_analyzer/run_module_a.py 600519 è´µå·èŒ…å°

# å¸¦äº¤æ˜“æ‰€åç¼€ï¼ˆè‡ªåŠ¨æ¸…æ´—ï¼‰
python stock_analyzer/run_module_a.py 600519.SH è´µå·èŒ…å°

# æ·±åœ³è‚¡ç¥¨
python stock_analyzer/run_module_a.py 000001.SZ å¹³å®‰é“¶è¡Œ
```

---

## ä¹ã€AKShare æ³¨æ„äº‹é¡¹

### 9.1 å·²çŸ¥é—®é¢˜ä¸åº”å¯¹ç­–ç•¥

| æ³¨æ„äº‹é¡¹ | è¯´æ˜ | åº”å¯¹ç­–ç•¥ |
|---------|------|---------|
| **é¢‘ç‡é™åˆ¶** | AKShare åº•å±‚æ˜¯çˆ¬è™«ï¼Œæ•°æ®æºç½‘ç«™ä¼šå° IP | ä¸²è¡Œè°ƒç”¨ + 3ç§’é—´éš”ï¼ˆ`AKSHARE_CALL_INTERVAL`ï¼‰ |
| **æ¥å£ä¸ç¨³å®š** | æ¥å£ç»å¸¸å› æ•°æ®æºç½‘ç«™æ”¹ç‰ˆè€Œå¤±æ•ˆ | `safe_call()` æ•è·å¼‚å¸¸ï¼Œä¸ä¸­æ–­æµç¨‹ |
| **å…¨å¸‚åœºè¿”å›** | éƒ¨åˆ†å‡½æ•°è¿”å›å…¨å¸‚åœºæ•°æ®ï¼ˆ5000+ è¡Œï¼‰ | æŒ‰ä»£ç /è¡Œä¸šè¿‡æ»¤åä½¿ç”¨ |
| **æ‰¹é‡é‡å¤æ‹‰å…¨é‡** | å¤šè‚¡ç¥¨åˆ†ææ—¶ä¼šé‡å¤è¯·æ±‚åŒä¸€ä»½å…¨å¸‚åœºæ•°æ® | ä½¿ç”¨ `AKShareMarketCache` æŒ‰ key+TTL å¤ç”¨ |
| **ä¸­æ–‡åˆ—å** | ç»å¤§å¤šæ•°å‡½æ•°è¿”å›ä¸­æ–‡åˆ—å | ç”¨ä¸­æ–‡å­—ç¬¦ä¸²ç´¢å¼•ï¼Œåˆ—åå˜åŒ–æ—¶éœ€æ›´æ–° |
| **æ—¥æœŸæ ¼å¼** | å¤§å¤šæ•° `"YYYYMMDD"`ï¼Œå°‘æ•° `"YYYY-MM-DD"` | åœ¨è§£æå±‚ç»Ÿä¸€å¤„ç† |
| **ä¸²è¡Œè°ƒç”¨** | ä¸è¦å¹¶è¡Œè°ƒç”¨å¤šä¸ª AKShare å‡½æ•° | ä½¿ç”¨åŒæ­¥ä»£ç ï¼Œä¸ç”¨ `asyncio` |
| **ä»£ç æ ¼å¼ä¸ä¸€è‡´** | ä¸åŒå‡½æ•°è¦æ±‚ä¸åŒçš„ä»£ç æ ¼å¼ | ç»Ÿä¸€ä½¿ç”¨ `format_symbol()` è½¬æ¢ |
| **å‚æ•°åä¸ä¸€è‡´** | `symbol` / `stock` / æ— å‚æ•°å‡æœ‰ | åœ¨å„é‡‡é›†æ–¹æ³•ä¸­æ˜ç¡®ä¼ å‚ |

### 9.2 åˆ—åé˜²å¾¡æ€§ç¼–ç¨‹

ç”±äº AKShare å¯èƒ½åœ¨ç‰ˆæœ¬æ›´æ–°æ—¶ä¿®æ”¹åˆ—åï¼ˆä¸­æ–‡/è‹±æ–‡éƒ½å¯èƒ½å˜åŒ–ï¼‰ï¼Œéœ€è¦åœ¨ä¸¤ä¸ªå±‚é¢åšé˜²å¾¡ï¼š

**å±‚é¢1ï¼šå•è¡Œå­—æ®µæå– â€” ä½¿ç”¨ `row.get()`**

```python
# âœ… æ¨èï¼šä½¿ç”¨ get() é˜²å¾¡åˆ—åå˜åŒ–
value = row.get("ä¸»åŠ›å‡€æµå…¥-å‡€é¢")

# âŒ ä¸æ¨èï¼šç›´æ¥ç´¢å¼•å¯èƒ½ KeyError
value = row["ä¸»åŠ›å‡€æµå…¥-å‡€é¢"]
```

**å±‚é¢2ï¼šå…¨å¸‚åœºæ•°æ®è¿‡æ»¤ â€” ä½¿ç”¨ `_safe_filter()`**

ä»å…¨å¸‚åœº DataFrame ä¸­æŒ‰åˆ—è¿‡æ»¤ç›®æ ‡è‚¡ç¥¨æ—¶ï¼Œå¿…é¡»å…ˆæ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ï¼š

```python
# âœ… æ¨èï¼šä½¿ç”¨ _safe_filter()ï¼Œåˆ—ä¸å­˜åœ¨æ—¶è¿”å›ç©º DataFrame + è®°å½•é”™è¯¯
row = self._safe_filter(df, "ä»£ç ", self.symbol, "realtime_quote")

# âŒ ä¸æ¨èï¼šåˆ—åå˜åŒ–ä¼šç›´æ¥æŠ› KeyErrorï¼Œä¸­æ–­æ•´ä¸ªé‡‡é›†æµç¨‹
row = df[df["ä»£ç "] == self.symbol]
```

**å±‚é¢3ï¼šå…œåº•ä¿æŠ¤ â€” `_safe_collect()` åŒ…è£…å™¨**

å³ä½¿ `_safe_filter()` é—æ¼äº†æŸä¸ªä½ç½®ï¼Œ`collect()` ä¸»æµç¨‹ä¸­çš„ `_safe_collect()` ä¹Ÿä¼š
æ•è·è§£æé˜¶æ®µçš„ä¸€åˆ‡éé¢„æœŸå¼‚å¸¸ï¼Œç¡®ä¿"å•ä¸»é¢˜å¤±è´¥ä¸ä¸­æ–­"çš„å®¹é”™æ‰¿è¯ºå§‹ç»ˆæˆç«‹ï¼š

```python
# collect() ä¸­çš„è°ƒç”¨æ–¹å¼
quote = self._safe_collect("realtime_quote", self._collect_realtime_quote)
#        â†‘ å³ä½¿ _collect_realtime_quote() å†…éƒ¨æŠ›å‡ºä»»ä½•å¼‚å¸¸ï¼Œ
#          ä¹Ÿä¼šè¢«æ•è·ã€è®°å½•åˆ° errorsï¼Œè¿”å› Noneï¼Œä¸å½±å“åç»­ä¸»é¢˜
```

**ğŸ”’ ç¡¬æ€§è§„åˆ™ï¼š**
- **å­—æ®µæå–**ï¼š`row` çº§è®¿é—®ä¸€å¾‹ä½¿ç”¨ `row.get("åˆ—å")` æˆ– `row.get("åˆ—å", é»˜è®¤å€¼)`ï¼›`DataFrame` çº§åˆ—è®¿é—®å‰éœ€å…ˆæ ¡éªŒåˆ—å­˜åœ¨ï¼ˆå¦‚ `item/value`ï¼‰ã€‚
- **åˆ—è¿‡æ»¤**ï¼šä¸€å¾‹ä½¿ç”¨ `self._safe_filter(df, "åˆ—å", value, topic)`
- **å…œåº•**ï¼š`collect()` ä¸­ä¸€å¾‹é€šè¿‡ `self._safe_collect(topic, collect_func)` è°ƒç”¨

### 9.3 è½¯è¶…æ—¶çš„çº¿ç¨‹å †ç§¯è¾¹ç•Œä¸é˜²æŠ¤

è½¯è¶…æ—¶æœºåˆ¶ï¼ˆ`safe_call()` ä¸­ `future.result(timeout=...)` + `shutdown(wait=False)`ï¼‰åœ¨è¶…æ—¶åä¼šç•™ä¸‹åå°çº¿ç¨‹ç»§ç»­æ‰§è¡Œ HTTP è¯·æ±‚ã€‚è¿ç»­è¶…æ—¶æ—¶è¿™äº›çº¿ç¨‹ä¼šçŸ­æ—¶å †ç§¯ã€‚

**å †ç§¯æ•°é‡ä¸Šç•Œï¼š**

| æ¡ä»¶ | å€¼ |
|------|-----|
| æ¯æ¬¡è¶…æ—¶äº§ç”Ÿé—ç•™çº¿ç¨‹ | 1 ä¸ª |
| è¿ç»­è¶…æ—¶ç†”æ–­é˜ˆå€¼ | `AKSHARE_MAX_CONSECUTIVE_TIMEOUTS`ï¼ˆé»˜è®¤ 3ï¼‰ |
| æœ€å¤§å †ç§¯çº¿ç¨‹æ•° | **3 ä¸ª**ï¼ˆè§¦å‘ç†”æ–­ååœæ­¢åˆ›å»ºæ–°çº¿ç¨‹ï¼‰ |
| é—ç•™çº¿ç¨‹å­˜æ´»æ—¶é—´ | å–å†³äºåº•å±‚ HTTP socket è¶…æ—¶ï¼ˆé€šå¸¸ < 60sï¼‰ |

**å››å±‚é˜²æŠ¤ï¼š**

1. **ä¸²è¡Œè°ƒç”¨**ï¼šå…¨æµç¨‹ä¸²è¡Œï¼ŒåŒä¸€æ—¶åˆ»åªæœ‰ 1 ä¸ª `safe_call()` åœ¨æ‰§è¡Œï¼Œä¸ä¼šå¹¶å‘åˆ›å»º executorï¼›
2. **è°ƒç”¨é—´éš”é™é€Ÿ**ï¼š`AKSHARE_CALL_INTERVAL`ï¼ˆé»˜è®¤ 3sï¼‰ä½¿å¾—è¶…æ—¶çº¿ç¨‹æœ‰æ›´å¤šæ—¶é—´è‡ªç„¶ç»“æŸï¼›
3. **è¿ç»­è¶…æ—¶ç†”æ–­**ï¼š`_consecutive_timeouts` è®¡æ•°å™¨åœ¨è¿ç»­ N æ¬¡è¶…æ—¶åæŠ›å‡º `AKShareCollectionError`ï¼Œä¸­æ­¢é‡‡é›†ã€‚ä»»ä½•ä¸€æ¬¡æˆåŠŸè°ƒç”¨éƒ½ä¼šé‡ç½®è®¡æ•°å™¨ä¸º 0ï¼›
4. **ç”Ÿäº§ç¯å¢ƒç›‘æ§**ï¼šå»ºè®®åœ¨è°ƒåº¦å±‚ï¼ˆä¸»æµç¨‹æˆ–å¤–éƒ¨ç›‘æ§ï¼‰å®šæœŸæ£€æŸ¥ `threading.active_count()`ï¼Œçº¿ç¨‹æ•°å¼‚å¸¸æ—¶å‘Šè­¦ã€‚

**ä¸ºä½•ä¸å¤ç”¨å…±äº«å•çº¿ç¨‹ executorï¼š**

- åœ¨è½¯è¶…æ—¶æ¨¡å‹ä¸‹ï¼Œè¶…æ—¶ä»»åŠ¡ä¸ä¼šè¢«å¼ºåˆ¶ç»ˆæ­¢ã€‚è‹¥å¤ç”¨å•çº¿ç¨‹ executorï¼Œå¡ä½ä»»åŠ¡ä¼šé•¿æœŸå ç”¨å”¯ä¸€ workerï¼Œåç»­ä»»åŠ¡åªèƒ½æ’é˜Ÿï¼Œå¯¼è‡´â€œä¸€ä¸ªæ…¢è¯·æ±‚æ‹–æ­»å…¨å±€â€ï¼›
- å½“å‰è®¾è®¡é€‰æ‹©â€œæ¯æ¬¡è°ƒç”¨ç‹¬ç«‹ executorâ€ï¼Œç‰ºç‰²å°‘é‡åˆ›å»º/é”€æ¯å¼€é”€ï¼Œæ¢å–è°ƒç”¨çº§éš”ç¦»ä¸æ›´å¥½çš„æ•…éšœæ¢å¤èƒ½åŠ›ï¼›
- é‰´äºæ¨¡å—Aå•è½®è°ƒç”¨è§„æ¨¡è¾ƒå°ï¼ˆçº¦ 12~15 æ¬¡ï¼‰ï¼Œè¯¥å¼€é”€åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚

**ç†”æ–­åçš„è¡Œä¸ºï¼š**

```python
# safe_call() ä¸­è§¦å‘ç†”æ–­æ—¶ï¼š
if self._consecutive_timeouts >= AKSHARE_MAX_CONSECUTIVE_TIMEOUTS:
    raise AKShareCollectionError(
        self.symbol, self.errors + [breaker_msg]
    )
    # â†‘ ç­¾åä¸ AKShareCollectionError(symbol, errors) ä¿æŒä¸€è‡´ï¼Œ
    #   breaker_msg ä½œä¸ºæœ€åä¸€æ¡é”™è¯¯è®°å½•è¿½åŠ åˆ° errors åˆ—è¡¨ä¸­ã€‚
    #   æ­¤å¼‚å¸¸ç©¿é€ _safe_collect()ï¼Œä¼ æ’­åˆ° collect() ä¸»æµç¨‹å¹¶ç»ˆæ­¢æœ¬è½®é‡‡é›†ã€‚
    #   å½“å‰å®ç°ï¼šä¸è¿”å› partial resultã€‚
    #   å¦‚éœ€ä¼˜é›…é™çº§è¿”å›éƒ¨åˆ†æ•°æ®ï¼Œéœ€æ–°å¢ partial_result è¾“å‡ºæœºåˆ¶ã€‚
```

> **è®¾è®¡å†³ç­–**ï¼šéè¶…æ—¶ç±»å¼‚å¸¸ï¼ˆå¦‚ç½‘ç»œ ConnectionErrorã€AKShare ä¸šåŠ¡å¼‚å¸¸ï¼‰**ä¸**ç´¯åŠ è¿ç»­è¶…æ—¶è®¡æ•°ï¼Œå› ä¸ºè¿™äº›é”™è¯¯é€šå¸¸æ˜¯å¶å‘çš„ï¼Œä¸ä»£è¡¨ç½‘ç»œæŒç»­ä¸å¯ç”¨ã€‚åªæœ‰è¿ç»­çš„ `FutureTimeoutError` æ‰è¡¨æ˜ç½‘ç»œå¯èƒ½æ•´ä½“é˜»å¡ï¼Œéœ€è¦ç†”æ–­ä¿æŠ¤ã€‚

### 9.4 ä¸æ¨¡å— C çš„æ•°æ®å…±äº«

æ¨¡å—Aå’Œæ¨¡å—Céƒ½ä½¿ç”¨ AKShareï¼Œä½†**ä¸å…±äº«è°ƒç”¨**ï¼š
- **æ¨¡å—A**ï¼šé‡‡é›†åŸºæœ¬é¢/èµ„é‡‘é¢æ•°æ®ï¼ˆ12ä¸ªä¸»é¢˜ï¼‰
- **æ¨¡å—C**ï¼šé‡‡é›†æœˆKçº¿æ•°æ®ï¼ˆ`ak.stock_zh_a_hist(period="monthly")`ï¼‰

ä¸¤è€…ç‹¬ç«‹è°ƒç”¨ï¼Œäº’ä¸å½±å“ã€‚åœ¨ä¸»æµç¨‹ç¼–æ’ä¸­ï¼Œæ¨¡å—A å…ˆæ‰§è¡Œå®Œæ¯•åå†æ‰§è¡Œæ¨¡å—Cï¼ˆè§æ¦‚è¦è®¾è®¡ 7.1 èŠ‚ï¼‰ï¼Œç¡®ä¿ AKShare è°ƒç”¨é—´éš”ã€‚

---

## åã€æ€§èƒ½ä¸è€—æ—¶ä¼°ç®—

### 10.1 å•æ¬¡è°ƒç”¨è€—æ—¶åŸºçº¿

| è°ƒç”¨ç±»å‹ | å¹³å‡è€—æ—¶ | è¯´æ˜ |
|---------|---------|------|
| å•è‚¡ç¥¨æŸ¥è¯¢ | 1-3 ç§’ | `stock_individual_info_em` ç­‰ |
| å…¨å¸‚åœºæŸ¥è¯¢ | 3-8 ç§’ | `stock_zh_a_spot_em` ç­‰ |
| è°ƒç”¨é—´éš” | 3 ç§’ | `AKSHARE_CALL_INTERVAL`ï¼ˆå¯é…ç½®ï¼‰ |
| è½¯è¶…æ—¶ä¸Šé™ | 30 ç§’ | `AKSHARE_CALL_TIMEOUT`ï¼ˆå¯é…ç½®ï¼‰ |

### 10.2 API è°ƒç”¨æ¬¡æ•°åˆ†æ

12 ä¸ªä¸»é¢˜ä¸­ï¼Œå›ºå®šè°ƒç”¨ä¸å¯å˜è°ƒç”¨æ‹†åˆ†å¦‚ä¸‹ï¼š

| ä¸»é¢˜ | è°ƒç”¨æ¬¡æ•° | è¯´æ˜ |
|------|---------|------|
| â‘ -â‘¥ã€â‘§-â‘©ã€â‘«ï¼ˆ10 ä¸ªä¸»é¢˜ï¼‰ | å„ 1 æ¬¡ï¼ˆå…± 10 æ¬¡ï¼‰ | å•æ¬¡è°ƒç”¨å³å¯è·å–è¯¥ä¸»é¢˜æ•°æ® |
| â‘¦ æ¿å—èµ„é‡‘æµå‘ | 2 æ¬¡ | è¡Œä¸šæ¿å— + æ¦‚å¿µæ¿å— |
| â‘ª ä¸šç»©é¢„å‘Š | 1-4 æ¬¡ | å¾ªç¯æœ€è¿‘ 4 ä¸ªå­£åº¦æœ«ï¼Œé¦–æ¬¡å‘½ä¸­å³åœ |
| å›ºå®šæ€»è®¡ï¼ˆä¸å«â‘ªé¢å¤–å°è¯•ï¼‰ | 12 æ¬¡ | 10 + 2 |

```
å®é™… API è°ƒç”¨æ¬¡æ•° = 12ï¼ˆå›ºå®šï¼‰+ earnings_forecast é¢å¤–å°è¯•æ¬¡æ•°ï¼ˆ0-3 æ¬¡ï¼‰
                  = 12 ~ 15 æ¬¡
```

### 10.3 åˆ†åœºæ™¯è€—æ—¶ä¼°ç®—

**é€šç”¨å…¬å¼ï¼š**

```
æ€»è€—æ—¶ â‰ˆ N Ã— avg_call_time + (N - 1) Ã— interval + timeout_count Ã— timeout
```

å…¶ä¸­ï¼š
- `N` = å®é™… API è°ƒç”¨æ¬¡æ•°
- `avg_call_time` = å¹³å‡å•æ¬¡è°ƒç”¨è€—æ—¶ï¼ˆ1-8 ç§’ï¼Œå–å†³äºå•è‚¡/å…¨å¸‚åœºæŸ¥è¯¢ï¼‰
- `interval` = `AKSHARE_CALL_INTERVAL`ï¼ˆé»˜è®¤ 3 ç§’ï¼‰
- `timeout_count` = è§¦å‘è½¯è¶…æ—¶çš„è°ƒç”¨æ¬¡æ•°
- `timeout` = `AKSHARE_CALL_TIMEOUT`ï¼ˆé»˜è®¤ 30 ç§’ï¼‰

**ä¸‰æ¡£ä¼°ç®—ï¼š**

| åœºæ™¯ | API æ¬¡æ•° | è¶…æ—¶æ¬¡æ•° | ä¼°ç®—è€—æ—¶ | è¯´æ˜ |
|------|---------|---------|---------|------|
| **ä¹è§‚** | 12 æ¬¡ï¼ˆä¸šç»©é¢„å‘Šä¸€æ¬¡å‘½ä¸­ï¼‰ | 0 | **~60-70 ç§’** | å…¨éƒ¨æ­£å¸¸å“åº”ï¼Œå•è‚¡æŸ¥è¯¢ ~2sï¼Œå…¨å¸‚åœº ~5s |
| **å¸¸è§„** | 14 æ¬¡ï¼ˆä¸šç»©é¢„å‘Šå°è¯• 3 ä¸ªå­£åº¦ï¼‰ | 0 | **~75-90 ç§’** | å¤šæ•°æƒ…å†µï¼Œå‰å‡ ä¸ªå­£åº¦ç©ºè¿”å› |
| **æœ€å** | 15 æ¬¡ï¼ˆä¸šç»©é¢„å‘Šéå† 4 ä¸ªå­£åº¦ï¼‰+ è¶…æ—¶ | 2 | **~130-160 ç§’** | éƒ¨åˆ†è°ƒç”¨è§¦å‘ 30s è¶…æ—¶ |
| **ç†”æ–­** | â‰¤15 æ¬¡ï¼ˆè¿ç»­ 3 æ¬¡è¶…æ—¶è§¦å‘ç†”æ–­ï¼‰ | 3 | **~90-120 ç§’** | ç†”æ–­ä¸­æ­¢åå‰©ä½™ä¸»é¢˜ä¸å†æ‰§è¡Œ |

**æ¨å¯¼ç¤ºä¾‹ï¼ˆå¸¸è§„åœºæ™¯ï¼Œ14 æ¬¡è°ƒç”¨ï¼‰ï¼š**

```
API è°ƒç”¨è€—æ—¶ï¼š5 Ã— 5sï¼ˆå…¨å¸‚åœºï¼‰+ 9 Ã— 2sï¼ˆå•è‚¡ï¼‰= 43s
è°ƒç”¨é—´éš”ç­‰å¾…ï¼š13 Ã— 3s = 39s
æ•°æ®è§£æï¼š< 1s
æ€»è®¡ â‰ˆ 43 + 39 + 1 â‰ˆ 83s
```

### 10.4 ä¼˜åŒ–ç­–ç•¥

1. **ä¸å¯å¹¶è¡Œ**ï¼šAKShare åº•å±‚çˆ¬è™«ä¸é€‚åˆå¹¶è¡Œï¼Œä¿æŒä¸²è¡Œ
2. **å¯é€‚å½“ç¼©çŸ­é—´éš”**ï¼šå¦‚æœè¿è¡Œç¯å¢ƒä¸æ˜“è¢«å° IPï¼ˆå¦‚æœåŠ¡å™¨ï¼‰ï¼Œå¯å°† `AKSHARE_CALL_INTERVAL` è°ƒè‡³ 2 ç§’
3. **ç¼“å­˜å…¨å¸‚åœºæ•°æ®**ï¼šé‡‡ç”¨ `AKShareMarketCache`ï¼ˆè§ 5.3 / 12.3ï¼‰å¯¹ `stock_zh_a_spot_em`ã€æ¿å—èµ„é‡‘æµå‘ã€åŒ—å‘ã€è´¨æŠ¼ã€ä¸šç»©é¢„å‘Šï¼ˆæŒ‰æ—¥æœŸï¼‰åšæ‰¹é‡å¤ç”¨
4. **è¶…æ—¶å€¼è°ƒä¼˜**ï¼šå¦‚æœç½‘ç»œç¨³å®šï¼Œå¯å°† `AKSHARE_CALL_TIMEOUT` ä» 30s ç¼©çŸ­åˆ° 15sï¼Œå‡å°‘æœ€åè€—æ—¶
5. **ç†”æ–­é˜ˆå€¼è°ƒä¼˜**ï¼š`AKSHARE_MAX_CONSECUTIVE_TIMEOUTS` é»˜è®¤ 3ï¼Œç½‘ç»œæä¸ç¨³å®šæ—¶å¯é€‚å½“æé«˜ï¼Œä½†éœ€æƒè¡¡çº¿ç¨‹å †ç§¯ä¸Šé™

---

## åä¸€ã€æµ‹è¯•ç­–ç•¥

### 11.1 æµ‹è¯•å±‚æ¬¡

| å±‚æ¬¡ | æµ‹è¯•å†…å®¹ | æ–‡ä»¶ |
|------|---------|------|
| **å·¥å…·å‡½æ•°** | `format_symbol()`, `get_market()` | `tests/test_utils.py` |
| **è§£æé€»è¾‘** | `_parse_company_info()`, `_safe_float()`, `_calc_percentile()` ç­‰ | `tests/test_module_a_parsers.py` |
| **API å¯ç”¨æ€§** | 12 ä¸ª AKShare API æ˜¯å¦æ­£å¸¸è¿”å› | `tests/test_akshare_api.py`ï¼ˆå·²æœ‰ï¼‰ |
| **é›†æˆæµ‹è¯•** | `collect_akshare_data()` ç«¯åˆ°ç«¯ | `tests/test_module_a_integration.py` |
| **Pydantic æ¨¡å‹** | æ¨¡å‹æ ¡éªŒåˆæ³•/éæ³•è¾“å…¥ | `tests/test_module_a_models.py` |

### 11.2 å•å…ƒæµ‹è¯•è¦ç‚¹

```python
# test_utils.py ç¤ºä¾‹

def test_format_symbol_bare():
    assert format_symbol("000001", "bare") == "000001"

def test_format_symbol_lower_sz():
    assert format_symbol("000001", "lower") == "sz000001"

def test_format_symbol_lower_sh():
    assert format_symbol("600519", "lower") == "sh600519"

def test_format_symbol_upper():
    assert format_symbol("000001", "upper") == "SZ000001"

def test_format_symbol_invalid_code():
    with pytest.raises(ValueError):
        format_symbol("12345", "bare")  # ä¸æ˜¯6ä½

def test_get_market_sh():
    assert get_market("600519") == "sh"

def test_get_market_sz():
    assert get_market("000001") == "sz"
    assert get_market("300750") == "sz"

def test_normalize_symbol_bare():
    assert normalize_symbol("600519") == "600519"

def test_normalize_symbol_with_suffix():
    assert normalize_symbol("600519.SH") == "600519"
    assert normalize_symbol("000001.SZ") == "000001"
    assert normalize_symbol("600519.sh") == "600519"

def test_normalize_symbol_with_prefix():
    assert normalize_symbol("SH600519") == "600519"
    assert normalize_symbol("sz000001") == "000001"

def test_normalize_symbol_invalid():
    with pytest.raises(ValueError):
        normalize_symbol("è´µå·èŒ…å°")
    with pytest.raises(ValueError):
        normalize_symbol("12345")
```

```python
# test_module_a_parsers.py ç¤ºä¾‹

def test_collect_company_info_returns_none_when_safe_call_none(mocker):
    collector = AKShareCollector("000001", "å¹³å®‰é“¶è¡Œ")
    mocker.patch.object(collector, "safe_call", return_value=None)
    assert collector._collect_company_info() is None

def test_collect_company_info_calls_parse_when_df_available(mocker):
    collector = AKShareCollector("000001", "å¹³å®‰é“¶è¡Œ")
    fake_df = pd.DataFrame({"item": ["è¡Œä¸š"], "value": ["é“¶è¡Œ"]})
    mocker.patch.object(collector, "safe_call", return_value=fake_df)
    parse_mock = mocker.patch.object(
        collector, "_parse_company_info", return_value={"industry": "é“¶è¡Œ"}
    )

    result = collector._collect_company_info()
    parse_mock.assert_called_once_with(fake_df)
    assert result == {"industry": "é“¶è¡Œ"}

def test_safe_float_normal():
    assert AKShareCollector._safe_float(3.14) == 3.14

def test_safe_float_none():
    assert AKShareCollector._safe_float(None) is None

def test_safe_float_nan():
    assert AKShareCollector._safe_float(float("nan")) is None

def test_safe_int_normal():
    assert AKShareCollector._safe_int("3456789") == 3456789

def test_safe_int_float_string():
    assert AKShareCollector._safe_int("3456789.0") == 3456789

def test_safe_int_none():
    assert AKShareCollector._safe_int(None) is None

def test_safe_int_nan():
    assert AKShareCollector._safe_int(float("nan")) is None

def test_parse_number_yi():
    assert AKShareCollector._parse_number("2156.80äº¿") == 2156.80

def test_parse_number_wan_to_yi():
    # "ä¸‡"æ¢ç®—åˆ°"äº¿"ï¼š19406 Ã— 0.0001 = 1.9406
    assert AKShareCollector._parse_number("19406ä¸‡") == 1.9406

def test_parse_number_no_unit():
    # æ— å•ä½å‡å®šå·²æ˜¯ç›®æ ‡å•ä½
    assert AKShareCollector._parse_number("3.5") == 3.5

def test_parse_number_target_wan():
    # target_unit="ä¸‡"ï¼šäº¿æ¢ç®—åˆ°ä¸‡
    assert AKShareCollector._parse_number("2.5äº¿", target_unit="ä¸‡") == 25000.0

def test_parse_number_dash():
    assert AKShareCollector._parse_number("-") is None

def test_calc_percentile():
    series = pd.Series(range(100))
    assert AKShareCollector._calc_percentile(series, 50) == 50.0

def test_calc_percentile_with_numeric_strings():
    # å­—ç¬¦ä¸²æ•°å€¼åº”å…ˆè¢«æ•°å€¼åŒ–ï¼Œå†å‚ä¸åˆ†ä½æ•°è®¡ç®—
    series = pd.Series([str(i) for i in range(1, 21)] + [None, "bad"])
    assert AKShareCollector._calc_percentile(series, "10") == 45.0

def test_collect_sector_flow_prefers_exact_match_over_contains(mocker):
    collector = AKShareCollector("600519", "è´µå·èŒ…å°")
    df_industry = pd.DataFrame([
        {"åç§°": "ç™½é…’â…¡", "æ’å": 1, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 999.0},
        {"åç§°": "ç™½é…’", "æ’å": 2, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 123.0},
    ])
    df_concept = pd.DataFrame([
        {"åç§°": "æ¦‚å¿µA", "æ’å": 2, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 20.0},
        {"åç§°": "æ¦‚å¿µB", "æ’å": 1, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 10.0},
    ])

    def fake_market_call(cache_key, topic, func, *args, **kwargs):
        if topic == "sector_flow_industry":
            return df_industry
        if topic == "sector_flow_concept":
            return df_concept
        return None

    mocker.patch.object(
        collector, "safe_call_market_cached", side_effect=fake_market_call
    )

    result = collector._collect_sector_flow("ç™½é…’")
    assert result["industry_name"] == "ç™½é…’"
    assert result["industry_rank"] == 2
    assert result["industry_net_inflow_today"] == 123.0

def test_collect_sector_flow_hot_concepts_top5_sorted_before_head(mocker):
    collector = AKShareCollector("600519", "è´µå·èŒ…å°")
    # è¾“å…¥é¡ºåºæ•…æ„æ‰“ä¹±ï¼ŒéªŒè¯ä¼šå…ˆæŒ‰â€œæ’åâ€æ’åºå†å– Top5
    df_concept = pd.DataFrame([
        {"åç§°": "æ¦‚å¿µ5", "æ’å": 5, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 50.0},
        {"åç§°": "æ¦‚å¿µ2", "æ’å": 2, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 20.0},
        {"åç§°": "æ¦‚å¿µ1", "æ’å": 1, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 10.0},
        {"åç§°": "æ¦‚å¿µ4", "æ’å": 4, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 40.0},
        {"åç§°": "æ¦‚å¿µ3", "æ’å": 3, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 30.0},
        {"åç§°": "æ¦‚å¿µ6", "æ’å": 6, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 60.0},
    ])

    def fake_market_call(cache_key, topic, func, *args, **kwargs):
        if topic == "sector_flow_industry":
            return None
        if topic == "sector_flow_concept":
            return df_concept
        return None

    mocker.patch.object(
        collector, "safe_call_market_cached", side_effect=fake_market_call
    )

    result = collector._collect_sector_flow("")
    top5_names = [x["name"] for x in result["hot_concepts_top5"]]
    assert top5_names == ["æ¦‚å¿µ1", "æ¦‚å¿µ2", "æ¦‚å¿µ3", "æ¦‚å¿µ4", "æ¦‚å¿µ5"]

def test_collect_sector_flow_logs_when_industry_not_matched(mocker):
    collector = AKShareCollector("600519", "è´µå·èŒ…å°")
    df_industry = pd.DataFrame([
        {"åç§°": "ç™½é…’â…¡", "æ’å": 1, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 999.0},
    ])
    df_concept = pd.DataFrame([
        {"åç§°": "æ¦‚å¿µA", "æ’å": 1, "ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢": 10.0},
    ])

    def fake_market_call(cache_key, topic, func, *args, **kwargs):
        if topic == "sector_flow_industry":
            return df_industry
        if topic == "sector_flow_concept":
            return df_concept
        return None

    mocker.patch.object(
        collector, "safe_call_market_cached", side_effect=fake_market_call
    )

    result = collector._collect_sector_flow("æœ‰è‰²é‡‘å±")
    assert result["industry_name"] == "æœ‰è‰²é‡‘å±"
    assert result["industry_rank"] is None
    assert result["industry_net_inflow_today"] is None
    assert any(
        "sector_flow_industry: è¡Œä¸š 'æœ‰è‰²é‡‘å±' åœ¨æ¿å—æ•°æ®ä¸­ç²¾ç¡®å’Œæ¨¡ç³ŠåŒ¹é…å‡æœªå‘½ä¸­" in e
        for e in collector.errors
    )

def test_collect_sector_flow_returns_none_when_both_sources_fail(mocker):
    collector = AKShareCollector("600519", "è´µå·èŒ…å°")

    mocker.patch.object(
        collector, "safe_call_market_cached", return_value=None
    )

    # è¡Œä¸šä¸æ¦‚å¿µä¸¤è·¯å…¨å¤±è´¥æ—¶åº”è¿”å› Noneï¼Œ
    # ç”± _safe_collect() ç»Ÿä¸€æ ‡è®° STATUS_FAILED
    assert collector._collect_sector_flow("ç™½é…’") is None

def test_judge_relative_valuation_negative_pe():
    # äºæŸåœºæ™¯ï¼ˆPE<=0ï¼‰åº”ç›´æ¥é™çº§ä¸ºâ€œæ— æ³•åˆ¤æ–­â€
    assert AKShareCollector._judge_relative_valuation(-10.0, 30.0) == "æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­"
    assert AKShareCollector._judge_relative_valuation(20.0, -5.0) == "æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­"

def test_judge_pledge_risk():
    assert AKShareCollector._judge_pledge_risk(5.0) == "ä½"
    assert AKShareCollector._judge_pledge_risk(25.0) == "ä¸­"
    assert AKShareCollector._judge_pledge_risk(45.0) == "é«˜"
    assert AKShareCollector._judge_pledge_risk(60.0) == "æé«˜"

def test_get_recent_quarter_ends_early_year():
    """å¹´åˆåœºæ™¯ï¼š2026-02 åº”åŒ…å« 20250930 è€Œä¸è·³åˆ° 20250630ã€‚"""
    from datetime import date
    result = AKShareCollector._get_recent_quarter_ends(
        lookback=4, today=date(2026, 2, 7)
    )
    assert result == ["20251231", "20250930", "20250630", "20250331"]

def test_get_recent_quarter_ends_mid_year():
    """å¹´ä¸­åœºæ™¯ï¼š2026-08 åº”ä» 20260630 å¼€å§‹ã€‚"""
    from datetime import date
    result = AKShareCollector._get_recent_quarter_ends(
        lookback=4, today=date(2026, 8, 15)
    )
    assert result == ["20260630", "20260331", "20251231", "20250930"]

def test_get_recent_quarter_ends_quarter_boundary():
    """æ°å¥½åœ¨å­£åº¦æœ«å½“å¤©ï¼š20260331 åº”åŒ…å«åœ¨ç»“æœä¸­ã€‚"""
    from datetime import date
    result = AKShareCollector._get_recent_quarter_ends(
        lookback=4, today=date(2026, 3, 31)
    )
    assert result == ["20260331", "20251231", "20250930", "20250630"]
```

### 11.3 é›†æˆæµ‹è¯•

```python
# test_module_a_integration.py ç¤ºä¾‹

def test_collect_akshare_data_basic():
    """åŸºæœ¬åŠŸèƒ½æµ‹è¯•ï¼šèƒ½é‡‡é›†åˆ°è‡³å°‘éƒ¨åˆ†æ•°æ®ã€‚"""
    result = collect_akshare_data("000001", "å¹³å®‰é“¶è¡Œ")

    assert result.meta.symbol == "000001"
    assert result.meta.name == "å¹³å®‰é“¶è¡Œ"
    assert result.meta.successful_topics > 0

    # è‡³å°‘å…¬å¸åŸºæœ¬ä¿¡æ¯åº”è¯¥èƒ½é‡‡åˆ°
    if result.company_info is not None:
        assert result.company_info.industry != ""

def test_collect_akshare_data_invalid_symbol():
    """æ— æ•ˆä»£ç åº”è¯¥æŠ›å‡º ValueErrorã€‚"""
    with pytest.raises(ValueError):
        collect_akshare_data("12345", "æµ‹è¯•")
```

---

## åäºŒã€ä½¿ç”¨ç¤ºä¾‹

### 12.1 åŸºæœ¬ä½¿ç”¨

```python
from stock_analyzer.module_a_akshare import collect_akshare_data

# é‡‡é›†æ•°æ®
result = collect_akshare_data("000001", "å¹³å®‰é“¶è¡Œ")

# âš ï¸ å„ä¸»é¢˜å­—æ®µå‡å¯èƒ½ä¸º Noneï¼ˆé‡‡é›†å¤±è´¥æ—¶ï¼‰ï¼Œè®¿é—®å‰å¿…é¡»åˆ¤ç©º
print(f"é‡‡é›†æˆåŠŸä¸»é¢˜æ•°ï¼š{result.meta.successful_topics}/12")
print(f"é‡‡é›†é”™è¯¯ï¼š{result.meta.data_errors}")

if result.company_info is not None:
    print(f"è¡Œä¸šï¼š{result.company_info.industry}")

if result.realtime_quote is not None:
    print(f"å½“å‰ä»·æ ¼ï¼š{result.realtime_quote.price}")

if result.valuation_history is not None:
    print(f"PEåˆ†ä½æ•°ï¼š{result.valuation_history.pe_percentile}%")
```

### 12.2 è¾“å‡ºä¸º JSON æ–‡ä»¶

```python
import json

result = collect_akshare_data("000001", "å¹³å®‰é“¶è¡Œ")

# æ–¹å¼1ï¼ˆæ¨èï¼‰ï¼šä¿ç•™ä¸­æ–‡
json_str = json.dumps(result.model_dump(), ensure_ascii=False, indent=2)

# æ–¹å¼2ï¼šä½¿ç”¨ Pydanticï¼ˆä¸­æ–‡ä¼šè½¬ä¹‰ä¸º \uXXXXï¼‰
# json_str = result.model_dump_json(indent=2)

# ä¿å­˜åˆ°æ–‡ä»¶
output_path = f"output/{result.meta.symbol}_akshare_data.json"
with open(output_path, "w", encoding="utf-8") as f:
    f.write(json_str)
```

### 12.3 ä¸ä¸»ç¼–æ’é›†æˆ

```python
# main.py ä¸­çš„ä½¿ç”¨æ–¹å¼ï¼ˆè§æ¦‚è¦è®¾è®¡ 7.1 èŠ‚ï¼‰
from stock_analyzer.module_a_akshare import collect_akshare_data

async def analyze_stock(symbol: str, name: str):
    # æ¨¡å—Aï¼šAKShare æ•°æ®é‡‡é›†ï¼ˆçº¯ä»£ç ï¼ŒåŒæ­¥æ‰§è¡Œï¼‰
    akshare_data = collect_akshare_data(symbol, name)

    # ä»æ¨¡å—Aè·å–è¡Œä¸šä¿¡æ¯ï¼Œä¾›æ¨¡å—Bä½¿ç”¨
    industry = ""
    if akshare_data.company_info:
        industry = akshare_data.company_info.industry

    # æ¨¡å—Bï¼šç½‘ç»œæœç´¢ï¼ˆéœ€è¦è¡Œä¸šä¿¡æ¯ï¼‰
    web_result = await run_web_research(symbol, name, industry)

    # æ¨¡å—Dï¼šé¦–å¸­åˆ†æå¸ˆ
    # ...ï¼ˆä¼ å…¥ akshare_data.model_dump() å³å¯ï¼‰
```

```python
# æ‰¹é‡åˆ†æåœºæ™¯ï¼šå…±äº«å…¨å¸‚åœºç¼“å­˜ï¼Œå¤ç”¨ 5000+ è¡ŒæŸ¥è¯¢ç»“æœ
from stock_analyzer.module_a_akshare import AKShareMarketCache, collect_akshare_data

def analyze_batch(stocks: list[tuple[str, str]]):
    shared_cache = AKShareMarketCache()  # TTL ç”± AKSHARE_MARKET_CACHE_TTL_SEC æ§åˆ¶
    results = []
    for symbol, name in stocks:
        data = collect_akshare_data(symbol, name, market_cache=shared_cache)
        results.append(data)
    return results
```

---

## åä¸‰ã€ä¸é¡¹ç›®å…¶ä»–æ¨¡å—çš„å…³ç³»

### 13.1 å…±äº«æ–‡ä»¶

| æ–‡ä»¶ | æ¨¡å—A ä½¿ç”¨æ–¹å¼ | æ¨¡å—B ä½¿ç”¨æ–¹å¼ |
|------|--------------|--------------|
| `config.py` | è¯»å– `AKSHARE_*` é…ç½® | è¯»å– `TAVILY_*`ã€`MODEL_*` é…ç½® |
| `logger.py` | `from stock_analyzer.logger import logger` | ç›¸åŒ |
| `exceptions.py` | å®šä¹‰ `AKShare*Error` å¼‚å¸¸ | å®šä¹‰ `Tavily*Error` ç­‰å¼‚å¸¸ |

### 13.2 æ¨¡å—A æ–°å¢æ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” |
|------|------|
| `module_a_models.py` | æ¨¡å—A çš„ Pydantic æ•°æ®æ¨¡å‹ |
| `module_a_akshare.py` | æ¨¡å—A ä¸»é€»è¾‘ï¼ˆAKShareCollector + å…¥å£å‡½æ•°ï¼‰ |
| `utils.py` | å·¥å…·å‡½æ•°ï¼ˆ`format_symbol`, `get_market`, `normalize_symbol`ï¼‰ |
| `run_module_a.py` | å‘½ä»¤è¡Œè¿è¡Œè„šæœ¬ï¼ˆç‹¬ç«‹æµ‹è¯•ç”¨ï¼‰ |

### 13.3 ä¸æ–°å¢æ–‡ä»¶çš„å†…å®¹

| å†…å®¹ | æ”¾ç½®ä½ç½® | è¯´æ˜ |
|------|---------|------|
| æ¨¡å—A é…ç½®é¡¹ | `config.py`ï¼ˆè¿½åŠ ï¼‰ | ä¸æ¨¡å—Bé…ç½®ç»Ÿä¸€ç®¡ç† |
| æ¨¡å—A å¼‚å¸¸ç±» | `exceptions.py`ï¼ˆè¿½åŠ ï¼‰ | ä¸æ¨¡å—Bå¼‚å¸¸ç»Ÿä¸€ç®¡ç† |

---

## åå››ã€å…³é”®è®¾è®¡å†³ç­–æ€»ç»“

| å†³ç­– | é€‰æ‹© | ç†ç”± |
|------|------|------|
| ç¼–ç¨‹èŒƒå¼ | çº¯åŒæ­¥ä»£ç  | AKShare åº•å±‚æ˜¯çˆ¬è™«ï¼Œä¸é€‚åˆå¼‚æ­¥å¹¶å‘ |
| è°ƒç”¨ç­–ç•¥ | ä¸²è¡Œ + é—´éš” 3ç§’ | é¿å…è§¦å‘æ•°æ®æº IP å°ç¦ |
| å¼‚å¸¸å¤„ç† | å•ä¸»é¢˜å¤±è´¥ä¸ä¸­æ–­ | å®¹é”™ä¼˜å…ˆï¼Œéƒ¨åˆ†æ•°æ®ä¹Ÿæœ‰åˆ†æä»·å€¼ |
| æ•°æ®æ¨¡å‹ | æ‰€æœ‰å­—æ®µå¯é€‰(`None`) | éƒ¨åˆ†ä¸»é¢˜å¯èƒ½é‡‡é›†å¤±è´¥ |
| ä»£ç æ ¼å¼ | ç»Ÿä¸€å·¥å…·å‡½æ•°è½¬æ¢ | AKShare ä¸åŒå‡½æ•°è¦æ±‚ä¸åŒæ ¼å¼ |
| æ•°å€¼è§£æ | `_safe_float()` é˜²å¾¡æ€§è§£æ | AKShare è¿”å›å€¼ç±»å‹ä¸å¯é  |
| åˆ—åå¼•ç”¨ | `dict.get()` é˜²å¾¡ | AKShare ä¸­æ–‡åˆ—åå¯èƒ½å˜åŒ– |
| åˆ†ä½æ•°è®¡ç®— | æœ¬æ¨¡å—å†…å®Œæˆ | çº¯æ•°å€¼è®¡ç®—ï¼Œä¸éœ€è¦ AI |
| é£é™©åˆ¤æ–­ | ç®€å•è§„åˆ™å¼•æ“ | è´¨æŠ¼æ¯”ä¾‹ã€ä¼°å€¼åˆ†ä½ç­‰æœ‰æ˜ç¡®é˜ˆå€¼ |
| ä¸æ¨¡å—Cå…³ç³» | ç‹¬ç«‹è°ƒç”¨ AKShare | å„å–æ‰€éœ€ï¼Œäº’ä¸å½±å“ |
