"""Workflow execution for Step 1 (concurrent) and Step 2 (magentic) using OpenAI compatible mode."""
from __future__ import annotations
import asyncio
import json
import logging
from typing import Any

from agent_framework import (
    ChatAgent,
    ChatMessage,
    ConcurrentBuilder,
    MagenticBuilder,
    StandardMagenticManager,
)
from agent_framework.openai import OpenAIChatClient
from openai import AsyncOpenAI
from pydantic import ValidationError

from . import config
from .agents import create_kline_agent, create_news_agent, create_sector_agent
from .merger import merge_results
from .models import HoldRecommendation, Step1Output
from .prompts import MANAGER_INSTRUCTIONS, REVIEW_AGENT_SYSTEM, SCORE_AGENT_SYSTEM
from .utils import extract_json_str

logger = logging.getLogger("analysis_llm")


async def execute_step1(stock_code: str):
    """Run Step 1 workflow and return Step1Output."""
    if not stock_code:
        raise ValueError("stock_code is required")

    api_key = config.DASHSCOPE_API_KEY
    if not api_key:
        raise EnvironmentError("ç¯å¢ƒå˜é‡ 'DASHSCOPE_API_KEY' æœªé…ç½®ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ã€‚")

    base_url = config.DASHSCOPE_BASE_URL

    # Create a shared AsyncOpenAI client with timeout configuration
    openai_client = AsyncOpenAI(
        api_key=api_key,
        base_url=base_url,
        timeout=config.API_TIMEOUT
    )

    # Initialize chat clients using MAF native OpenAIChatClient
    # This works for both text (qwen-plus) and vision (qwen-vl-max) models
    news_client = OpenAIChatClient(
        model_id=config.MODEL_NEWS_AGENT,
        async_client=openai_client
    )
    
    sector_client = OpenAIChatClient(
        model_id=config.MODEL_SECTOR_AGENT,
        async_client=openai_client
    )
    
    kline_client = OpenAIChatClient(
        model_id=config.MODEL_KLINE_AGENT,
        async_client=openai_client
    )

    # Note: Using the same client for checkers if needed, or separate instances
    checker_client_news = OpenAIChatClient(model_id=config.MODEL_CHECKER_NEWS, async_client=openai_client)
    checker_client_sector = OpenAIChatClient(model_id=config.MODEL_CHECKER_SECTOR, async_client=openai_client)
    checker_client_kline = OpenAIChatClient(model_id=config.MODEL_CHECKER_KLINE, async_client=openai_client)

    # Create agents with the new clients
    news_agent = create_news_agent(news_client, checker_client_news)
    sector_agent = create_sector_agent(sector_client, checker_client_sector)
    kline_agent = create_kline_agent(kline_client, checker_client_kline)

    workflow = (
        ConcurrentBuilder()
        .participants([news_agent, sector_agent, kline_agent])
        .build()
    )

    logger.info("Step1 workflow started for %s using OpenAI compatible mode", stock_code)
    result = await workflow.run(stock_code)
    
    messages = []
    
    # 1. ä¼˜å…ˆå°è¯•å®˜æ–¹ API get_outputs()
    if hasattr(result, "get_outputs"):
        try:
            outputs = result.get_outputs()
            logger.info("Using WorkflowRunResult.get_outputs(), count: %d", len(outputs))
            
            # æ‰å¹³åŒ–æå– ChatMessage
            for out in outputs:
                # out å¯èƒ½æ˜¯ä¸€ä¸ªåˆ—è¡¨ (èšåˆå™¨è¾“å‡º) æˆ–å•ä¸ªå¯¹è±¡
                items = out if isinstance(out, list) else [out]
                
                for item in items:
                    # å¤ç”¨å‰¥æ´‹è‘±é€»è¾‘
                    if hasattr(item, "agent_response"):
                        resp = item.agent_response
                        if hasattr(resp, "messages"):
                            messages.extend(resp.messages)
                    elif hasattr(item, "messages"):
                        messages.extend(item.messages)
                    elif hasattr(item, "role") and hasattr(item, "text"): # ChatMessage duck typing
                        messages.append(item)
                    elif isinstance(item, dict):
                        try:
                            messages.append(ChatMessage.from_dict(item))
                        except Exception: pass
                    
        except Exception as e:
            logger.warning("get_outputs() failed, falling back to event scanning: %s", e)

    # 2. å¦‚æœå®˜æ–¹ API æœªè¿”å›æœ‰æ•ˆæ¶ˆæ¯ï¼Œå›é€€åˆ°äº‹ä»¶æ‰«æ (Fallback)
    if not messages:
        logger.info("No messages from get_outputs(), scanning events...")
        # result æœ¬èº«æ˜¯å¯è¿­ä»£çš„äº‹ä»¶æµ (list[WorkflowEvent])
        for event in result:
            event_type = type(event).__name__
            if event_type == "WorkflowOutputEvent":
                logger.debug("Found WorkflowOutputEvent, processing data...")
                # èšåˆå™¨é€šå¸¸è¿”å›ä¸€ä¸ªåˆ—è¡¨
                items = event.data if isinstance(event.data, list) else [event.data]
                for item in items:
                    if hasattr(item, "agent_response"):
                        resp = item.agent_response
                        if hasattr(resp, "messages"):
                            messages.extend(resp.messages)
                    elif hasattr(item, "messages"):
                        messages.extend(item.messages)
                    elif isinstance(item, ChatMessage):
                        messages.append(item)
                    elif isinstance(item, dict):
                        try:
                            messages.append(ChatMessage.from_dict(item))
                        except Exception: pass
            
            elif event_type == "ExecutorCompletedEvent" and not messages:
                # è¿›ä¸€æ­¥å…œåº•ï¼šå¦‚æœæ²¡æœ‰ WorkflowOutputEventï¼Œä» ExecutorCompletedEvent æ
                payload = getattr(event, "output", getattr(event, "data", None))
                raw_msgs = payload if isinstance(payload, list) else [payload]
                for item in raw_msgs:
                    if hasattr(item, "agent_response"):
                        resp = item.agent_response
                        if hasattr(resp, "messages"):
                            messages.extend(resp.messages)
                    elif hasattr(item, "messages"):
                        messages.extend(item.messages)
                    elif isinstance(item, ChatMessage):
                        messages.append(item)

    # Debug: Print extracted messages
    logger.info("Extracted %d messages from workflow result", len(messages))
            
    return merge_results(messages)


class ScoringWorkflow:
    """Magentic-based scoring workflow for Step 2."""

    def __init__(
        self,
        dashscope_client: AsyncOpenAI | None = None,
        deepseek_client: AsyncOpenAI | None = None,
    ) -> None:
        logger.info("åˆå§‹åŒ– Step2 Workflow")

        if dashscope_client is None:
            if not config.DASHSCOPE_API_KEY:
                logger.error("DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
                raise EnvironmentError("DASHSCOPE_API_KEY is required for Step2")
            self._dashscope_client = AsyncOpenAI(
                api_key=config.DASHSCOPE_API_KEY,
                base_url=config.DASHSCOPE_BASE_URL,
                timeout=config.API_TIMEOUT,
            )
        else:
            self._dashscope_client = dashscope_client

        if deepseek_client is None:
            if not config.DEEPSEEK_API_KEY:
                logger.error("DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
                raise EnvironmentError("DEEPSEEK_API_KEY is required for Step2")
            self._deepseek_client = AsyncOpenAI(
                api_key=config.DEEPSEEK_API_KEY,
                base_url=config.DEEPSEEK_BASE_URL,
                timeout=config.API_TIMEOUT,
            )
        else:
            self._deepseek_client = deepseek_client

        self.manager_client = OpenAIChatClient(
            model_id=config.MODEL_MANAGER,
            async_client=self._dashscope_client,
        )
        self.score_client = OpenAIChatClient(
            model_id=config.MODEL_SCORE_AGENT,
            async_client=self._dashscope_client,
        )
        self.review_client = OpenAIChatClient(
            model_id=config.MODEL_REVIEW_AGENT,
            async_client=self._deepseek_client,
        )
        logger.debug("ReviewAgent Client åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: %s", config.MODEL_REVIEW_AGENT)
        logger.info("Step2 Workflow åˆå§‹åŒ–å®Œæˆ")

    async def run(self, step1_output: Step1Output) -> HoldRecommendation:
        stock_code = step1_output.news.stock_code
        logger.info("å¼€å§‹ Step2 è¯„åˆ†æµç¨‹ - è‚¡ç¥¨: %s", stock_code)

        try:
            # ä½¿ç”¨ ensure_ascii=False ä¿æŒä¸­æ–‡å¯è¯»æ€§ï¼Œé¿å… Unicode è½¬ä¹‰
            # è¿™æ · LLM èƒ½æ›´å¥½åœ°ç†è§£ä¸­æ–‡å†…å®¹ï¼ŒåŒæ—¶å‡å°‘ token æ¶ˆè€—
            context_str = step1_output.model_dump_json(ensure_ascii=False)
            logger.debug("Step1 è¾“å…¥æ•°æ®å¤§å°: %d å­—ç¬¦", len(context_str))

            score_agent = ChatAgent(
                name="ScoreAgent",
                chat_client=self.score_client,
                instructions=SCORE_AGENT_SYSTEM.format(stock_code=stock_code),
                default_options={
                    "temperature": 0.1,  # é™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
                    "response_format": {"type": "json_object"},
                    "extra_body": {"enable_search": True},
                },
            )

            review_agent = ChatAgent(
                name="ReviewAgent",
                chat_client=self.review_client,
                instructions=REVIEW_AGENT_SYSTEM.format(stock_code=stock_code),
                default_options={"response_format": {"type": "json_object"}},
            )

            # Manager ä¹Ÿéœ€è¦æ˜¯ä¸€ä¸ª Agent
            manager_agent = ChatAgent(
                name="Manager",
                chat_client=self.manager_client,
                instructions=MANAGER_INSTRUCTIONS,
            )

            workflow = (
                MagenticBuilder()
                .with_manager(
                    manager=StandardMagenticManager(
                        agent=manager_agent,
                        max_round_count=config.MAX_ITERATIONS,
                    )
                )
                .participants([score_agent, review_agent])
                .build()
            )

            task = (
                "è¯·æ ¹æ®ä»¥ä¸‹ Step1 æ•°æ®ç”Ÿæˆè‚¡ç¥¨æŠ•èµ„è¯„åˆ†æŠ¥å‘Šã€‚\n\n"
                f"æ•°æ®å†…å®¹ï¼š\n{context_str}\n\n"
                "æµç¨‹çº¦æŸï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š\n"
                "1. é¦–å…ˆè®© ScoreAgent ç”Ÿæˆè¯„åˆ†æŠ¥å‘Šåˆç¨¿ï¼ˆåŒ…å« hold_score å’Œ summary_reasonï¼‰\n"
                "2. ç„¶åå¿…é¡»è®© ReviewAgent å®¡æ ¸åˆç¨¿ï¼ˆè¿”å› passed å’Œ reason å­—æ®µï¼‰\n"
                "3. å¦‚æœ ReviewAgent è¿”å› passed=falseï¼Œå¿…é¡»å°† reason åé¦ˆç»™ ScoreAgent è¿›è¡Œä¿®æ”¹\n"
                "4. é‡å¤æ­¥éª¤ 2-3ï¼Œç›´åˆ° ReviewAgent è¿”å› passed=true\n"
                "5. åªæœ‰åœ¨ passed=true çš„æƒ…å†µä¸‹æ‰èƒ½è¾“å‡ºæœ€ç»ˆç»“æœ\n\n"
                "æ³¨æ„ï¼šReviewAgent æ‹¥æœ‰ä¸€ç¥¨å¦å†³æƒï¼Œä¸å¾—è·³è¿‡å®¡æ ¸ç¯èŠ‚ã€‚"
            )

            try:
                result = await workflow.run(task)
                logger.info("Magentic å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
            except RuntimeError as exc:
                lowered = str(exc).lower()
                if "iteration" in lowered or "max" in lowered:
                    logger.error(
                        "Magentic å·¥ä½œæµè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° (%d)",
                        config.MAX_ITERATIONS,
                    )
                    logger.debug("è¿­ä»£è¶…é™è¯¦æƒ…: %s", str(exc), exc_info=True)
                    raise RuntimeError(
                        f"Step2 consensus failed for {stock_code}. "
                        f"ScoreAgent and ReviewAgent could not reach agreement within {config.MAX_ITERATIONS} iterations. "
                        "This may indicate conflicting evaluation criteria or data quality issues."
                    ) from exc
                raise

            logger.debug("æå–è¯„åˆ†ç»“æœ")
            try:
                final_json = self._extract_result(result)
                logger.info("è¯„åˆ†ç”Ÿæˆå®Œæˆ - åˆ†æ•°: %.2f", final_json["hold_score"])
                logger.debug("è¯„åˆ†ç†ç”±æ‘˜è¦: %s...", final_json["summary_reason"][:100])
            except ValueError as exc:
                logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¯„åˆ†ç»“æœ - %s", stock_code)
                logger.debug("ç»“æœæå–å¤±è´¥è¯¦æƒ…: %s", str(exc), exc_info=True)
                raise RuntimeError(
                    f"Step2 failed to produce valid output for {stock_code}. "
                    "No valid ScoreAgent output found after workflow execution. "
                    "This may indicate consensus failure or workflow timeout."
                ) from exc
            except json.JSONDecodeError as exc:
                logger.error("JSON è§£æå¤±è´¥ - %s", stock_code)
                logger.debug("JSON é”™è¯¯è¯¦æƒ…: %s", str(exc), exc_info=True)
                raise

            stock_name = step1_output.news.stock_name or step1_output.sector.stock_name
            if not stock_name:
                logger.warning(
                    "stock_name ä¸ºç©º - %s: Step1 çš„ news.stock_name å’Œ sector.stock_name éƒ½ä¸ºç©ºã€‚"
                    "è¿™ä¸å½±å“è¯„åˆ†æµç¨‹ï¼Œä½†å¯èƒ½å½±å“ä¸‹æ¸¸ç³»ç»Ÿçš„æ˜¾ç¤ºã€‚",
                    stock_code,
                )
                stock_name = ""

            output = HoldRecommendation(
                stock_code=stock_code,
                stock_name=stock_name,
                hold_score=final_json["hold_score"],
                summary_reason=final_json["summary_reason"],
            )
            logger.info("Step2 å®Œæˆ - %s: %.2fåˆ†", stock_code, output.hold_score)
            return output

        except asyncio.TimeoutError as exc:
            logger.error(
                "Step2 æ‰§è¡Œè¶…æ—¶ - %s: API è°ƒç”¨è¶…è¿‡ %s ç§’",
                stock_code,
                config.API_TIMEOUT,
            )
            logger.debug("è¶…æ—¶è¯¦æƒ…: %s", str(exc), exc_info=True)
            raise RuntimeError(
                f"Step2 generation timeout for {stock_code}. "
                f"API call exceeded {config.API_TIMEOUT} seconds. "
                "Please retry later or check network connectivity."
            ) from exc
        except ValidationError as exc:
            logger.error("Pydantic æ ¡éªŒå¤±è´¥ - %s", stock_code)
            logger.debug("æ ¡éªŒé”™è¯¯è¯¦æƒ…: %s", exc.json(), exc_info=True)
            raise
        except Exception as exc:
            if "timeout" in str(exc).lower():
                logger.error("æ£€æµ‹åˆ°è¶…æ—¶ç›¸å…³é”™è¯¯ - %s: %s", stock_code, str(exc))
                logger.debug("è¶…æ—¶å †æ ˆ", exc_info=True)
                raise RuntimeError(f"Timeout error in Step2 for {stock_code}") from exc
            logger.error("Step2 æ‰§è¡Œå¼‚å¸¸ - %s: %s", stock_code, str(exc))
            logger.debug("å¼‚å¸¸å †æ ˆ", exc_info=True)
            raise

    def _extract_result(self, result: Any) -> dict:
        """
        ä» Magentic å·¥ä½œæµç»“æœä¸­æå–è¯„åˆ†æ•°æ®ï¼ˆå«å®¡æ ¸éªŒè¯ï¼‰ã€‚

        æ ¸å¿ƒåŸåˆ™ï¼šä¸ç®¡ç»“æœä»å“ªæ¥ï¼Œéƒ½å¿…é¡»éªŒè¯ ReviewAgent çš„ passed=trueã€‚

        æå–è·¯å¾„ä¼˜å…ˆçº§ï¼š
        1. events - æœ€å¯é ï¼ŒåŒ…å«å®Œæ•´çš„å®¡æ ¸ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
        2. __iter__ - æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼

        æ‰€æœ‰è·¯å¾„éƒ½å¿…é¡»ç»è¿‡ ReviewAgent å®¡æ ¸éªŒè¯æ‰èƒ½è¿”å›ç»“æœã€‚

        Args:
            result: Magentic å·¥ä½œæµè¿”å›çš„ç»“æœå¯¹è±¡

        Returns:
            dict: å®¡æ ¸é€šè¿‡çš„è¯„åˆ†ç»“æœ

        Raises:
            ValueError: å¦‚æœæ— æ³•æå–ç»“æœæˆ–å®¡æ ¸éªŒè¯å¤±è´¥
        """
        logger.debug("å¼€å§‹æå– Magentic å·¥ä½œæµç»“æœ")

        # ğŸ”‘ å…³é”®ï¼šé¦–å…ˆè·å– eventsï¼Œç”¨äºæ‰€æœ‰è·¯å¾„çš„å®¡æ ¸éªŒè¯
        events = getattr(result, "events", None)

        # æ£€æŸ¥ events æ˜¯å¦å­˜åœ¨ä½†ä¸ºç©ºï¼ˆå¼‚å¸¸æƒ…å†µï¼Œåº”æ˜ç¡®æŠ¥é”™ï¼‰
        if events is not None and not events:
            logger.error("âš  äº‹ä»¶æµä¸ºç©ºåˆ—è¡¨ (events=[])ï¼Œæ— æ³•æå–å®¡æ ¸ä¿¡æ¯")
            raise ValueError(
                "Events list is empty. Cannot verify ReviewAgent approval without event history."
            )

        # è·¯å¾„1: ä¼˜å…ˆä½¿ç”¨ eventsï¼ˆæœ€å¯é ï¼ŒåŒ…å«å®Œæ•´å®¡æ ¸ä¿¡æ¯ï¼‰
        if events:
            logger.debug("ä»äº‹ä»¶æµä¸­æå–ç»“æœï¼Œå…± %d ä¸ªäº‹ä»¶", len(events))
            return self._extract_from_events(events)

        # è·¯å¾„2: __iter__ï¼ˆæ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©ï¼‰
        if hasattr(result, "__iter__"):
            items = list(result)
            if items:
                logger.debug("ä»å¯è¿­ä»£å¯¹è±¡ä¸­æå–ç»“æœï¼Œå…± %d ä¸ªå…ƒç´ ", len(items))
                first_item = items[0]
                if hasattr(first_item, "executor_id") or hasattr(first_item, "agent_name"):
                    # çœ‹èµ·æ¥æ˜¯ events
                    return self._extract_from_events(items)

        logger.error("æ— æ³•ä» result å¯¹è±¡æå–ç»“æœï¼Œç±»å‹: %s", type(result))
        raise ValueError("Workflow result format not supported")

    def _extract_from_events(self, events: list) -> dict:
        logger.debug("å€’åºéå†äº‹ä»¶æµï¼ŒæŸ¥æ‰¾ ScoreAgent çš„æœ€ç»ˆè¾“å‡º")

        # ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
        stats = {
            "score_agent_total": 0,        # ScoreAgent æ€»æäº¤æ¬¡æ•°
            "score_agent_valid": 0,        # ScoreAgent æœ‰æ•ˆè¾“å‡ºæ¬¡æ•°
            "review_agent_total": 0,       # ReviewAgent æ€»å®¡æ ¸æ¬¡æ•°
            "review_approved": 0,          # ReviewAgent é€šè¿‡æ¬¡æ•°
            "review_rejected": 0,          # ReviewAgent æ‹’ç»æ¬¡æ•°
            "review_format_error": 0,      # ReviewAgent æ ¼å¼é”™è¯¯æ¬¡æ•°
        }

        for idx, event in enumerate(reversed(events)):
            event_idx = len(events) - idx - 1
            logger.debug("æ£€æŸ¥äº‹ä»¶ [%d]: %s", event_idx, type(event))

            is_score_agent = False
            if hasattr(event, "executor_id") and event.executor_id == "ScoreAgent":
                is_score_agent = True
            elif hasattr(event, "agent_name") and event.agent_name == "ScoreAgent":
                is_score_agent = True
            elif hasattr(event, "source") and "ScoreAgent" in str(event.source):
                is_score_agent = True

            if not is_score_agent:
                logger.debug("äº‹ä»¶ [%d] ä¸æ˜¯ ScoreAgent çš„è¾“å‡ºï¼Œè·³è¿‡", event_idx)
                continue

            logger.debug("äº‹ä»¶ [%d] æ¥è‡ª ScoreAgentï¼Œå°è¯•è§£æ", event_idx)
            stats["score_agent_total"] += 1

            content = self._get_content(event)
            if content is None:
                logger.debug("äº‹ä»¶ [%d] å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡", event_idx)
                continue

            # è°ƒè¯•ï¼šè®°å½•åŸå§‹å†…å®¹ä»¥ä¾¿æ’æŸ¥é—®é¢˜
            logger.debug("äº‹ä»¶ [%d] åŸå§‹å†…å®¹: %s", event_idx, str(content)[:500])

            try:
                data = self._parse_and_validate(content)
                stats["score_agent_valid"] += 1

                # ğŸ”’ å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯æ­¤ ScoreAgent è¾“å‡ºæ˜¯å¦æœ‰å¯¹åº”çš„ ReviewAgent å®¡æ ¸é€šè¿‡
                approval_result = self._is_approved_by_reviewer(events, event_idx, stats)
                if not approval_result:
                    logger.warning(
                        "äº‹ä»¶ [%d] çš„ ScoreAgent è¾“å‡ºæœªç» ReviewAgent å®¡æ ¸é€šè¿‡ï¼Œè·³è¿‡",
                        event_idx
                    )
                    continue

                logger.info("æˆåŠŸä»äº‹ä»¶ [%d] æå–ç»“æœï¼šhold_score=%.2f", event_idx, data["hold_score"])

                # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
                self._log_workflow_stats(stats)

                return data
            except Exception as exc:
                logger.warning("äº‹ä»¶ [%d] è§£æå¤±è´¥: %s", event_idx, exc)
                continue

        logger.error("æœªåœ¨äº‹ä»¶æµä¸­æ‰¾åˆ°æœ‰æ•ˆçš„ ScoreAgent è¾“å‡º")
        raise ValueError("No valid ScoreAgent output found in events")

    def _is_approved_by_reviewer(self, events: list, score_agent_idx: int, stats: dict = None) -> bool:
        """
        éªŒè¯æŒ‡å®šçš„ ScoreAgent è¾“å‡ºæ˜¯å¦æœ‰å¯¹åº”çš„ ReviewAgent å®¡æ ¸é€šè¿‡ã€‚

        æ£€æŸ¥é€»è¾‘ï¼š
        1. ä» score_agent_idx ä¹‹åçš„äº‹ä»¶ä¸­æŸ¥æ‰¾ ReviewAgent çš„è¾“å‡º
        2. æ‰¾åˆ°ç¬¬ä¸€ä¸ª ReviewAgent è¾“å‡ºåï¼Œæ£€æŸ¥å…¶ passed å­—æ®µ
        3. å¦‚æœ passed=trueï¼Œè¿”å› Trueï¼›å¦åˆ™è¿”å› False

        Args:
            events: äº‹ä»¶æµåˆ—è¡¨
            score_agent_idx: ScoreAgent äº‹ä»¶çš„ç´¢å¼•ä½ç½®
            stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºæ”¶é›†å®¡æ ¸ç»Ÿè®¡

        Returns:
            bool: True è¡¨ç¤ºå·²å®¡æ ¸é€šè¿‡ï¼ŒFalse è¡¨ç¤ºæœªé€šè¿‡æˆ–æœªå®¡æ ¸
        """
        logger.debug("éªŒè¯äº‹ä»¶ [%d] çš„ ScoreAgent è¾“å‡ºæ˜¯å¦ç»è¿‡å®¡æ ¸", score_agent_idx)

        # ä» ScoreAgent ä¹‹åçš„äº‹ä»¶ä¸­æŸ¥æ‰¾ ReviewAgent
        for idx in range(score_agent_idx + 1, len(events)):
            event = events[idx]

            # è¯†åˆ« ReviewAgent çš„è¾“å‡º
            is_review_agent = False
            if hasattr(event, "executor_id") and event.executor_id == "ReviewAgent":
                is_review_agent = True
            elif hasattr(event, "agent_name") and event.agent_name == "ReviewAgent":
                is_review_agent = True
            elif hasattr(event, "source") and "ReviewAgent" in str(event.source):
                is_review_agent = True

            if not is_review_agent:
                continue

            # æ‰¾åˆ° ReviewAgentï¼Œæå–å…¶è¾“å‡º
            logger.debug("æ‰¾åˆ° ReviewAgent äº‹ä»¶ [%d]ï¼Œæ£€æŸ¥å®¡æ ¸ç»“æœ", idx)
            if stats is not None:
                stats["review_agent_total"] += 1

            content = self._get_content(event)
            if content is None:
                logger.debug("ReviewAgent äº‹ä»¶ [%d] å†…å®¹ä¸ºç©º", idx)
                if stats is not None:
                    stats["review_format_error"] += 1
                continue

            try:
                # è§£æ ReviewAgent çš„è¾“å‡º
                if isinstance(content, dict):
                    review_data = content
                elif isinstance(content, str):
                    # ä½¿ç”¨ extract_json_str æå– JSONï¼Œå¤„ç†ä»£ç å—å’Œå‰åæ–‡
                    try:
                        json_str = extract_json_str(content)
                        review_data = json.loads(json_str)
                    except ValueError as extract_exc:
                        logger.warning(
                            "ReviewAgent äº‹ä»¶ [%d] æ— æ³•æå– JSON: %s",
                            idx, extract_exc
                        )
                        if stats is not None:
                            stats["review_format_error"] += 1
                        continue
                else:
                    logger.warning("ReviewAgent äº‹ä»¶ [%d] å†…å®¹æ ¼å¼ä¸æ”¯æŒ: %s", idx, type(content))
                    if stats is not None:
                        stats["review_format_error"] += 1
                    continue

                # æ£€æŸ¥ passed å­—æ®µ
                if "passed" in review_data:
                    passed_raw = review_data["passed"]

                    # è§„èŒƒåŒ–ä¸ºå¸ƒå°”å€¼ï¼ˆå®¹å¿ LLM å¯èƒ½è¾“å‡ºçš„å¤šç§ç±»å‹ï¼‰
                    if isinstance(passed_raw, bool):
                        passed = passed_raw
                    elif isinstance(passed_raw, str):
                        # å®¹å¿å­—ç¬¦ä¸² "true"/"false"/"1"/"0"/"yes"/"no"
                        passed = passed_raw.lower().strip() in ("true", "1", "yes")
                    elif isinstance(passed_raw, (int, float)):
                        # å®¹å¿æ•°å­— 1/0
                        passed = bool(passed_raw)
                    else:
                        logger.warning(
                            "ReviewAgent äº‹ä»¶ [%d] passed å­—æ®µç±»å‹å¼‚å¸¸: %sï¼Œé»˜è®¤ä¸º False",
                            idx, type(passed_raw)
                        )
                        passed = False

                    logger.debug(
                        "ReviewAgent äº‹ä»¶ [%d] å®¡æ ¸ç»“æœ: passed=%s (åŸå§‹å€¼: %r, ç±»å‹: %s)",
                        idx, passed, passed_raw, type(passed_raw).__name__
                    )

                    if passed:
                        if stats is not None:
                            stats["review_approved"] += 1
                        logger.info("âœ“ ScoreAgent [%d] çš„è¾“å‡ºå·²é€šè¿‡ ReviewAgent [%d] å®¡æ ¸", score_agent_idx, idx)
                        return True
                    else:
                        if stats is not None:
                            stats["review_rejected"] += 1
                        reason = review_data.get("reason", "æœªæä¾›åŸå› ")
                        logger.warning(
                            "âœ— ScoreAgent [%d] çš„è¾“å‡ºæœªé€šè¿‡ ReviewAgent [%d] å®¡æ ¸ï¼ŒåŸå› : %s",
                            score_agent_idx, idx, reason
                        )
                        return False
                else:
                    logger.warning("ReviewAgent äº‹ä»¶ [%d] ç¼ºå°‘ passed å­—æ®µ", idx)
                    if stats is not None:
                        stats["review_format_error"] += 1
                    continue

            except json.JSONDecodeError as exc:
                logger.warning("ReviewAgent äº‹ä»¶ [%d] JSON è§£æå¤±è´¥: %s", idx, exc)
                if stats is not None:
                    stats["review_format_error"] += 1
                continue
            except Exception as exc:
                logger.warning("ReviewAgent äº‹ä»¶ [%d] å¤„ç†å¤±è´¥: %s", idx, exc)
                if stats is not None:
                    stats["review_format_error"] += 1
                continue

        # æœªæ‰¾åˆ°å¯¹åº”çš„ ReviewAgent å®¡æ ¸è®°å½•
        logger.warning("âš  ScoreAgent [%d] çš„è¾“å‡ºæœªæ‰¾åˆ°å¯¹åº”çš„ ReviewAgent å®¡æ ¸è®°å½•", score_agent_idx)
        return False

    def _log_workflow_stats(self, stats: dict) -> None:
        """è¾“å‡ºå·¥ä½œæµç»Ÿè®¡æ‘˜è¦ã€‚

        Args:
            stats: åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        logger.info("")
        logger.info("=" * 70)
        logger.info("Step2 å·¥ä½œæµç»Ÿè®¡æ‘˜è¦")
        logger.info("=" * 70)
        logger.info("ScoreAgent æäº¤æ¬¡æ•°:        %d", stats["score_agent_total"])
        logger.info("  - æœ‰æ•ˆè¾“å‡ºæ¬¡æ•°:           %d", stats["score_agent_valid"])
        logger.info("  - æ ¼å¼é”™è¯¯/ç©ºå†…å®¹:        %d", stats["score_agent_total"] - stats["score_agent_valid"])
        logger.info("")
        logger.info("ReviewAgent å®¡æ ¸æ¬¡æ•°:       %d", stats["review_agent_total"])
        logger.info("  - é€šè¿‡ (passed=true):     %d âœ…", stats["review_approved"])
        logger.info("  - æ‹’ç» (passed=false):    %d âŒ", stats["review_rejected"])
        logger.info("  - æ ¼å¼é”™è¯¯/æ— æ³•è§£æ:      %d âš ï¸", stats["review_format_error"])
        logger.info("")

        # è®¡ç®—é‡å†™æ¬¡æ•°ï¼ˆæ€»æäº¤æ¬¡æ•° - 1ï¼Œå› ä¸ºé¦–æ¬¡ä¸ç®—é‡å†™ï¼‰
        rewrite_count = max(0, stats["score_agent_total"] - 1)
        logger.info("ScoreAgent é‡å†™æ¬¡æ•°:        %d", rewrite_count)
        logger.info("ReviewAgent æ‹’ç»æ¬¡æ•°:       %d", stats["review_rejected"])
        logger.info("")

        # è®¡ç®—æˆåŠŸç‡
        if stats["review_agent_total"] > 0:
            success_rate = (stats["review_approved"] / stats["review_agent_total"]) * 100
            logger.info("å®¡æ ¸é€šè¿‡ç‡:                 %.1f%%", success_rate)

        logger.info("=" * 70)
        logger.info("")

    def _get_content(self, obj: Any) -> Any:
        """
        ä»å„ç§å¯¹è±¡ç±»å‹ä¸­æå–å†…å®¹ã€‚

        å¯¹äº list/tuple ç±»å‹ï¼Œä½¿ç”¨å€’åºéå†ä»¥ä¼˜å…ˆè·å–æœ€åä¸€æ¡æ¶ˆæ¯ã€‚
        è¿™ç¡®ä¿åœ¨ messages åˆ—è¡¨ä¸­ä¼˜å…ˆè·å– assistant çš„è¾“å‡ºï¼Œè€Œä¸æ˜¯ system/user æ¶ˆæ¯ã€‚

        Args:
            obj: å¾…æå–å†…å®¹çš„å¯¹è±¡

        Returns:
            æå–åˆ°çš„å†…å®¹ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å› None
        """
        if obj is None:
            return None
        if isinstance(obj, dict):
            return obj
        if isinstance(obj, str):
            return obj
        if isinstance(obj, (list, tuple)):
            # ğŸ”„ å€’åºéå†ï¼šä¼˜å…ˆè·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆé€šå¸¸æ˜¯ assistant è¾“å‡ºï¼‰
            for item in reversed(obj):
                content = self._get_content(item)
                if content is not None:
                    return content
            return None
        if hasattr(obj, "agent_response"):
            return self._get_content(getattr(obj, "agent_response"))
        if hasattr(obj, "messages"):
            return self._get_content(getattr(obj, "messages"))
        if hasattr(obj, "message"):
            return self._get_content(getattr(obj, "message"))
        if hasattr(obj, "data"):
            return self._get_content(getattr(obj, "data"))
        if hasattr(obj, "content"):
            return self._get_content(getattr(obj, "content"))
        if hasattr(obj, "text"):
            return getattr(obj, "text")
        return None

    def _parse_and_validate(self, content: Any) -> dict:
        if isinstance(content, dict):
            data = content
        elif isinstance(content, str):
            raw = content.strip()
            if raw.startswith("```json"):
                raw = raw[7:]
            if raw.startswith("```"):
                raw = raw[3:]
            if raw.endswith("```"):
                raw = raw[:-3]
            raw = raw.strip()
            data = json.loads(raw)
        else:
            raise ValueError(f"Unsupported content type: {type(content)}")

        if "hold_score" not in data:
            raise ValueError("Missing required field: hold_score")
        if "summary_reason" not in data:
            raise ValueError("Missing required field: summary_reason")

        hold_score = data["hold_score"]
        if not isinstance(hold_score, (int, float)):
            raise ValueError(f"hold_score must be numeric, got {type(hold_score)}")
        if not (0 <= hold_score <= 100):
            raise ValueError(f"hold_score must be in [0, 100], got {hold_score}")

        summary_reason = data["summary_reason"]
        if not isinstance(summary_reason, str):
            raise ValueError(f"summary_reason must be string, got {type(summary_reason)}")
        if len(summary_reason) < config.SUMMARY_REASON_MIN_CHARS:
            raise ValueError(
                f"summary_reason too short: {len(summary_reason)} chars "
                f"(min: {config.SUMMARY_REASON_MIN_CHARS})"
            )
        if len(summary_reason) > config.SUMMARY_REASON_MAX_CHARS:
            raise ValueError(
                f"summary_reason too long: {len(summary_reason)} chars "
                f"(max: {config.SUMMARY_REASON_MAX_CHARS})"
            )

        logger.debug("å†…å®¹éªŒè¯é€šè¿‡")
        return data
